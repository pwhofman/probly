{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First-Order Data Generator Tutorial\n",
    "\n",
    "##  Learning Objectives\n",
    "\n",
    "In this tutorial you will learn:\n",
    "1. What First-Order data is and why it is important\n",
    "2. How to use the `FirstOrderDataGenerator`\n",
    "3. How to save and load distributions\n",
    "4. How to work with `FirstOrderDataset` and DataLoader\n",
    "5. How to train a model with soft targets\n",
    "\n",
    "**Prerequisites:** Basic knowledge of PyTorch\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 1: Introduction and Setup\n",
    "\n",
    "### What is First-Order Data?\n",
    "\n",
    "In Machine Learning we work with the distribution $p(X, Y)$, where:\n",
    "- $X$ = Input features\n",
    "- $Y$ = Target labels\n",
    "\n",
    "The **conditional distribution** $p(Y|X)$ tells us: \"Given a specific $x$, how likely are the different classes?\"\n",
    "\n",
    "**Problem:** Normally we don't have access to $p(Y|X)$!\n",
    "\n",
    "**Solution:** We approximate this with a well-trained model $\\hat{h}$:\n",
    "$$\\hat{h}(x) \\approx p(\\cdot | x)$$\n",
    "\n",
    "We call these approximations **First-Order Data**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Import First-Order Generator\n",
    "# NOTE: Adjust the import path to your project structure!\n",
    "# PyTorch-specific import (recommended)\n",
    "from probly.data_generator.torch_first_order_generator import (\n",
    "    FirstOrderDataGenerator,\n",
    "    FirstOrderDataset,\n",
    ")\n",
    "\n",
    "# Alternative: Factory Pattern (for multi-framework)\n",
    "# from probly.data_generator.factory import create_data_generator  # noqa: ERA001\n",
    "# generator = create_data_generator('pytorch', model, dataset)  # noqa: ERA001\n",
    "\n",
    "print(\"All imports successful!\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 2: Prepare Example Data\n",
    "\n",
    "We create a simple dataset and a \"Teacher\" model that we use as ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example dataset\n",
    "class SimpleDataset(Dataset):\n",
    "    \"\"\"A simple dataset for demonstration purposes.\"\"\"\n",
    "\n",
    "    def __init__(self, n_samples: int = 200, input_dim: int = 10, n_classes: int = 3, seed: int = 42) -> None:\n",
    "        \"\"\"Initialize dataset.\"\"\"\n",
    "        torch.manual_seed(seed)\n",
    "        self.n_samples = n_samples\n",
    "        self.input_dim = input_dim\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        # Generate synthetic data\n",
    "        self.data = torch.randn(n_samples, input_dim)\n",
    "        self.labels = torch.randint(0, n_classes, (n_samples,))\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Return length.\"\"\"\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, idx: int) -> tuple:\n",
    "        \"\"\"Get item.\"\"\"\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "# Create dataset\n",
    "dataset = SimpleDataset(n_samples=200, input_dim=10, n_classes=3)\n",
    "print(f\"Dataset created: {len(dataset)} samples, {dataset.n_classes} classes\")\n",
    "\n",
    "# Look at example sample\n",
    "sample_x, sample_y = dataset[0]\n",
    "print(\"\\nExample sample:\")\n",
    "print(f\"  Input shape: {sample_x.shape}\")\n",
    "print(f\"  Label: {sample_y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teacher model (represents the \"ground truth\")\n",
    "class TeacherModel(nn.Module):\n",
    "    \"\"\"A simple neural network as Teacher model.\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim: int = 10, n_classes: int = 3) -> None:\n",
    "        \"\"\"Initialize model.\"\"\"\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, n_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass.\"\"\"\n",
    "        return self.network(x)  # Returns logits\n",
    "\n",
    "\n",
    "# Create model\n",
    "teacher_model = TeacherModel(input_dim=10, n_classes=3)\n",
    "teacher_model.eval()  # Important: In evaluation mode!\n",
    "\n",
    "print(\"Teacher model created\")\n",
    "print(\"\\nModel architecture:\")\n",
    "print(teacher_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 3: Generate First-Order Distributions\n",
    "\n",
    "Now we use the `FirstOrderDataGenerator` to calculate a probability distribution for each sample in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize generator\n",
    "generator = FirstOrderDataGenerator(\n",
    "    model=teacher_model,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    batch_size=32,\n",
    "    output_mode=\"logits\",  # Our model outputs logits\n",
    "    model_name=\"teacher_v1\",\n",
    ")\n",
    "\n",
    "print(\"FirstOrderDataGenerator initialized\")\n",
    "print(f\"  Device: {generator.device}\")\n",
    "print(f\"  Batch Size: {generator.batch_size}\")\n",
    "print(f\"  Output Mode: {generator.output_mode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate distributions\n",
    "print(\"Generating First-Order distributions...\\n\")\n",
    "\n",
    "distributions = generator.generate_distributions(\n",
    "    dataset,\n",
    "    progress=True,  # Shows progress\n",
    ")\n",
    "\n",
    "print(f\"\\n{len(distributions)} distributions generated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at example distributions\n",
    "print(\"Example distributions:\\n\")\n",
    "\n",
    "for i in range(5):\n",
    "    dist = distributions[i]\n",
    "    print(f\"Sample {i}:\")\n",
    "    print(f\"  Distribution: [{dist[0]:.4f}, {dist[1]:.4f}, {dist[2]:.4f}]\")\n",
    "    print(f\"  Sum: {sum(dist):.6f} (should be ≈ 1.0)\")\n",
    "    print(f\"  Most likely class: {np.argmax(dist)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Distributions for first 10 samples\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(10):\n",
    "    ax = axes[i]\n",
    "    dist = distributions[i]\n",
    "\n",
    "    ax.bar(range(len(dist)), dist, color=[\"blue\", \"orange\", \"green\"])\n",
    "    ax.set_title(f\"Sample {i}\")\n",
    "    ax.set_xlabel(\"Class\")\n",
    "    ax.set_ylabel(\"Probability\")\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"First-Order Distributions for the First 10 Samples\", y=1.02, fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "print(\"Visualization: Each bar shows the probability for a class\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 4: Save and Load Distributions\n",
    "\n",
    "We can save the generated distributions as a JSON file to reuse them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory\n",
    "output_dir = Path(\"tutorial_output\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Define path\n",
    "save_path = output_dir / \"first_order_distributions.json\"\n",
    "\n",
    "# Define metadata\n",
    "metadata = {\n",
    "    \"dataset\": \"SimpleDataset\",\n",
    "    \"n_samples\": len(dataset),\n",
    "    \"n_classes\": dataset.n_classes,\n",
    "    \"input_dim\": dataset.input_dim,\n",
    "    \"note\": \"Generated for tutorial purposes\",\n",
    "    \"teacher_architecture\": \"Simple 3-layer network\",\n",
    "}\n",
    "\n",
    "# Save\n",
    "print(f\"Saving distributions to: {save_path}\")\n",
    "generator.save_distributions(\n",
    "    path=save_path,\n",
    "    distributions=distributions,\n",
    "    meta=metadata,\n",
    ")\n",
    "print(\"Successfully saved!\")\n",
    "\n",
    "# Show file size\n",
    "file_size = save_path.stat().st_size / 1024  # in KB\n",
    "print(f\"\\nFile size: {file_size:.2f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load distributions\n",
    "print(\"Loading distributions...\\n\")\n",
    "\n",
    "loaded_distributions, loaded_metadata = generator.load_distributions(save_path)\n",
    "\n",
    "print(\"Successfully loaded!\\n\")\n",
    "print(\"Metadata:\")\n",
    "for key, value in loaded_metadata.items():\n",
    "    print(f\"  - {key}: {value}\")\n",
    "\n",
    "# Verification\n",
    "print(\"\\n✓ Verification:\")\n",
    "print(f\"  Number of distributions: {len(loaded_distributions)}\")\n",
    "print(f\"  Data identical: {distributions == loaded_distributions}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 5: Using FirstOrderDataset\n",
    "\n",
    "`FirstOrderDataset` is a PyTorch Dataset wrapper that combines the original dataset with the First-Order distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FirstOrderDataset\n",
    "fo_dataset = FirstOrderDataset(\n",
    "    base_dataset=dataset,\n",
    "    distributions=loaded_distributions,\n",
    ")\n",
    "\n",
    "print(f\"FirstOrderDataset created with {len(fo_dataset)} samples\\n\")\n",
    "\n",
    "# Get one sample\n",
    "input_tensor, label, distribution = fo_dataset[0]\n",
    "\n",
    "print(\"Sample 0:\")\n",
    "print(f\"  Input Shape: {input_tensor.shape}\")\n",
    "print(f\"  Label: {label}\")\n",
    "print(f\"  Distribution Shape: {distribution.shape}\")\n",
    "print(f\"  Distribution: [{distribution[0]:.4f}, {distribution[1]:.4f}, {distribution[2]:.4f}]\")\n",
    "print(f\"  Summe: {distribution.sum():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through multiple samples\n",
    "print(\"Iterating through multiple samples:\\n\")\n",
    "\n",
    "for i in range(5):\n",
    "    input_tensor, label, distribution = fo_dataset[i]\n",
    "    predicted_class = torch.argmax(distribution).item()\n",
    "    confidence = distribution[predicted_class].item()\n",
    "\n",
    "    print(f\"Sample {i}:\")\n",
    "    print(f\"  Ground Truth Label: {label}\")\n",
    "    print(f\"  Predicted Class: {predicted_class}\")\n",
    "    print(f\"  Confidence: {confidence:.4f}\")\n",
    "    print(f\"  Match: {'✓' if predicted_class == label else '✗'}\")\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 6: Create DataLoader\n",
    "\n",
    "For training we need a DataLoader that provides batches with First-Order distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader with First-Order distributions\n",
    "fo_loader = output_fo_dataloader(  # noqa: F821\n",
    "    base_dataset=dataset,\n",
    "    distributions=loaded_distributions,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=0,  # For Windows compatibility\n",
    ")\n",
    "\n",
    "print(\"DataLoader created\")\n",
    "print(\"  Batch Size: 32\")\n",
    "print(f\"  Number of batches: {len(fo_loader)}\")\n",
    "print(\"  Shuffle: True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at first batch\n",
    "batch_inputs, batch_labels, batch_distributions = next(iter(fo_loader))\n",
    "\n",
    "print(\"\\nFirst batch:\")\n",
    "print(f\"  Inputs Shape: {batch_inputs.shape}\")\n",
    "print(f\"  Labels Shape: {batch_labels.shape}\")\n",
    "print(f\"  Distributions Shape: {batch_distributions.shape}\")\n",
    "print(\"\\n  First 3 distributions in batch:\")\n",
    "for i in range(3):\n",
    "    dist = batch_distributions[i]\n",
    "    print(f\"    Sample {i}: [{dist[0]:.4f}, {dist[1]:.4f}, {dist[2]:.4f}]\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 7: Train Student Model with Soft Targets\n",
    "\n",
    "Now we train a \"Student\" model that tries to learn the distributions of the Teacher model. This is called **Knowledge Distillation**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student model (smaller network)\n",
    "class StudentModel(nn.Module):\n",
    "    \"\"\"A smaller model that learns from the Teacher.\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim: int = 10, n_classes: int = 3) -> None:\n",
    "        \"\"\"Initialize model.\"\"\"\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, 32),  # Smaller than Teacher\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, n_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass.\"\"\"\n",
    "        return self.network(x)\n",
    "\n",
    "\n",
    "# Create Student model\n",
    "student_model = StudentModel(input_dim=10, n_classes=3)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "student_model = student_model.to(device)\n",
    "\n",
    "print(\"Student model created\")\n",
    "print(\"\\nComparison Teacher vs Student:\")\n",
    "print(f\"  Teacher parameters: {sum(p.numel() for p in teacher_model.parameters())}\")\n",
    "print(f\"  Student parameters: {sum(p.numel() for p in student_model.parameters())}\")\n",
    "ratio = sum(p.numel() for p in teacher_model.parameters()) / sum(p.numel() for p in student_model.parameters())\n",
    "print(f\"  Student is {ratio:.1f}x smaller!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setup\n",
    "optimizer = torch.optim.Adam(student_model.parameters(), lr=0.001)\n",
    "epochs = 10\n",
    "\n",
    "# Lists for tracking\n",
    "train_losses = []\n",
    "\n",
    "print(\"Starting training...\\n\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    student_model.train()\n",
    "    epoch_loss = 0.0\n",
    "    n_batches = 0\n",
    "\n",
    "    for inputs, _labels, target_distributions in fo_loader:\n",
    "        # Move data to device\n",
    "        batch_inputs = inputs.to(device)\n",
    "        batch_target_distributions = target_distributions.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logits = student_model(batch_inputs)\n",
    "\n",
    "        # KL Divergence Loss\n",
    "        # Student tries to imitate the Teacher distributions\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "        loss = F.kl_div(\n",
    "            log_probs,\n",
    "            target_distributions,\n",
    "            reduction=\"batchmean\",\n",
    "        )\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        n_batches += 1\n",
    "\n",
    "    avg_loss = epoch_loss / n_batches\n",
    "    train_losses.append(avg_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} - Loss: {avg_loss:.4f}\")\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Training Loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, epochs + 1), train_losses, marker=\"o\", linewidth=2, markersize=8)\n",
    "plt.xlabel(\"Epoch\", fontsize=12)\n",
    "plt.ylabel(\"KL Divergence Loss\", fontsize=12)\n",
    "plt.title(\"Training Loss over Epochs\", fontsize=14, fontweight=\"bold\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nLoss reduction: {train_losses[0]:.4f} → {train_losses[-1]:.4f}\")\n",
    "print(f\"   Improvement: {(1 - train_losses[-1] / train_losses[0]) * 100:.1f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 8: Evaluation - Teacher vs Student\n",
    "\n",
    "Let's compare the predictions of the Teacher model with those of the trained Student model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation mode\n",
    "student_model.eval()\n",
    "teacher_model.eval()\n",
    "\n",
    "# Collect predictions\n",
    "all_inputs = []\n",
    "teacher_probs_list = []\n",
    "student_probs_list = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(len(dataset)):\n",
    "        x, y = dataset[i]\n",
    "        x = x.unsqueeze(0).to(device)  # Batch dimension\n",
    "\n",
    "        # Teacher predictions\n",
    "        teacher_logits = teacher_model(x)\n",
    "        teacher_probs = F.softmax(teacher_logits, dim=-1)\n",
    "\n",
    "        # Student predictions\n",
    "        student_logits = student_model(x)\n",
    "        student_probs = F.softmax(student_logits, dim=-1)\n",
    "\n",
    "        all_inputs.append(x.cpu())\n",
    "        teacher_probs_list.append(teacher_probs.cpu())\n",
    "        student_probs_list.append(student_probs.cpu())\n",
    "        true_labels.append(y)\n",
    "\n",
    "# Convert to tensors\n",
    "teacher_probs_all = torch.cat(teacher_probs_list, dim=0)\n",
    "student_probs_all = torch.cat(student_probs_list, dim=0)\n",
    "true_labels_all = torch.tensor(true_labels)\n",
    "\n",
    "print(\"Evaluation completed\")\n",
    "print(f\"\\nEvaluated on {len(dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "teacher_predictions = torch.argmax(teacher_probs_all, dim=-1)\n",
    "student_predictions = torch.argmax(student_probs_all, dim=-1)\n",
    "\n",
    "teacher_accuracy = (teacher_predictions == true_labels_all).float().mean().item()\n",
    "student_accuracy = (student_predictions == true_labels_all).float().mean().item()\n",
    "\n",
    "print(\"Accuracy:\")\n",
    "print(f\"  Teacher: {teacher_accuracy * 100:.2f}%\")\n",
    "print(f\"  Student: {student_accuracy * 100:.2f}%\")\n",
    "print(f\"\\n  Difference: {abs(teacher_accuracy - student_accuracy) * 100:.2f} percentage points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate KL Divergence between Teacher and Student\n",
    "kl_div = F.kl_div(\n",
    "    F.log_softmax(student_probs_all, dim=-1),\n",
    "    teacher_probs_all,\n",
    "    reduction=\"batchmean\",\n",
    ").item()\n",
    "\n",
    "print(f\"Average KL Divergence between Teacher and Student: {kl_div:.4f}\")\n",
    "print(\"\\nInterpretation:\")\n",
    "print(f\"   Low value ({kl_div:.4f}) means that the Student has\")\n",
    "print(\"   learned the Teacher distributions well!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Teacher vs Student for some samples\n",
    "n_samples_to_show = 6\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(n_samples_to_show):\n",
    "    ax = axes[i]\n",
    "\n",
    "    teacher_dist = teacher_probs_all[i].numpy()\n",
    "    student_dist = student_probs_all[i].numpy()\n",
    "    true_label = true_labels_all[i].item()\n",
    "\n",
    "    x = np.arange(len(teacher_dist))\n",
    "    width = 0.35\n",
    "\n",
    "    bars1 = ax.bar(x - width / 2, teacher_dist, width, label=\"Teacher\", alpha=0.8)\n",
    "    bars2 = ax.bar(x + width / 2, student_dist, width, label=\"Student\", alpha=0.8)\n",
    "\n",
    "    # Mark true label\n",
    "    ax.axvline(x=true_label, color=\"red\", linestyle=\"--\", linewidth=2, label=\"True Label\")\n",
    "\n",
    "    ax.set_title(f\"Sample {i} (True Label: {true_label})\", fontweight=\"bold\")\n",
    "    ax.set_xlabel(\"Class\")\n",
    "    ax.set_ylabel(\"Probability\")\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.legend()\n",
    "    ax.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Comparison: Teacher vs Student Predictions\", y=1.02, fontsize=16, fontweight=\"bold\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nThe bars show how similar the Student predictions are to the Teacher predictions\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 9: Calculate Coverage Metric\n",
    "\n",
    "Coverage measures how well the Student distributions \"cover\" the Teacher distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coverage(pred_probs: torch.Tensor, target_probs: torch.Tensor, epsilon: float = 0.15) -> float:\n",
    "    \"\"\"Calculates epsilon-Credal Coverage.\n",
    "\n",
    "    A prediction \"covers\" the target if the L1 distance <= epsilon.\n",
    "    \"\"\"\n",
    "    l1_distance = torch.sum(torch.abs(pred_probs - target_probs), dim=-1)\n",
    "    covered = (l1_distance <= epsilon).float()\n",
    "    return covered.mean().item()\n",
    "\n",
    "\n",
    "# Coverage for different epsilon values\n",
    "epsilons = [0.05, 0.10, 0.15, 0.20, 0.25, 0.30]\n",
    "coverages = []\n",
    "\n",
    "for eps in epsilons:\n",
    "    cov = compute_coverage(student_probs_all, teacher_probs_all, epsilon=eps)\n",
    "    coverages.append(cov)\n",
    "    print(f\"Coverage at ε = {eps:.2f}: {cov * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Coverage vs Epsilon\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epsilons, [c * 100 for c in coverages], marker=\"o\", linewidth=2, markersize=10)\n",
    "plt.xlabel(\"Epsilon (ε)\", fontsize=12)\n",
    "plt.ylabel(\"Coverage (%)\", fontsize=12)\n",
    "plt.title(\"Coverage as a Function of Epsilon\", fontsize=14, fontweight=\"bold\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.ylim([0, 105])\n",
    "\n",
    "# Mark optimal point\n",
    "optimal_idx = len(coverages) // 2\n",
    "plt.axvline(x=epsilons[optimal_idx], color=\"red\", linestyle=\"--\", alpha=0.5, label=\"Example ε\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"   The higher the epsilon, the more predictions are counted as 'covered'.\")\n",
    "print(\"   A good model has high coverage at small epsilon!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 10: Advanced Analyses\n",
    "\n",
    "Let's look at which samples the Student performs best and worst on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate L1 distances for all samples\n",
    "l1_distances = torch.sum(torch.abs(student_probs_all - teacher_probs_all), dim=-1)\n",
    "\n",
    "# Find best and worst samples\n",
    "best_indices = torch.argsort(l1_distances)[:5]  # 5 best\n",
    "worst_indices = torch.argsort(l1_distances, descending=True)[:5]  # 5 worst\n",
    "\n",
    "print(\"Top 5 Samples (smallest L1 distance):\")\n",
    "for i, idx_tensor in enumerate(best_indices):\n",
    "    idx = idx_tensor.item()\n",
    "    dist = l1_distances[idx].item()\n",
    "    print(f\"  {i + 1}. Sample {idx}: L1-Distanz = {dist:.4f}\")\n",
    "\n",
    "print(\"\\nBottom 5 Samples (largest L1 distance):\")\n",
    "for i, idx_tensor in enumerate(worst_indices):\n",
    "    idx = idx_tensor.item()\n",
    "    dist = l1_distances[idx].item()\n",
    "    print(f\"  {i + 1}. Sample {idx}: L1-Distanz = {dist:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of L1 distances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(l1_distances.numpy(), bins=30, edgecolor=\"black\", alpha=0.7)\n",
    "plt.xlabel(\"L1 Distance\", fontsize=12)\n",
    "plt.ylabel(\"Number of Samples\", fontsize=12)\n",
    "plt.title(\"Distribution of L1 Distances between Teacher and Student\", fontsize=14, fontweight=\"bold\")\n",
    "plt.axvline(\n",
    "    x=l1_distances.mean().item(),\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=2,\n",
    "    label=f\"Mean: {l1_distances.mean().item():.3f}\",\n",
    ")\n",
    "plt.legend()\n",
    "plt.grid(axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nL1 Distance Statistics:\")\n",
    "print(f\"   Mean: {l1_distances.mean().item():.4f}\")\n",
    "print(f\"   Median: {l1_distances.median().item():.4f}\")\n",
    "print(f\"   Standard deviation: {l1_distances.std().item():.4f}\")\n",
    "print(f\"   Min: {l1_distances.min().item():.4f}\")\n",
    "print(f\"   Max: {l1_distances.max().item():.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 11: Summary and Best Practices\n",
    "\n",
    "### What Have We Learned?\n",
    "\n",
    "1. **First-Order Data** are approximations of the conditional distribution $p(Y|X)$\n",
    "2. The **FirstOrderDataGenerator** makes it easy to generate these\n",
    "3. Distributions can be **saved and loaded** (JSON format)\n",
    "4. **FirstOrderDataset** combines data with distributions\n",
    "5. **Knowledge Distillation** uses First-Order data as soft targets\n",
    "6. **Coverage** is an important metric for uncertainty quantification\n",
    "\n",
    "### Best Practices\n",
    "\n",
    " **DO:**\n",
    "- Always set model to `eval()` mode before generation\n",
    "- Add metadata when saving\n",
    "- Use `shuffle=False` when generating\n",
    "- Regularly verify distributions (sum = 1.0)\n",
    "\n",
    " **DON'T:**\n",
    "- Don't leave model in training mode\n",
    "- Don't ignore index alignment\n",
    "- Don't save without metadata\n",
    "- Don't forget device consistency\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Try it with your own models and datasets\n",
    "2. Experiment with different `output_mode` settings\n",
    "3. Implement custom `input_getter` functions\n",
    "4. Explore advanced use cases (e.g. Credal Sets)\n",
    "5. Compare different Teacher models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Practice Exercises\n",
    "\n",
    "Try the following extensions:\n",
    "\n",
    "1. **Experiment 1**: Change the Teacher architecture and observe the effects on Coverage\n",
    "2. **Experiment 2**: Use different temperatures for Softmax (`F.softmax(logits/T, dim=-1)`)\n",
    "3. **Experiment 3**: Implement an ensemble approach with multiple Teacher models\n",
    "4. **Experiment 4**: Visualize confidence calibration\n",
    "5. **Experiment 5**: Test with a real dataset (e.g. MNIST or CIFAR-10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Further Resources\n",
    "\n",
    "- **Documentation**: `data_generation_guide.md`\n",
    "- **API Reference**: `api_reference.md`\n",
    "- **Example Script**: `simple_usage.py`\n",
    "- **Tests**: `test_first_order_generator.py`\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
