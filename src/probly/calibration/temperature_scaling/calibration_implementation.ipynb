{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05e005b3-6700-4c1d-8878-51adf94c3241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from scipy.optimize import linprog\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc80f968-e6be-4cda-8351-6e110d2139b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader  = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79409bb4-9695-47a3-89da-813586541d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNet5, self).__init__()\n",
    "\n",
    "        # Original LeNet-5 uses tanh; we keep ReLU for better training stability.\n",
    "        # If you need the exact classical version, I can give that too.\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0)   # 28 → 24\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0)  # 12 → 8\n",
    "    \n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Feature extractor\n",
    "        x = F.relu(self.conv1(x))   # (batch, 6, 24, 24)\n",
    "        x = F.max_pool2d(x, 2)      # → (batch, 6, 12, 12)\n",
    "        \n",
    "        x = F.relu(self.conv2(x))   # (batch, 16, 8, 8)\n",
    "        x = F.max_pool2d(x, 2)      # → (batch, 16, 4, 4)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Classifier\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "\n",
    "        logits = self.fc3(x)        # Raw logits → perfect for temp scaling\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ded5cf8c-5e69-4ce7-9fd4-0fd263a0ebb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = LeNet5(num_classes=10).to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9a21303-c5ff-428b-b544-34fa822fbca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]  Loss: 0.7348  Acc: 0.7150\n",
      "Epoch [2/10]  Loss: 0.4787  Acc: 0.8206\n",
      "Epoch [3/10]  Loss: 0.4008  Acc: 0.8522\n",
      "Epoch [4/10]  Loss: 0.3594  Acc: 0.8677\n",
      "Epoch [5/10]  Loss: 0.3320  Acc: 0.8781\n",
      "Epoch [6/10]  Loss: 0.3100  Acc: 0.8871\n",
      "Epoch [7/10]  Loss: 0.2931  Acc: 0.8932\n",
      "Epoch [8/10]  Loss: 0.2804  Acc: 0.8963\n",
      "Epoch [9/10]  Loss: 0.2685  Acc: 0.9009\n",
      "Epoch [10/10]  Loss: 0.2564  Acc: 0.9044\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10  # you can change this\n",
    "best_acc = 0.0\n",
    "best_model_path = \"best_model_fashion_pth\"\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()          # reset gradients\n",
    "        logits = model(images)         # forward pass\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()                # backward pass\n",
    "        optimizer.step()               # update weights\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = logits.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_acc = correct / total\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]  Loss: {epoch_loss:.4f}  Acc: {epoch_acc:.4f}\")\n",
    "    if epoch_acc > best_acc: \n",
    "        best_acc = epoch_acc\n",
    "        torch.save(model.state_dict(), best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4267fb6-fef4-4be5-9ab7-86e8c5d72181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet5(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9ab66bcb-f907-49a1-a1a1-670d9c9699d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
      "tensor([9, 2, 1, 1, 6, 1, 4, 6, 5, 7, 4, 5, 7, 3, 4, 1, 2, 4, 8, 0, 2, 5, 7, 9,\n",
      "        1, 4, 6, 0, 9, 3, 8, 8, 3, 3, 8, 0, 7, 5, 7, 9, 6, 1, 3, 7, 6, 7, 2, 1,\n",
      "        2, 2, 4, 4, 5, 8, 2, 2, 8, 4, 8, 0, 7, 7, 8, 5])\n"
     ]
    }
   ],
   "source": [
    "print(test_loader.dataset.classes)\n",
    "for image, labels  in test_loader:\n",
    "    print(labels)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9a01733e-97a2-4d46-9f55-6d32ed10342d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities for first batch:\n",
      " tensor([[1.1039e-06, 3.6344e-09, 2.6412e-08, 1.6688e-08, 4.6046e-11, 6.2828e-04,\n",
      "         2.1235e-10, 1.5064e-03, 1.1998e-08, 9.9786e-01],\n",
      "        [8.8461e-06, 4.6992e-09, 9.9929e-01, 1.5312e-07, 2.8559e-04, 5.5941e-12,\n",
      "         4.1592e-04, 2.9225e-13, 8.4764e-07, 2.1216e-10],\n",
      "        [5.1711e-08, 1.0000e+00, 8.1623e-09, 1.6715e-07, 7.6110e-09, 5.6345e-12,\n",
      "         5.2706e-07, 3.1448e-15, 1.2978e-07, 2.4247e-16],\n",
      "        [1.0091e-07, 9.9999e-01, 1.1655e-08, 2.0174e-06, 8.5603e-07, 1.0720e-09,\n",
      "         5.9012e-06, 5.4706e-12, 1.6368e-07, 5.1195e-13],\n",
      "        [3.9880e-02, 3.8795e-07, 6.7004e-03, 7.1930e-04, 7.9000e-04, 2.6957e-07,\n",
      "         9.5181e-01, 3.8908e-09, 9.7684e-05, 3.1690e-06],\n",
      "        [3.3558e-07, 1.0000e+00, 1.6691e-07, 3.6650e-08, 6.1572e-08, 4.0042e-12,\n",
      "         2.4279e-07, 2.4434e-15, 1.3446e-07, 1.4237e-15],\n",
      "        [4.4643e-05, 9.8564e-07, 5.8992e-02, 1.4096e-05, 8.4181e-01, 1.8687e-07,\n",
      "         9.9108e-02, 4.6034e-09, 2.9046e-05, 7.9662e-07],\n",
      "        [2.5068e-04, 3.1070e-07, 5.1465e-03, 1.0499e-04, 2.4633e-02, 7.9606e-07,\n",
      "         9.6981e-01, 3.0499e-07, 3.1552e-05, 2.5925e-05],\n",
      "        [6.3148e-05, 5.1944e-06, 2.3627e-06, 3.4471e-08, 5.1941e-08, 9.9846e-01,\n",
      "         5.8605e-06, 1.2086e-03, 2.4841e-04, 7.9011e-06],\n",
      "        [3.6435e-07, 3.1433e-08, 3.1724e-07, 9.7219e-07, 1.1994e-09, 1.5212e-04,\n",
      "         1.8380e-08, 9.9982e-01, 2.7672e-06, 2.3714e-05],\n",
      "        [6.0864e-05, 3.8885e-05, 2.3602e-02, 4.1737e-06, 9.5175e-01, 7.9590e-07,\n",
      "         2.4507e-02, 4.9301e-08, 3.3846e-05, 2.1466e-06],\n",
      "        [8.6143e-06, 8.3553e-07, 1.1692e-07, 8.4629e-09, 2.9698e-09, 9.9985e-01,\n",
      "         5.5111e-07, 1.3516e-04, 2.3552e-06, 1.5104e-06],\n",
      "        [1.2029e-04, 5.0899e-05, 6.1572e-06, 5.5428e-05, 2.3496e-06, 7.9957e-01,\n",
      "         6.6994e-06, 1.9356e-01, 2.5237e-03, 4.1112e-03],\n",
      "        [5.1056e-05, 8.2323e-04, 4.1635e-05, 9.9850e-01, 2.8889e-04, 6.7590e-08,\n",
      "         9.7160e-05, 1.7247e-09, 2.0013e-04, 9.6974e-09],\n",
      "        [4.7079e-04, 3.6549e-06, 1.4803e-01, 1.3051e-04, 8.1999e-01, 1.0526e-07,\n",
      "         3.0945e-02, 3.8164e-08, 4.1798e-04, 1.1169e-05],\n",
      "        [2.6019e-07, 9.9998e-01, 1.1495e-07, 1.4217e-05, 2.6230e-06, 1.6676e-09,\n",
      "         6.6571e-06, 1.1391e-10, 1.3113e-07, 4.9038e-12],\n",
      "        [4.8788e-04, 6.1278e-06, 9.9558e-01, 5.8310e-06, 4.6534e-04, 1.0223e-08,\n",
      "         3.3773e-03, 1.7927e-09, 7.9568e-05, 4.5842e-08],\n",
      "        [9.0557e-04, 1.2074e-05, 9.7251e-02, 6.1712e-05, 5.4823e-01, 9.6688e-07,\n",
      "         3.5307e-01, 3.6624e-07, 4.4314e-04, 3.0924e-05],\n",
      "        [1.0307e-04, 6.5623e-08, 3.6979e-05, 1.0470e-07, 1.5195e-06, 8.6660e-08,\n",
      "         1.8916e-05, 6.4509e-07, 9.9984e-01, 3.2598e-06],\n",
      "        [9.5502e-01, 1.5104e-06, 7.5395e-04, 1.8345e-04, 1.4417e-05, 2.1718e-07,\n",
      "         4.3726e-02, 6.6270e-11, 2.9965e-04, 1.8923e-07],\n",
      "        [2.6705e-02, 8.4618e-04, 8.3389e-01, 1.0678e-03, 3.1518e-02, 1.0071e-05,\n",
      "         1.0341e-01, 3.0873e-06, 2.4535e-03, 9.8153e-05],\n",
      "        [1.2244e-05, 1.2361e-06, 6.7036e-07, 1.2983e-06, 8.1246e-08, 9.3373e-01,\n",
      "         1.6795e-07, 6.1521e-02, 5.1618e-06, 4.7313e-03],\n",
      "        [7.4175e-07, 8.6713e-09, 4.2052e-07, 5.0018e-07, 5.6240e-10, 2.4721e-04,\n",
      "         1.0913e-08, 9.9955e-01, 1.9413e-06, 1.9837e-04],\n",
      "        [9.2870e-07, 6.8140e-08, 4.4320e-08, 4.8581e-10, 8.0105e-11, 9.9751e-01,\n",
      "         1.2836e-09, 1.0450e-04, 3.8581e-09, 2.3847e-03],\n",
      "        [3.9678e-07, 9.9993e-01, 3.6840e-08, 4.8372e-05, 1.2840e-06, 6.1072e-10,\n",
      "         1.9421e-05, 2.5048e-12, 3.9351e-07, 3.0078e-13],\n",
      "        [1.9863e-03, 8.1728e-05, 2.0336e-01, 7.3433e-04, 5.1812e-01, 2.4595e-06,\n",
      "         2.7550e-01, 1.7678e-07, 1.9218e-04, 1.8597e-05],\n",
      "        [4.3031e-04, 4.3431e-07, 3.2907e-02, 4.7937e-05, 3.0776e-01, 4.2352e-07,\n",
      "         6.5874e-01, 3.8955e-08, 1.0066e-04, 7.5507e-06],\n",
      "        [7.1168e-01, 4.8155e-04, 1.2178e-02, 4.4243e-02, 2.5416e-03, 9.2197e-07,\n",
      "         2.2865e-01, 2.6214e-08, 2.3019e-04, 2.3618e-06],\n",
      "        [1.9057e-06, 4.4692e-08, 2.1052e-07, 5.1996e-07, 1.2739e-09, 3.4132e-04,\n",
      "         3.9812e-09, 4.3551e-03, 2.0412e-07, 9.9530e-01],\n",
      "        [6.0522e-02, 2.7486e-03, 1.7262e-01, 2.1172e-01, 4.2155e-01, 8.5650e-05,\n",
      "         1.1378e-01, 1.8366e-05, 1.6584e-02, 3.6049e-04],\n",
      "        [7.7970e-07, 6.4274e-09, 1.1990e-07, 5.7290e-08, 4.6943e-07, 2.9877e-08,\n",
      "         9.9268e-09, 4.5298e-08, 1.0000e+00, 4.5379e-07],\n",
      "        [7.2558e-06, 4.5492e-09, 4.7860e-08, 6.5109e-07, 4.4433e-07, 4.4511e-05,\n",
      "         6.1858e-08, 7.2766e-07, 9.9995e-01, 2.2755e-08],\n",
      "        [1.9816e-04, 2.5481e-02, 7.7917e-04, 9.5067e-01, 3.8901e-04, 6.4376e-04,\n",
      "         1.7419e-04, 9.3180e-05, 2.1232e-02, 3.4077e-04],\n",
      "        [2.5377e-02, 5.4273e-04, 1.4617e-02, 8.3245e-01, 6.2562e-02, 1.1483e-04,\n",
      "         6.3073e-02, 3.6367e-07, 1.2447e-03, 1.6906e-05],\n",
      "        [6.3123e-04, 7.4565e-08, 3.1826e-05, 7.1541e-07, 1.0162e-05, 7.1449e-06,\n",
      "         1.0544e-06, 1.9218e-07, 9.9932e-01, 6.7814e-09],\n",
      "        [9.6393e-01, 2.7502e-07, 5.7848e-04, 2.6621e-05, 5.5860e-06, 3.9682e-09,\n",
      "         3.5445e-02, 6.1896e-12, 1.8560e-05, 4.2413e-08],\n",
      "        [4.5952e-07, 1.7773e-09, 5.4611e-07, 4.0190e-07, 5.0498e-10, 2.5453e-05,\n",
      "         5.6566e-09, 9.9995e-01, 2.9778e-06, 1.8196e-05],\n",
      "        [1.5062e-05, 8.3065e-07, 7.1099e-07, 1.1773e-08, 2.3142e-08, 9.9916e-01,\n",
      "         7.8051e-07, 7.6783e-04, 7.8740e-06, 4.3887e-05],\n",
      "        [2.7905e-08, 1.3561e-09, 1.5170e-08, 4.8805e-08, 3.3710e-11, 6.2744e-05,\n",
      "         9.6749e-10, 9.9993e-01, 2.1806e-07, 2.7020e-06],\n",
      "        [2.4327e-08, 7.6014e-11, 6.3578e-10, 4.4500e-09, 1.7885e-12, 1.1608e-05,\n",
      "         4.0657e-12, 4.5484e-04, 1.7719e-10, 9.9953e-01],\n",
      "        [6.0058e-01, 2.1369e-06, 1.2948e-03, 9.3703e-05, 1.3656e-04, 1.6365e-07,\n",
      "         3.9780e-01, 4.0934e-10, 9.2114e-05, 2.2123e-06],\n",
      "        [2.0804e-08, 1.0000e+00, 4.0751e-09, 2.2532e-07, 2.7348e-08, 4.5775e-10,\n",
      "         3.1653e-06, 1.0043e-11, 1.3051e-06, 1.8984e-14],\n",
      "        [2.0262e-01, 2.0414e-03, 4.2715e-02, 1.3558e-01, 5.9223e-02, 2.9526e-05,\n",
      "         5.5196e-01, 2.8380e-06, 5.7149e-03, 1.1135e-04],\n",
      "        [4.7794e-05, 1.2538e-08, 1.0474e-06, 1.8867e-06, 4.4479e-10, 5.2989e-04,\n",
      "         4.0442e-08, 4.1475e-01, 3.8779e-08, 5.8467e-01],\n",
      "        [4.4164e-04, 1.5771e-06, 9.6264e-03, 1.9933e-04, 1.1930e-01, 3.9726e-07,\n",
      "         8.7031e-01, 1.8571e-07, 9.4352e-05, 2.2619e-05],\n",
      "        [1.0615e-05, 9.1010e-08, 1.2585e-06, 3.4270e-05, 9.1687e-09, 7.6735e-04,\n",
      "         6.2283e-08, 9.4345e-01, 1.7877e-06, 5.5733e-02],\n",
      "        [2.8517e-02, 8.9799e-03, 6.8020e-01, 6.5899e-03, 5.3601e-02, 1.5905e-04,\n",
      "         2.0870e-01, 3.7181e-05, 1.2946e-02, 2.6945e-04],\n",
      "        [3.9956e-06, 9.9964e-01, 8.7412e-07, 1.4885e-04, 1.1638e-05, 1.0866e-07,\n",
      "         1.4758e-04, 6.6835e-09, 4.3207e-05, 2.2236e-10],\n",
      "        [2.3588e-03, 1.6825e-05, 8.0808e-01, 3.7892e-05, 5.9647e-02, 7.7696e-06,\n",
      "         1.2957e-01, 1.0413e-07, 2.6694e-04, 1.9356e-05],\n",
      "        [7.2603e-03, 2.3480e-04, 1.9028e-01, 5.7092e-03, 3.9390e-02, 2.8921e-05,\n",
      "         7.5554e-01, 3.8967e-06, 1.4300e-03, 1.2750e-04],\n",
      "        [4.3688e-04, 2.5562e-05, 3.1292e-02, 1.3568e-05, 9.1198e-01, 3.0509e-07,\n",
      "         5.6093e-02, 4.1145e-08, 1.5184e-04, 4.6124e-06],\n",
      "        [6.0091e-04, 2.7523e-04, 4.1036e-01, 3.4461e-05, 3.7463e-01, 1.6197e-05,\n",
      "         2.1393e-01, 3.6923e-07, 1.4318e-04, 8.4615e-06],\n",
      "        [1.6376e-04, 2.2615e-05, 1.1532e-05, 1.1484e-07, 1.6803e-07, 9.9932e-01,\n",
      "         1.8322e-05, 2.4529e-04, 9.0915e-05, 1.3131e-04],\n",
      "        [1.0182e-01, 1.1374e-02, 6.1487e-04, 7.9006e-04, 1.7064e-04, 5.2598e-05,\n",
      "         9.9943e-02, 1.8402e-06, 7.8519e-01, 4.3371e-05],\n",
      "        [2.4062e-04, 1.2501e-06, 9.6951e-01, 1.3259e-05, 2.8983e-02, 5.2650e-09,\n",
      "         1.2288e-03, 1.8172e-10, 1.9410e-05, 6.9210e-08],\n",
      "        [1.5024e-02, 7.5305e-06, 9.0987e-01, 8.0785e-05, 1.3671e-03, 1.8669e-07,\n",
      "         7.3302e-02, 5.1736e-09, 3.4765e-04, 1.0836e-06],\n",
      "        [4.8556e-04, 1.0129e-07, 2.1603e-05, 6.5787e-08, 8.9543e-07, 1.0989e-07,\n",
      "         4.4748e-05, 1.0145e-06, 9.9944e-01, 3.4113e-06],\n",
      "        [2.0682e-04, 9.9351e-07, 3.5780e-02, 7.2527e-05, 4.9017e-01, 3.2505e-07,\n",
      "         4.7372e-01, 4.6832e-08, 4.2815e-05, 6.3003e-06],\n",
      "        [8.9782e-05, 5.0363e-08, 1.7933e-05, 9.4537e-08, 2.2682e-06, 9.9825e-07,\n",
      "         2.0101e-05, 2.5834e-06, 9.9985e-01, 1.2187e-05],\n",
      "        [9.6852e-01, 2.0971e-08, 1.1085e-04, 4.1099e-06, 5.7444e-07, 8.5367e-11,\n",
      "         3.1362e-02, 1.0283e-13, 8.7658e-07, 3.1081e-09],\n",
      "        [2.1792e-06, 2.2086e-08, 1.5775e-06, 1.8406e-06, 4.8153e-09, 1.0592e-04,\n",
      "         8.7082e-08, 9.9978e-01, 1.7764e-05, 9.0619e-05],\n",
      "        [1.6803e-06, 1.0010e-07, 2.3599e-07, 3.6745e-06, 7.6934e-09, 2.0342e-02,\n",
      "         8.4303e-09, 9.7063e-01, 1.0718e-06, 9.0208e-03],\n",
      "        [1.4179e-05, 4.1824e-07, 3.8222e-05, 4.2478e-05, 4.0181e-05, 1.1672e-04,\n",
      "         1.9120e-06, 2.1749e-04, 9.9909e-01, 4.4112e-04],\n",
      "        [3.5310e-07, 4.5099e-09, 1.4596e-09, 3.5733e-11, 4.4829e-11, 9.9999e-01,\n",
      "         6.9678e-09, 1.2715e-05, 4.3400e-08, 3.8249e-07]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.eval()  # evaluation mode\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    images = images.to(device)\n",
    "\n",
    "    with torch.no_grad():  # no gradients needed\n",
    "        logits = model(images)            # raw outputs from the model\n",
    "        probs = F.softmax(logits, dim=1)  # convert logits to probabilities\n",
    "\n",
    "    val_probs = probs\n",
    "    print(\"Probabilities for first batch:\\n\", probs)\n",
    "    break  # only first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c9ba6ffc-9991-4258-ae20-0a5207f2b2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels (indices): tensor([9, 2, 1, 1, 6, 1, 4, 6, 5, 7, 4, 5, 5, 3, 4, 1, 2, 4, 8, 0, 2, 5, 7, 5,\n",
      "        1, 4, 6, 0, 9, 4, 8, 8, 3, 3, 8, 0, 7, 5, 7, 9, 0, 1, 6, 9, 6, 7, 2, 1,\n",
      "        2, 6, 4, 2, 5, 8, 2, 2, 8, 4, 8, 0, 7, 7, 8, 5])\n",
      "True labels (indices)     : tensor([9, 2, 1, 1, 6, 1, 4, 6, 5, 7, 4, 5, 7, 3, 4, 1, 2, 4, 8, 0, 2, 5, 7, 9,\n",
      "        1, 4, 6, 0, 9, 3, 8, 8, 3, 3, 8, 0, 7, 5, 7, 9, 6, 1, 3, 7, 6, 7, 2, 1,\n",
      "        2, 2, 4, 4, 5, 8, 2, 2, 8, 4, 8, 0, 7, 7, 8, 5])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# iterate over test_loader (or take one batch)\n",
    "for images, labels in test_loader:\n",
    "    images, labels = images.to(device), labels.to(device)  # move to device\n",
    "    \n",
    "    with torch.no_grad():  # no need to compute gradients for inference\n",
    "        outputs = model(images)              # forward pass\n",
    "        _, predicted = torch.max(outputs, 1)  # get predicted class index\n",
    "\n",
    "    print(\"Predicted labels (indices):\", predicted)\n",
    "    print(\"True labels (indices)     :\", labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "102aebeb-c091-41a8-983f-bb75f44304e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_test = []\n",
    "for images, labels in test_loader: \n",
    "    save_test.append((images, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "51ccfce2-910f-4d7d-93cc-f7bae7b5717c",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_test_images = save_test[2][0]\n",
    "to_test_labels = save_test[2][1]\n",
    "with torch.no_grad():  # no gradients needed\n",
    "    logits = model(to_test_images)            # raw outputs from the model\n",
    "    neu_probs = F.softmax(logits, dim=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "12b6a345-7e65-4788-ae10-ffa8b0bfdcdf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.7172e-06, 9.9997e-01, 9.6320e-08, 1.0118e-05, 3.9442e-07, 6.6034e-10,\n",
       "         2.1184e-05, 3.4099e-12, 2.7518e-07, 7.0176e-13],\n",
       "        [6.8104e-06, 8.3936e-08, 1.1518e-07, 4.3987e-09, 5.4663e-10, 9.9975e-01,\n",
       "         1.2813e-07, 2.3185e-04, 2.2901e-06, 5.0626e-06],\n",
       "        [1.4861e-04, 3.2108e-05, 3.6833e-02, 3.7079e-05, 9.6044e-01, 3.5373e-07,\n",
       "         2.1980e-03, 3.7740e-08, 3.0238e-04, 6.1710e-06],\n",
       "        [3.9315e-08, 9.9999e-01, 1.9230e-08, 3.3926e-07, 1.3222e-06, 3.5385e-10,\n",
       "         2.9974e-06, 5.8609e-12, 4.8709e-07, 1.0130e-13],\n",
       "        [1.2231e-06, 5.6793e-09, 6.7388e-09, 2.0214e-08, 1.0369e-11, 2.0731e-03,\n",
       "         3.8526e-10, 8.5274e-04, 8.9060e-10, 9.9707e-01],\n",
       "        [1.3435e-05, 9.9996e-01, 4.2168e-07, 7.1040e-06, 1.0235e-06, 1.4769e-09,\n",
       "         1.9753e-05, 1.0577e-12, 1.6836e-06, 8.6818e-13],\n",
       "        [4.6155e-04, 3.7513e-05, 8.8781e-05, 2.9047e-06, 2.4899e-05, 1.6834e-06,\n",
       "         3.7662e-04, 2.4130e-06, 9.9897e-01, 2.8674e-05],\n",
       "        [1.3226e-04, 2.5597e-08, 1.0618e-01, 7.6751e-06, 1.4825e-01, 3.7725e-08,\n",
       "         7.4535e-01, 6.2732e-09, 8.1750e-05, 4.0392e-06],\n",
       "        [1.3205e-03, 8.5402e-08, 9.3405e-01, 7.2688e-05, 1.1680e-03, 3.0266e-08,\n",
       "         6.3336e-02, 4.7366e-10, 5.0093e-05, 2.0650e-07],\n",
       "        [3.9885e-09, 1.0000e+00, 2.0992e-09, 7.2918e-08, 1.2931e-08, 8.5433e-11,\n",
       "         1.0534e-06, 1.7736e-12, 8.3133e-07, 2.1011e-15],\n",
       "        [4.9004e-05, 4.5467e-08, 9.9249e-01, 2.7170e-06, 6.7476e-03, 3.8272e-10,\n",
       "         7.0416e-04, 8.1945e-12, 4.9881e-06, 5.6843e-09],\n",
       "        [8.5104e-06, 8.0728e-08, 5.6112e-07, 7.6218e-10, 1.7418e-08, 9.9996e-01,\n",
       "         7.8995e-07, 1.8200e-05, 3.5741e-07, 1.0928e-05],\n",
       "        [2.6080e-08, 1.0000e+00, 1.0793e-08, 2.3081e-07, 8.9863e-08, 3.9231e-11,\n",
       "         1.2949e-06, 9.8394e-13, 1.2809e-07, 1.7609e-14],\n",
       "        [4.4806e-01, 1.2246e-04, 7.1199e-02, 1.1455e-02, 7.2026e-04, 6.8735e-06,\n",
       "         4.6805e-01, 2.8580e-09, 3.9291e-04, 6.6933e-07],\n",
       "        [9.7832e-01, 8.4028e-08, 9.2021e-05, 2.6442e-05, 2.3692e-06, 5.3899e-10,\n",
       "         2.1558e-02, 2.3126e-13, 5.3421e-06, 2.5979e-09],\n",
       "        [9.9670e-01, 9.2583e-08, 4.0933e-04, 6.8902e-06, 9.0295e-07, 1.0844e-09,\n",
       "         2.8653e-03, 4.7113e-13, 1.3559e-05, 3.9519e-09],\n",
       "        [8.5350e-07, 9.9997e-01, 1.0024e-07, 5.6044e-06, 1.5141e-06, 5.0399e-09,\n",
       "         1.9739e-05, 1.8588e-11, 4.4080e-06, 4.4861e-12],\n",
       "        [1.2140e-01, 3.2140e-04, 2.1773e-01, 5.9235e-03, 1.5442e-03, 2.4407e-05,\n",
       "         6.5114e-01, 2.8153e-07, 1.8977e-03, 1.9993e-05],\n",
       "        [7.8889e-06, 9.9977e-01, 1.0245e-06, 8.2914e-05, 5.1099e-05, 3.6525e-08,\n",
       "         8.4423e-05, 1.2287e-09, 1.2902e-06, 5.6891e-10],\n",
       "        [2.5871e-02, 1.0460e-01, 5.1883e-03, 7.1893e-01, 4.1322e-02, 1.2128e-04,\n",
       "         3.2937e-02, 2.0130e-06, 7.1009e-02, 2.1239e-05],\n",
       "        [3.9939e-04, 1.0506e-06, 9.9651e-01, 4.3849e-06, 8.6279e-04, 2.3837e-09,\n",
       "         2.1974e-03, 1.7213e-10, 2.6264e-05, 2.3664e-08],\n",
       "        [7.4134e-03, 3.0929e-05, 7.2711e-01, 4.5322e-03, 3.9477e-02, 1.5864e-05,\n",
       "         2.1982e-01, 5.8189e-07, 1.5400e-03, 5.3646e-05],\n",
       "        [1.8448e-02, 1.7551e-04, 1.2624e-01, 6.5872e-01, 7.2019e-02, 5.0517e-05,\n",
       "         1.1881e-01, 3.6719e-06, 5.4932e-03, 3.6297e-05],\n",
       "        [1.7650e-03, 5.9459e-04, 5.1725e-02, 2.5472e-03, 6.9855e-01, 3.3666e-05,\n",
       "         2.2499e-01, 2.2856e-05, 1.9513e-02, 2.5690e-04],\n",
       "        [9.4327e-08, 9.9999e-01, 1.9720e-08, 2.3419e-06, 5.7270e-07, 7.9643e-11,\n",
       "         3.1988e-06, 4.1676e-12, 9.3322e-08, 3.7760e-13],\n",
       "        [1.3378e-02, 2.6850e-03, 5.1874e-02, 3.0920e-01, 5.2090e-01, 1.0670e-04,\n",
       "         9.2881e-02, 8.8289e-06, 8.7400e-03, 2.2664e-04],\n",
       "        [1.0013e-05, 4.9764e-07, 2.5960e-07, 9.2061e-09, 7.1544e-09, 9.9959e-01,\n",
       "         3.4086e-07, 3.5392e-04, 2.7432e-06, 3.9143e-05],\n",
       "        [3.6030e-01, 4.0870e-05, 2.5096e-01, 3.0548e-03, 2.7249e-04, 4.3300e-06,\n",
       "         3.8509e-01, 4.3986e-09, 2.7106e-04, 1.2675e-06],\n",
       "        [3.6415e-03, 3.0444e-05, 1.9948e-02, 9.5676e-02, 5.8348e-01, 8.5198e-06,\n",
       "         2.9558e-01, 1.6653e-06, 1.5510e-03, 7.7794e-05],\n",
       "        [2.6879e-06, 1.5252e-07, 6.5566e-07, 1.2327e-06, 7.0471e-09, 6.7705e-03,\n",
       "         8.7759e-08, 9.9313e-01, 1.6015e-05, 7.3621e-05],\n",
       "        [1.1483e-08, 5.3622e-11, 1.5543e-10, 6.8406e-10, 2.5229e-13, 1.1944e-05,\n",
       "         8.4252e-13, 7.8810e-05, 6.8054e-11, 9.9991e-01],\n",
       "        [1.3827e-03, 2.3657e-04, 1.1170e-04, 9.9547e-01, 1.9504e-03, 3.3192e-08,\n",
       "         7.3668e-04, 3.3631e-11, 1.1264e-04, 1.4826e-08],\n",
       "        [1.1708e-06, 1.0544e-07, 6.6111e-07, 3.1604e-06, 1.9435e-09, 1.7496e-03,\n",
       "         1.6662e-08, 9.9680e-01, 5.8121e-07, 1.4427e-03],\n",
       "        [1.9838e-05, 3.1049e-09, 9.9923e-01, 5.3762e-07, 2.8581e-04, 3.1353e-11,\n",
       "         4.6719e-04, 6.6732e-13, 1.5339e-06, 2.0695e-10],\n",
       "        [2.0810e-02, 9.3582e-03, 1.2886e-04, 9.5406e-01, 7.5136e-04, 3.0826e-06,\n",
       "         1.4880e-02, 2.8672e-08, 1.1810e-05, 1.8714e-06],\n",
       "        [5.4476e-07, 1.8952e-09, 1.8113e-08, 2.6340e-09, 2.0079e-11, 2.8425e-03,\n",
       "         7.2759e-11, 8.0128e-04, 1.4772e-08, 9.9636e-01],\n",
       "        [9.8681e-01, 1.3349e-07, 4.8222e-05, 1.3841e-05, 6.7208e-07, 1.2918e-10,\n",
       "         1.3127e-02, 1.4723e-14, 7.0791e-07, 6.3501e-10],\n",
       "        [7.5784e-09, 3.1809e-11, 2.0841e-10, 4.0596e-10, 5.6170e-13, 8.8469e-06,\n",
       "         6.2583e-13, 1.6243e-04, 5.1751e-10, 9.9983e-01],\n",
       "        [1.3620e-05, 1.7894e-06, 4.2079e-01, 1.2278e-07, 5.7847e-01, 1.0169e-09,\n",
       "         7.1353e-04, 1.8718e-11, 3.4668e-06, 2.7554e-08],\n",
       "        [8.5029e-06, 1.9613e-07, 9.9418e-07, 3.5366e-05, 1.2538e-08, 7.3202e-04,\n",
       "         8.9936e-08, 7.8396e-01, 3.3357e-06, 2.1525e-01],\n",
       "        [2.1240e-03, 1.4932e-04, 3.7118e-02, 2.9084e-03, 9.3370e-01, 2.6727e-06,\n",
       "         1.3978e-02, 1.2987e-06, 9.8942e-03, 1.2457e-04],\n",
       "        [7.9199e-04, 2.5554e-05, 9.9267e-01, 6.7636e-06, 3.0517e-03, 2.6040e-08,\n",
       "         3.2824e-03, 5.0176e-09, 1.7516e-04, 2.4903e-07],\n",
       "        [5.8378e-01, 9.7830e-06, 1.6966e-03, 8.4535e-04, 2.9137e-04, 5.5956e-06,\n",
       "         4.1210e-01, 1.1546e-09, 1.2714e-03, 2.2237e-06],\n",
       "        [2.0945e-05, 1.6220e-06, 8.3672e-07, 2.4194e-08, 1.5011e-08, 9.9772e-01,\n",
       "         1.3920e-06, 2.1912e-03, 4.3868e-05, 1.6981e-05],\n",
       "        [3.8932e-03, 2.0528e-04, 2.5228e-01, 7.3350e-04, 3.0441e-01, 3.6700e-05,\n",
       "         4.3649e-01, 3.2386e-06, 1.7849e-03, 1.6343e-04],\n",
       "        [1.8374e-08, 1.0000e+00, 6.1763e-09, 1.2580e-07, 5.8067e-07, 2.2571e-10,\n",
       "         1.9758e-06, 2.1885e-12, 3.2573e-07, 3.8073e-14],\n",
       "        [3.6308e-04, 1.7021e-06, 9.8758e-01, 1.3857e-06, 4.3462e-03, 5.4334e-09,\n",
       "         7.6595e-03, 1.0435e-10, 4.4019e-05, 3.0043e-08],\n",
       "        [1.2579e-04, 9.9940e-01, 2.6436e-05, 1.2312e-05, 4.1020e-05, 2.8227e-07,\n",
       "         2.1783e-04, 1.8937e-09, 1.7238e-04, 4.4704e-09],\n",
       "        [7.7215e-04, 1.4149e-05, 2.1197e-03, 9.8887e-01, 5.9281e-03, 1.8286e-07,\n",
       "         2.1528e-03, 2.7559e-09, 1.4031e-04, 4.3738e-08],\n",
       "        [6.9231e-01, 2.4600e-07, 1.7658e-04, 3.8894e-05, 2.0602e-05, 2.5870e-08,\n",
       "         3.0741e-01, 2.5923e-11, 3.9134e-05, 1.7439e-07],\n",
       "        [2.0624e-09, 2.4931e-12, 7.8600e-12, 1.1127e-11, 6.9645e-15, 2.2156e-05,\n",
       "         1.7688e-14, 3.2274e-05, 4.3873e-12, 9.9995e-01],\n",
       "        [1.5061e-07, 9.9998e-01, 3.0529e-08, 2.7573e-06, 4.0271e-07, 1.9116e-09,\n",
       "         1.5788e-05, 1.2783e-10, 5.6695e-07, 1.0018e-12],\n",
       "        [9.9841e-01, 1.4590e-08, 2.7013e-04, 2.1122e-06, 2.0045e-07, 2.0509e-10,\n",
       "         1.3107e-03, 3.9590e-14, 1.0919e-05, 8.7398e-10],\n",
       "        [1.0650e-08, 3.3248e-10, 1.2926e-09, 1.1614e-08, 5.3649e-12, 1.2822e-04,\n",
       "         2.7040e-12, 2.3423e-04, 1.2127e-09, 9.9964e-01],\n",
       "        [1.6071e-02, 1.9508e-05, 4.5225e-03, 9.4253e-01, 3.0702e-02, 1.0175e-07,\n",
       "         6.1047e-03, 4.1593e-11, 4.7076e-05, 4.3546e-09],\n",
       "        [1.5744e-01, 2.7924e-05, 6.7845e-03, 1.6766e-03, 2.1621e-04, 2.0365e-07,\n",
       "         8.3348e-01, 1.3015e-08, 3.7895e-04, 6.1329e-07],\n",
       "        [1.3815e-07, 8.2584e-09, 3.1826e-08, 4.0112e-07, 1.9379e-10, 1.1456e-03,\n",
       "         2.1250e-09, 9.9883e-01, 3.8854e-07, 2.0510e-05],\n",
       "        [2.5322e-08, 5.2942e-11, 1.3434e-10, 1.7950e-09, 3.9390e-13, 2.7116e-06,\n",
       "         6.6571e-12, 1.0434e-03, 9.9240e-10, 9.9895e-01],\n",
       "        [3.8449e-07, 6.3998e-09, 3.5984e-08, 6.2502e-08, 2.0879e-10, 1.9086e-04,\n",
       "         2.5111e-10, 6.4691e-04, 1.4883e-08, 9.9916e-01],\n",
       "        [7.3860e-05, 4.6626e-06, 2.5820e-01, 2.7305e-06, 7.3902e-01, 2.1380e-08,\n",
       "         2.6550e-03, 1.1686e-09, 3.9104e-05, 6.0201e-07],\n",
       "        [6.6322e-05, 1.0446e-05, 1.4976e-01, 1.0396e-06, 8.4589e-01, 1.0359e-08,\n",
       "         4.2372e-03, 1.1276e-09, 3.9753e-05, 5.0832e-07],\n",
       "        [2.4700e-08, 5.7168e-09, 1.4867e-08, 1.6579e-07, 3.7840e-11, 5.8282e-04,\n",
       "         4.1777e-10, 9.9941e-01, 1.0941e-07, 9.9305e-06],\n",
       "        [2.6115e-05, 9.9969e-01, 1.1332e-06, 5.5016e-05, 8.0624e-05, 3.1530e-08,\n",
       "         1.4046e-04, 3.6925e-10, 3.9573e-06, 6.2216e-10],\n",
       "        [6.5802e-04, 5.3162e-07, 9.6343e-01, 1.9548e-05, 6.6375e-04, 2.0066e-08,\n",
       "         3.5169e-02, 1.0489e-09, 5.4622e-05, 9.3377e-08]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neu_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8d1971ee-90f7-4172-8c06-b2ca8dc284e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Implementation of temperature scaling in torch.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Implementation of temperature scaling in torch.\"\"\"\n",
    "\n",
    "# Suppose val_probs, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "61ed6dfe-57fd-4657-afa2-89742fcad3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_logits = torch.log(val_probs + 1e-12)  # pseudo logits\n",
    "val_logits = logits\n",
    "val_labels = labels\n",
    "\n",
    "\n",
    "class TempScaler(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.temperature = nn.Parameter(torch.ones(1))\n",
    "        \n",
    "    def forward(self, logits):\n",
    "        return logits / self.temperature\n",
    "\n",
    "def calibrate_temperature_grid(logits, labels, temp_min=0.5, temp_max=5.0, num_steps=100):\n",
    "    \"\"\"\n",
    "    Find optimal temperature T using grid search\n",
    "    \"\"\"\n",
    "    scaler = TempScaler()  # use original module\n",
    "    best_temp = 1.0\n",
    "    best_loss = float('inf')\n",
    "    labels = labels.long()\n",
    "    \n",
    "    temperatures = torch.linspace(temp_min, temp_max, num_steps)\n",
    "    \n",
    "    for T in temperatures:\n",
    "        # improve the scaler's temperature\n",
    "        scaler.temperature.data.fill_(T)\n",
    "        scaled_logits = scaler.forward(logits)\n",
    "        loss = F.cross_entropy(scaled_logits, labels)\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_temp = T.item()\n",
    "    \n",
    "    # set final optimal temperature\n",
    "    scaler.temperature.data.fill_(best_temp)\n",
    "    print(best_temp)\n",
    "    return scaler\n",
    "\n",
    "\n",
    "def calibrate_temperature(logits, labels, max_iter=50, lr=0.01):\n",
    "    scaler = TempScaler()\n",
    "    optimizer = torch.optim.LBFGS([scaler.temperature], lr=lr, max_iter=max_iter)\n",
    "\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        scaled_logits = scaler(logits)\n",
    "        loss = nn.functional.cross_entropy(scaled_logits, labels)\n",
    "        loss.backward()\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)\n",
    "    return scaler\n",
    "\n",
    "\n",
    "def apply_temperature_scaling_probs(probs, scaler):\n",
    "    pseudo_logits = torch.log(probs + 1e-12)       # convert probabilities to pseudo logits\n",
    "    scaled_logits = scaler(pseudo_logits)          # divide by learned temperature\n",
    "    calibrated_probs = torch.softmax(scaled_logits, dim=1)\n",
    "    return calibrated_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b4c5f84e-056a-4b85-9f99-d033891ae4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0909091234207153\n"
     ]
    }
   ],
   "source": [
    "test_scaler = calibrate_temperature_grid(val_logits, val_labels)\n",
    "calibrated_probs = apply_temperature_scaling_probs(neu_probs, test_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e0f136c7-e7c1-4560-bcea-bf19ae14ec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scaler_2 = calibrate_temperature(val_logits, val_labels)\n",
    "calibrated_probs_2 = apply_temperature_scaling_probs(neu_probs, test_scaler_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a0524180-ac80-404c-9cf9-521fcff06489",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROUND_DECIMALS = 3  # Number of decimals to round probabilities to when computing coverage, efficiency, etc.\n",
    "\n",
    "\n",
    "def expected_calibration_error(probs: np.ndarray, labels: np.ndarray, num_bins: int = 10) -> float:\n",
    "    \"\"\"Compute the expected calibration error (ECE) of the predicted probabilities :cite:`guoOnCalibration2017`.\n",
    "\n",
    "    Args:\n",
    "        probs: The predicted probabilities as an array of shape (n_instances, n_classes).\n",
    "        labels: The true labels as an array of shape (n_instances,).\n",
    "        num_bins: The number of bins to use for the calibration error calculation.\n",
    "\n",
    "    Returns:\n",
    "        ece: The expected calibration error.\n",
    "    \"\"\"\n",
    "    confs = np.max(probs, axis=1)\n",
    "    preds = np.argmax(probs, axis=1)\n",
    "    bins = np.linspace(0, 1, num_bins + 1, endpoint=True)\n",
    "    bin_indices = np.digitize(confs, bins, right=True) - 1\n",
    "    num_instances = probs.shape[0]\n",
    "    ece = 0\n",
    "    for i in range(num_bins):\n",
    "        _bin = np.where(bin_indices == i)[0]\n",
    "        # check if bin is empty\n",
    "        if _bin.shape[0] == 0:\n",
    "            continue\n",
    "        acc_bin = np.mean(preds[_bin] == labels[_bin])\n",
    "        conf_bin = np.mean(confs[_bin])\n",
    "        weight = _bin.shape[0] / num_instances\n",
    "        ece += weight * np.abs(acc_bin - conf_bin)\n",
    "    return float(ece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2a45b9c2-11a6-4fd4-b271-d212fc862a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7252609780989587\n",
      "0.7330209827050567\n"
     ]
    }
   ],
   "source": [
    "print(expected_calibration_error(neu_probs.cpu().numpy(), val_labels.cpu().numpy()))\n",
    "print(expected_calibration_error(calibrated_probs.detach().cpu().numpy(), val_labels.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4403556e-e15c-4a72-9fb6-b5f7e3325877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7252609780989587\n",
      "0.7225449196994305\n"
     ]
    }
   ],
   "source": [
    "print(expected_calibration_error(neu_probs.cpu().numpy(), val_labels.cpu().numpy()))\n",
    "print(expected_calibration_error(calibrated_probs_2.detach().cpu().numpy(), val_labels.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a96e600-5cd9-4916-ae1d-3ed989bb1ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752f3751-ef6b-4728-81e5-3473d73e5c80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13",
   "language": "python",
   "name": "python313"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
