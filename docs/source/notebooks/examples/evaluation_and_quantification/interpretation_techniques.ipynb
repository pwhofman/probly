{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f1db370",
   "metadata": {},
   "source": [
    "# Interpretation techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13070549",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39b8a44",
   "metadata": {},
   "source": [
    "Quantifying a model's uncertainty is only the first step; the true value comes from interpreting what that uncertainty means. \n",
    "A single score tells us if a model is uncertain, but a deeper analysis can tell us why. \n",
    "The `probly.quantification` module provides a suite of functions designed to facilitate this interpretation.\n",
    "\n",
    "The key technique `probly` supports is **decomposition of uncertainty**. \n",
    "For sampling-based methods (like MC-Dropout or Ensembles), the library provides functions to separate total predictive uncertainty into two components:\n",
    "\n",
    "- **Aleatoric uncertainty** – captures the inherent noise and ambiguity in the data. \n",
    "  Can be calculated with `conditional_entropy` (classification) or `expected_conditional_variance` (regression).\n",
    "- **Epistemic uncertainty** – represents the model's own ignorance or lack of knowledge. \n",
    "  Can be calculated with `mutual_information` (both tasks).\n",
    "\n",
    "Distinguishing these is critical for debugging and building trust. \n",
    "High aleatoric uncertainty may be irreducible due to noisy data, while high epistemic uncertainty signals the model is “out of its depth” on unfamiliar inputs. \n",
    "This information can guide **out-of-distribution detection** or **active learning**, leading to more robust and reliable systems.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
