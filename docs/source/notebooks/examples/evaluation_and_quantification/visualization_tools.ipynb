{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4577e588",
   "metadata": {},
   "source": [
    "# Visualisation Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afcd127",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e08670b",
   "metadata": {},
   "source": [
    "While numerical metrics provide a quantitative measure of uncertainty, visualizations offer an intuitive, qualitative understanding of a model's predictions. A single plot can often reveal the nature of a model's confidence in a way that is difficult to grasp from numbers alone. To this end, probly provides specialized tools for plotting predictive distributions, focusing on classification tasks.\n",
    "\n",
    "Currently, the plotting module is designed to visualize the outputs of 3-class classifiers on a 2D simplex. This is a triangle where each corner represents 100% confidence in one of the three classes.\n",
    "\n",
    "The library provides two main functions for this:\n",
    "\n",
    "    The Simplex Plot is used to scatter individual predictions on this triangle, allowing you to see the distribution of a model's predictions across a dataset.\n",
    "\n",
    "    The Credal Set Plot is a more advanced tool for visualizing the uncertainty of a single prediction derived from multiple samples (e.g., from an ensemble or MC-Dropout). It plots the region of all possible probability distributions consistent with the model's outputs. A small, tight region indicates high confidence, while a large, spread-out region signifies high uncertainty.\n",
    "\n",
    "These tools are essential for the qualitative interpretation and debugging of classification uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaede28",
   "metadata": {},
   "source": [
    "## 0. First things first:\n",
    "All modules mentioned here have more in depth notebooks to explain more detailed, how they are working.\n",
    "You can find them under the section further reading.\n",
    "\n",
    "## 1. What can you visualize in probly? \n",
    "### Credal Sets: <br>\n",
    "Based on the number of classes given in the visualizer, the `credal` package chooses between those three modules:\n",
    "\n",
    "- **Intervall plot** / `plot_2d`: Quick sanity checks for two-feature views (or 2D embeddings): cluster overlap, separation, and how uncertainty behaves in feature space.\n",
    "\n",
    "- **Ternary plot** / `plot_3d`: Visualization of **3-class probability vectors** on a simplex: highlights confident regions (near corners) vs. ambiguous regions (towards the center / edges).\n",
    "\n",
    "- **Spider plot** / `plot_multid`: Multi-class probability diagnostics when `n_classes > 3`: compact views to spot systematic uncertainty patterns across many classes.\n",
    "\n",
    "\n",
    "### Specialized plots:<br>\n",
    "Upon our credal package, you can also visualize special plots:\n",
    "- `plot_uncertainty`: Visualizes **margin-based confidende** between two 2D clusters by mapping the SVM decision margin into a smooth field.\n",
    "\n",
    "- `plot_dirichlet`: Plots **Dirichlet density contours** on the ternary simplex to illustrate “distributions over probabilities” (concentration, symmetry, and skew).\n",
    "\n",
    "- `plot_coverage_efficency`: Shows the **trade-off between empirical coverage and prediction set size** across confidence levels (coverage vs. efficiency on a dual-axis view)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5dff97",
   "metadata": {},
   "source": [
    "## 2. Imports\n",
    "To demonstrate, first let's import the following modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44119eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from probly.visualization.dirichlet.dirichlet_visualization import create_dirichlet_plot\n",
    "\n",
    "from probly.visualization.credal.credal_visualization import create_credal_plot\n",
    "from credal_visualization import create_credal_plot\n",
    "from probly.visualization.clustermargin.clustervisualizer import plot_uncertainty\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    from probly.visualization.efficiency.plot_coverage_efficiency import CoverageEfficiencyVisualizer\n",
    "except ImportError:\n",
    "    from plot_coverage_final import CoverageEfficiencyVisualizer\n",
    "print(\"Imports successfully loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99617098",
   "metadata": {},
   "source": [
    "## 3. Credal\n",
    "**What the package does:**<br>\n",
    "It takes an array of probability vectors (each summing to 1) and visualizes them as a credal set:\n",
    "- **2 classes:** interval band on a line\n",
    "- **3 classes:** ternary simpplotlex with convex hull\n",
    "- **more than 3** classes: radar/spider plot with min–max envelope\n",
    "The public entry point is `create_credal_plot()`, which delegates to `dispatch_plot()` based on the number of classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b87bc7",
   "metadata": {},
   "source": [
    "### 3.1 Public API `credal_visualization.py`\n",
    "This module provides the single public entry point for creating credal-set visualizations across different class counts (2D / 3D / multi-class).\n",
    "`create_credal_plot()` takes the `input_data` plus optional flags to customize your plot. \n",
    "\n",
    "It delegates all validation and plot selection to `dispatch_plot()` from `input_handling.py`, which decides which plot backend to use based on the number of classes.\n",
    "\n",
    "If `show=True`, it calls `plt.show()` so the figure is displayed immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8800eda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load credal data for all three plots here.\n",
    "print(\"Demodata successfully loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6aaff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae33db8e",
   "metadata": {},
   "source": [
    "### 3.2 `input_handling.py`\n",
    "It selects and executes the correct plotting function based on class count.\n",
    "By calling `create_credal_plot()` from `credal_visualization.py` your \n",
    "\n",
    "Validates input_data is a non-empty NumPy array, at least 2D, with non-negative probabilities that sum to 1 per row, and ≥2 classes with `check_shape()`.\n",
    "It then normalizes shapes by flattening higher-dimensional inputsso plotting always sees a 2D matrix of samples with `normalize_input()`.\n",
    "**Important to mention:**<br>\n",
    "- Your probabilities **must sum to 1**(otherwise you’ll get a clear error).\n",
    "- `choice=\"Probability\"` shows only raw points; `choice=\"MLE\"` shows only the mean; `choice=\"Credal\"` shows only the uncertainty region; `choice=None` shows both.\n",
    "- `minmax=True` only has an effect for **3-class plots**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfee049",
   "metadata": {},
   "source": [
    "### 3.3 `plot_2d.py`\n",
    "This module implements the **2-class credal visualization**: an *interval plot* on a one dimentional probability axis.\n",
    "\n",
    "**Core idea:** <br>\n",
    "If you have probabilities `[p1, p2]` with `p1 + p2 = 1`, then the whole distribution is determined by **one number** (`p2`). So every prediction can be placed on a line from 0 to 1 (where `x = p2`)\n",
    "\n",
    "**Use an interval plot when:**\n",
    "- you have **exactly 2 classes** (binary classification)\n",
    "- you want a **simple uncertainty summary** of predicted probabilities\n",
    "\n",
    "**It’s especially useful for:**\n",
    "- comparing **model uncertainty** across different inputs (narrow band = confident, wide band = uncertain)\n",
    "- showing uncertainty for a **single data point** (or a small set) in a compact way\n",
    "\n",
    "\n",
    "`IntervalVisualizer.probs_to_coords_2d()`: Maps each probability vector `[p1, p2]` to a 2D coordinate `(x, y)`\n",
    "\n",
    "`IntervalVisualizer.interval_plot()`: Draws baseline and maps probability samples as blue points.\n",
    "  - optional **MLE summary** (red dot): the mean of the sampled `p2` values when `mle_flag=True`\n",
    "  - optional **credal band** (shaded region): the min–max interval of `p2` across samples `credal_flag=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25d1b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_2d = np.array(\n",
    "    [\n",
    "        [0.2, 0.8],\n",
    "        [0.5, 0.5], \n",
    "        [0.3, 0.7], \n",
    "    ]\n",
    ")\n",
    "\n",
    "labels_2d = [\"Class A\", \"Class B\"]\n",
    "create_credal_plot(\n",
    "    input_data=points_2d,\n",
    "    labels=labels_2d,\n",
    "    title=\"Binary Credal Set (Interval)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f61125",
   "metadata": {},
   "source": [
    "### 3.4 `plot_3d.py`\n",
    "This module implements the **3-class credal visualization**: a *ternary plot* on the 2D probability simplex.\n",
    "\n",
    "**Core idea:** <br>\n",
    "If you have probabilities `[p1, p2, p3]` with `p1 + p2 + p3 = 1`, every prediction is a point inside the simplex. The closer a point is to a corner, the higher the probability of that class.\n",
    "\n",
    "**Use a ternary plot when:**\n",
    "- you have **exactly 3 classes**\n",
    "- you want to visualize a **credal set** as a region (instead of just individual points)\n",
    "\n",
    "**It’s especially useful for:**\n",
    "- comparing **uncertainty structure** \n",
    "- showing a **credal set** via the convex hull (and optionally min/max envelopes)\n",
    "\n",
    "`TernaryVisualizer.probs_to_coords_3d()`: Converts each probability triple `[p1, p2, p3]` into 2D ternary coordinates `(x, y)` so it can be plotted in a triangle.\n",
    "\n",
    "`TernaryVisualizer.ternary_plot()`: Draws the triangle simplex, axis ticks, and plots probability samples as points.\n",
    "  - optional **MLE** (red dot): the mean probability vector when `mle_flag=True`\n",
    "  - optional **MLE guide lines**: helper lines to make the MLE easier to read `draw_mle_prob_line`\n",
    "  - optional **credal set**: the **convex hull** around all points when `credal_flag=True`\n",
    "  - optional **min/max envelope lines**: draws up to 6 lines (min & max for each class) when `minmax_flag=True`\n",
    "\n",
    "`TernaryVisualizer.plot_convex_hull()`: Builds convex hull around points, depending on how many probabilities are given.\n",
    "\n",
    "`TernaryVisualizer.plot_minmax_lines()`: Computes per-class min and max probabilities across samples, then draws constant-probability lines for each bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8a1de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_3d = np.array(\n",
    "    [\n",
    "        [0.7, 0.2, 0.1],\n",
    "        [0.4, 0.3, 0.3],\n",
    "        [0.6, 0.1, 0.3],\n",
    "    ]\n",
    ")\n",
    "\n",
    "labels_3d = [\"Detractor\", \"Passive\", \"Promoter\"]\n",
    "\n",
    "create_credal_plot(\n",
    "    input_data=points_3d,\n",
    "    labels=labels_3d,\n",
    "    title=\"Ternary Credal Set (Simplex)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88647a6",
   "metadata": {},
   "source": [
    "### 3.5 plot_multid.py\n",
    "This module provides radar (spider) plots for multiclass probability predictions with **more than three classes.** It visualizes probability samples, MLE-style summaries, and credal uncertainty bands in a compact way. The plot is based on a custom Matplotlib radar projection created via `radar_factory`, supporting circular and polygonal frames.\n",
    "\n",
    "**Core Idea:**<br>\n",
    "Each axis corresponds to one class and the radius represents the predicted probability. For a probability vector `p = (p1,..., p)` with `sum(p) = 1`, only the dominant (maximum-probability) class of each sample is plotted. Optionally, a mean probability vector MLE-style and a per-class min–max credal band can be shown. This makes the plot suitable for ensemble outputs, robust classification, and imprecise probability models.\n",
    "\n",
    "`radar_factory():`\n",
    "Creates and registers a custom radar projection. Parameters: num_vars = number of classes; frame = “circle” or “polygon” (recommended). Returns: theta (np.ndarray, shape (num_vars,)) giving angular class positions.\n",
    "\n",
    "`spider_plot()`:\n",
    "General spider plot for multiclass credal predictions. Input: probs (np.ndarray of shape (N, C), row-wise normalized) and labels (list of length C). Options: mle_flag shows the mean probability vector; credal_flag shows the min–max credal band; ax is an optional existing radar axis.\n",
    "\n",
    "Visualization:\n",
    "Sample points: angle = most probable class, radius = probability value. MLE summary: single point at the mean probability vector. Credal band: shaded min–max envelope plus lower and upper bounds per class. Radial values lie in [0, 1]. For polygon frames, scaling uses r_max = cos(π / C). A reference axis with ticks (0.2–1.0) is drawn for readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238ddd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "n_samples = 5\n",
    "points_multi = np.random.dirichlet(alpha=np.ones(n_classes), size=n_samples)\n",
    "\n",
    "labels_multi = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "create_credal_plot(\n",
    "    input_data=points_multi,\n",
    "    labels=labels_multi,\n",
    "    title=\"Multi-Class Credal Set (Spider)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba3d18c",
   "metadata": {},
   "source": [
    "## 4. Specialized plots:\n",
    "Besides the **credal based plots**, our visualization tool includes three further visualizations that focus on different aspects of uncertainty and reliability.\n",
    "\n",
    "**Cluster-margin (SVM) uncertainty plot:**<br>\n",
    "A 2D visualization that uses an SVM’s **distance to the decision boundary** as a *margin-based uncertainty*.\n",
    "It highlights **where the ambiguous region between two clusters lies** in feature space (high uncertainty near the boundary).\n",
    "\n",
    "**Dirichlet / Evidential plot:**<br> \n",
    "A visualization tailored to **Dirichlet-based predictions** (common in evidential deep learning). It helps interpret not only the predicted class probabilities, but also the **strength / concentration** of the Dirichlet distribution (how “certain” the model is overall).\n",
    "\n",
    "**Coverage–Efficiency plot:**<br>\n",
    "A diagnostic plot for **prediction sets**. It shows the trade-off between **coverage** (how often the true label is included in the set) and **efficiency** (how small the set is on average). This is especially useful to compare behaviour on **ID vs. OOD** data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f5092c",
   "metadata": {},
   "source": [
    "### 4.1 `clustervisualizer.py`\n",
    "The `clustervisualizer.py` is a simple visualization tool for inspecting how **confident a classifier separates two clusters** in a 2D feature space. \n",
    "It is based on a **Support Vector Machine (SVM)** and highlights where the model is uncertain about a sample’s class belonging. \n",
    "**Core idea:**<br>\n",
    "The visualization makes model uncertainty intuitive and easy to understand. Areas near the decision boundary appear highly uncertain, while regions farther away indicate higher confidence. As the two clusters move closer together or overlap, the region of uncertainty expands, demonstrating the difficulty of the classification. <br>\n",
    "SVMs are **margin-based classifiers**. They **separate classes** by learning a decision boundary the maximizes the margin between samples of different classes. Using a soft margin allows misclassification but can improve the overall classification in the long run.\n",
    "\n",
    "The SVM provides a margin-based confidence through its decision_function. \n",
    "In this plot, the absolute margin values are inverted and normalized so that:<br> \n",
    "- **High uncertainty:** values close to the decision boundary \n",
    "- **Low uncertainty:** values far from the decision boundary\n",
    "\n",
    "**What the plot shows:**\n",
    "- A continuous uncertainty background derived from the SVM decision function \n",
    "- The two input cluster s overlaid as scatter points\n",
    "- A colorbar indicating relative uncertainty \n",
    "- Clear visual emphasis on ambiguous regions between classes\n",
    "\n",
    "**Methods:** <br>\n",
    "- `_check_shape()`: Validates that input arrays are NumPy arrays with shape **(n_samples, 2)** and are non-empty.\n",
    "\n",
    "- `_2_cluster_to_x()`: Stacks the two clusters into a single feature matrix `X` with shape `(n1+n2, 2)`.\n",
    "\n",
    "- `_2_cluster_to_y()`: Creates a label vector `y` of zeros (for cluster1) and ones (for cluster2), shape `(n1+n2,)`.\n",
    "\n",
    "- `_plot_svm_beam()`: Builds a dense 2D grid over the data range, evaluates the SVM `decision_function`, converts absolute margin to uncertainty, normalizes it to `[0, 1]`, and plots it as a filled contour heatmap + colorbar.\n",
    "\n",
    "- `plot_uncertainty()`: Main entry point.\n",
    "\t- validates `gamma` and `C`\n",
    "\t- scatters the two clusters with distinct colors\n",
    "\t- trains an `sklearn.svm.SVC` on `(X, y)`\n",
    "\t- overlays the uncertainty heatmap from `_plot_svm_beam`\n",
    "\t- optionally calls `plt.show()` and returns the Matplotlib `Axes`\n",
    "\n",
    "**Model Parameters: To adapt the underlying SVM behaviour change those parameters**\n",
    "- Kernel: SVM kernel type (“linear”, “rbf”, “sigmoid”)\n",
    "- C: Regularization strength controlling tolerance for misclassification; Lower values allow more misclassification\n",
    "- gamma: Kernel coefficient controlling the locality of influence; Higher values produce more localized decision boundaries\n",
    "\n",
    "**Visualization Options:**<br>\n",
    "- `title`: Plot title \n",
    "- `x_label`, `y_label`: Axis labels \n",
    "- `class_labels`: Custom names for the two classes\n",
    "- `show`: If `True`, the plot is displayed immediately; If `False`, the Matplotlib Axes object is returned\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a537fb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "value = 42\n",
    "rng = np.random.default_rng(value)\n",
    "\n",
    "n1, n2 = 120, 120\n",
    "cluster1 = rng.normal(loc=(0.0, 0.0), scale=0.7, size=(n1, 2))\n",
    "cluster2 = rng.normal(loc=(2.0, 1.5), scale=0.7, size=(n2, 2))\n",
    "\n",
    "plot_uncertainty(\n",
    "    cluster1,\n",
    "    cluster2,\n",
    "    title=\"Quick demo\",\n",
    "    kernel=\"rbf\",\n",
    "    C=0.5,\n",
    "    gamma=\"scale\",\n",
    "    show=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada2b475",
   "metadata": {},
   "source": [
    "### 4.2 dirichlet\n",
    "Dirichlet distribution plots visualize probability density over the simplex of categorical probability vectors. Each point in the ternary plot represents a possible distribution over three classes, and the contours show which distributions are more likely under a given α. In machine learning, these plots are used to understand and debug Bayesian priors for categorical and multinomial models. They make clear how α controls uncertainty, sparsity, and bias toward specific classes. This is especially useful in topic models, mixture models, and uncertainty-aware classifiers where probabilities themselves are treated as random variables.\n",
    "\n",
    "How to generate a Dirichlet distribution plot:\n",
    "\n",
    "The user needs to call upon the create_dirichlet_plot function. They may pass through parameters such as: alpha, title and labels. Although only alpha is needed; title and labels will be defaulted to: “Dirichlet Distribution X, Y, Z” and \"θ₁\", \"θ₂\", \"θ₃\".\n",
    "\n",
    "e.g.: \n",
    "\n",
    "alpha = np.array([2, 2, 8])\n",
    "\n",
    "create_dirichlet_plot(alpha)\n",
    "\n",
    "Notes on alpha values:\n",
    "The alpha values must be strictly positive; zero or negative values are not allowed, as they do not define a valid Dirichlet distribution. Each αᵢ controls how strongly the distribution favors higher probability mass for class i. Larger α values lead to smoother, more concentrated distributions, while values less than 1 encourage sparse, peaked distributions near the simplex corners. Unequal α values bias the distribution toward specific classes, encoding prior beliefs about class dominance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d964e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_values = np.array([8, 2, 2])\n",
    "labels = (\"Red\", \"Green\", \"Blue\")\n",
    "title = f\"Distribution of likelihood if balls in a Urn are: {labels}\"\n",
    "\n",
    "create_dirichlet_plot(alpha=alpha_values, labels=labels, title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf8fd95",
   "metadata": {},
   "source": [
    "### Coverage Efficency:\n",
    "**The plot tracks two critical metrics:<br>**\n",
    "    - **Coverage** (Blue Line - Reliability): Indicates how often the true class was actually included in the predicted set. Ideally, this curve should follow the diagonal line. If it falls significantly below the diagonal, the model is considered overconfident, as it promises a level of safety it fails to deliver.<br>\n",
    "    - **Efficiency** (Red Line - Precision): Meassures normalized size of the prediction set. A value of **1.0** indicates perfect precision (the set contains only 1 class), while **0.0** represents maximum uncertainty (the set contains all classes). In an ideal **Out-of-Distribution (OOD)** scenario, Efficiency should drop towards zero because the model correctly identifies its lack of knowledge and expands the prediction set. A dangerous failure mode occurs if Efficiency remains high while Coverage drops, indicating the model is making confident but incorrect predictions.\n",
    "    \n",
    "1. How to access the module\n",
    "The module `coverage_efficiency_ood.py` provides two primary functions. If your data is already split into ID and OOD sets, use plot_coverage_efficiency_id_ood, which accepts separate probability and target arrays for each distribution. For combined datasets containing binary markers (where 0 is ID and 1 is OOD), use `plot_coverage_efficiency_from_ood_labels`. This function automatically handles the splitting process based on the provided labels.\n",
    "2. Inputs and Configuration\n",
    "Inputs require specific NumPy array formats: probs must be a 2D array `(N, C)` where rows sum to 1, and targets must be a 1D array of integer indices. If using the label-based approach, ood_labels must match the length of the probability array. While you can customize parameters like titles and figsize via arguments, the visual style (colors like BLUE`/RED, fonts, etc.) is managed centrally via config.py to ensure consistency across the library.\n",
    "3. Summary\n",
    "The primary purpose of this module is to visualize the trustworthiness of a machine learning model. By employing the method of \"Prediction Sets,\" it evaluates whether the model accurately estimates its own uncertainty—a property known as calibration. Furthermore, it analyzes the trade-off between safety and precision, helping to determine whether the model remains specific in its predictions or effectively starts \"guessing\" (by creating large prediction sets) as the required safety levels increase.\n",
    "4. Theory and Interpretation\n",
    "The visualization is grounded in the concept of Prediction Sets(similar to Conformal Prediction), where the model predicts a set of likely classes rather than a single label to guarantee a specific safety level. The X-axis represents the Target Confidence (), which is the safety level specified by the user; for instance, a value of 0.95 implies the model aims to be 95% certain that the true class is contained within the predicted set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e221e384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-Order Distribution:\n",
    "n_samples = 1000\n",
    "n_classes = 10\n",
    "\n",
    "probs_id = np.random.dirichlet(alpha=np.ones(n_classes) * 0.2, size=n_samples)\n",
    "\n",
    "targets_id = np.array([np.random.choice(n_classes, p=p) for p in probs_id])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "visualizer.plot_coverage_efficiency(\n",
    "    probs=probs_id, targets=targets_id, title=\"In-Distribution (ID): High Confidence & Efficiency\", ax=ax\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Out-of-Order Distribution:\n",
    "probs_ood = np.random.dirichlet(alpha=np.ones(n_classes) * 1.0, size=n_samples)\n",
    "\n",
    "targets_ood = np.random.randint(0, n_classes, size=n_samples)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "visualizer.plot_coverage_efficiency(\n",
    "    probs=probs_ood, targets=targets_ood, title=\"Out-of-Distribution (OOD): Low Confidence & Efficiency\", ax=ax\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b629b3e",
   "metadata": {},
   "source": [
    "### Further reading:\n",
    "Here you can find the notebooks of all the plots in depth:\n",
    "**Credal**\n",
    "**Clustermargin**\n",
    "**Dirichlet**\n",
    "**Coverage-Efficency**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
