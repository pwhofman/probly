{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52b4a87d-d06e-4f20-adb2-424c98af6d56",
   "metadata": {},
   "source": [
    "# Testing Evidential Classification — Step-by-Step Tutorial\n",
    "\n",
    "This notebook explains and tests two core components of the `probly` library:\n",
    "\n",
    "1. The registration system in `common.py`  \n",
    "2. The Torch appender in `torch.py`  \n",
    "\n",
    "We'll:\n",
    "- Understand how the registration works  \n",
    "- Verify that the Torch appender adds a Softplus activation  \n",
    "- Create and run custom tests with real data  \n",
    "\n",
    "At the end, you'll know how to register your own appender and test the entire pipeline end-to-end.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a41cbed1-bf52-4b85-8ba4-0891bbafeab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from lazy_dispatch.isinstance import LazyType\n",
    "from probly.transformation.evidential.classification.common import (\n",
    "    evidential_classification,\n",
    "    register,\n",
    ")\n",
    "from probly.transformation.evidential.classification.torch import append_activation_torch\n",
    "\n",
    "print(\"Imports successful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5351162a-20ea-403f-b761-4977f53da8cb",
   "metadata": {},
   "source": [
    "## Step 1 — Understanding `register()` and `evidential_classification()`\n",
    "\n",
    "In the `common.py` file, Probly defines a small internal registry system.\n",
    "\n",
    "| Function | Purpose | Analogy |\n",
    "|-----------|----------|---------|\n",
    "| `register(cls, appender)` | Stores a mapping between a model class and its appender function | Like a contact list — “If you see this model type, call this function.” |\n",
    "| `evidential_classification(model)` | Looks up which appender is registered for the model’s type and applies it | Like a dispatcher that finds the correct plugin automatically |\n",
    "\n",
    "Let's test that this logic works by creating a dummy model and a fake appender.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eebcd260-12d3-4803-992e-d8e378e6c6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appender called for DummyModel\n",
      "Result: Appended(DummyModel)\n"
     ]
    }
   ],
   "source": [
    "class DummyModel:\n",
    "    \"\"\"A simple dummy model for testing.\"\"\"\n",
    "\n",
    "\n",
    "def fake_appender(model: LazyType) -> str:\n",
    "    print(\"Appender called for\", type(model).__name__)\n",
    "    return f\"Appended({type(model).__name__})\"\n",
    "\n",
    "\n",
    "# Register the dummy model\n",
    "register(DummyModel, fake_appender)\n",
    "\n",
    "# Run the dispatcher\n",
    "result = evidential_classification(DummyModel())\n",
    "print(\"Result:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdbf0a0-52c5-435a-bc5c-61dc31c79eeb",
   "metadata": {},
   "source": [
    "The registration works as expected.\n",
    "\n",
    "Here’s what happened:\n",
    "- You registered the `DummyModel` with a simple appender function.\n",
    "- When calling `evidential_classification(DummyModel())`, it automatically found the correct appender and executed it.\n",
    "\n",
    "Now let's test what happens if we call it with an unregistered type — this should raise a clear error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61cf8885-d2f4-4b26-b82c-eaae1bda0f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected error: No evidential classification appender registered for type <class '__main__.UnknownModel'>\n"
     ]
    }
   ],
   "source": [
    "class UnknownModel:\n",
    "    pass\n",
    "\n",
    "\n",
    "try:\n",
    "    evidential_classification(UnknownModel())\n",
    "except NotImplementedError as e:\n",
    "    print(\"Expected error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31f9aa6-c552-4ea7-bbac-2aa3213386c1",
   "metadata": {},
   "source": [
    "## Step 2 — Testing `append_activation_torch()`\n",
    "\n",
    "In `torch.py`, Probly defines a simple helper function:\n",
    "\n",
    "```python\n",
    "def append_activation_torch(obj: nn.Module) -> nn.Sequential:\n",
    "    return nn.Sequential(obj, nn.Softplus())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4dc29aff-86da-4d13-9d54-239da4635716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=4, out_features=2, bias=True)\n",
      "  (1): Softplus(beta=1.0, threshold=20.0)\n",
      ")\n",
      "Torch appender structure looks correct.\n"
     ]
    }
   ],
   "source": [
    "base = nn.Linear(4, 2)\n",
    "model = append_activation_torch(base)\n",
    "\n",
    "print(model)\n",
    "\n",
    "assert isinstance(model, nn.Sequential)  # noqa: S101\n",
    "assert isinstance(model[0], nn.Linear)  # noqa: S101\n",
    "assert isinstance(model[1], nn.Softplus)  # noqa: S101\n",
    "\n",
    "print(\"Torch appender structure looks correct.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd940b6-91f2-4aa5-988a-c4d3fe67143e",
   "metadata": {},
   "source": [
    "The test passed successfully.\n",
    "\n",
    "You just verified that:\n",
    "- The appender correctly returns a `torch.nn.Sequential`\n",
    "- The base model remains the first layer\n",
    "- A `Softplus` is added as the final activation\n",
    "\n",
    "Now let's confirm that the `evidential_classification()` function automatically uses this appender for any PyTorch model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "435c453f-f0a5-482e-92e1-b292feff1270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=10, out_features=3, bias=True)\n",
      "  (1): Softplus(beta=1.0, threshold=20.0)\n",
      ")\n",
      "evidential_classification() correctly used the Torch appender.\n"
     ]
    }
   ],
   "source": [
    "torch_model = nn.Linear(10, 3)\n",
    "wrapped = evidential_classification(torch_model)\n",
    "\n",
    "print(wrapped)\n",
    "assert isinstance(wrapped, nn.Sequential)  # noqa: S101\n",
    "assert isinstance(wrapped[-1], nn.Softplus)  # noqa: S101\n",
    "print(\"evidential_classification() correctly used the Torch appender.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd77bee-0870-4dd2-8a4e-561313abde0c",
   "metadata": {},
   "source": [
    "## Step 3 — Custom Test with Real Data\n",
    "\n",
    "Let's now create a small fake dataset and feed it through our evidential model.\n",
    "\n",
    "This helps verify that:\n",
    "- The output works numerically\n",
    "- The `Softplus` activation ensures all outputs are non-negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fdd241-146a-4971-82d9-341ffc76ca59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " tensor([[ 0.5000,  1.0000],\n",
      "        [ 2.0000, -1.0000],\n",
      "        [ 1.5000,  3.0000]])\n",
      "Output:\n",
      " tensor([[0.6931, 0.6931],\n",
      "        [0.6931, 0.6931],\n",
      "        [0.6931, 0.6931]])\n",
      "All outputs are non-negative. Softplus confirmed.\n"
     ]
    }
   ],
   "source": [
    "# Simple test model\n",
    "net = nn.Sequential(nn.Linear(2, 2), nn.ReLU())\n",
    "\n",
    "# Make it evidential\n",
    "ev_model = evidential_classification(net)\n",
    "\n",
    "# Create dummy input data\n",
    "x = torch.tensor([[0.5, 1.0], [2.0, -1.0], [1.5, 3.0]])\n",
    "\n",
    "# Run forward pass\n",
    "with torch.no_grad():\n",
    "    y = ev_model(x)\n",
    "\n",
    "print(\"Input:\\n\", x)\n",
    "print(\"Output:\\n\", y)\n",
    "\n",
    "# Check that all outputs are positive\n",
    "assert torch.all(y >= 0)  # noqa: S101\n",
    "print(\"All outputs are non-negative. Softplus confirmed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48d2eed-9c6a-4a7f-8b0a-5f0aeebce51e",
   "metadata": {},
   "source": [
    "## Step 4 — Recap\n",
    "\n",
    "| File | Functionality Tested | Expected Behavior |\n",
    "|------|----------------------|-------------------|\n",
    "| `common.py` | Appender registration system | Maps model classes to the correct appender |\n",
    "| `torch.py` | Torch appender function | Adds a Softplus activation |\n",
    "| Integration test | Combined behavior | Torch models automatically use the correct appender |\n",
    "| Data test | Forward pass | All outputs are positive due to Softplus |\n",
    "\n",
    "Everything works as expected.\n",
    "\n",
    "You now know:\n",
    "- How the internal registry in `common.py` works\n",
    "- How the Torch appender adds the activation\n",
    "- How to test it interactively with Jupyter and real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a0d881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " tensor([[ 0.4787,  0.4512,  0.2799],\n",
      "        [ 0.0497, -1.6902,  0.2462],\n",
      "        [-0.8920, -1.7543, -0.9900],\n",
      "        [ 0.4936,  0.2649, -0.2056]])\n",
      "Output:\n",
      " tensor([[0.8671, 1.0110],\n",
      "        [0.7782, 0.8960],\n",
      "        [0.8912, 0.9888],\n",
      "        [0.8958, 1.0935]])\n",
      "All outputs are non-negative. Softplus confirmed.\n"
     ]
    }
   ],
   "source": [
    "# Define your own small model\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self) -> None:  # noqa: D107\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(3, 4)\n",
    "        self.fc2 = nn.Linear(4, 2)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass.\n",
    "\n",
    "        Args:\n",
    "            x: torch.Tensor, input data\n",
    "        Returns:\n",
    "            torch.Tensor, output data\n",
    "        \"\"\"\n",
    "        # //TODO(@todo): fill in your own 2-line forward pass below\n",
    "        # HINT: use ReLU and pass through both layers\n",
    "        x = torch.relu(self.fc1(x))  # <- first line\n",
    "        x = self.fc2(x)  # <- second line\n",
    "        return x\n",
    "\n",
    "\n",
    "# Create model and make it evidential\n",
    "my_net = MyNet()\n",
    "ev_model = evidential_classification(my_net)\n",
    "\n",
    "# Create dummy input data\n",
    "x = torch.randn(4, 3)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y = ev_model(x)\n",
    "\n",
    "print(\"Input:\\n\", x)\n",
    "print(\"Output:\\n\", y)\n",
    "\n",
    "# Check that all outputs are positive\n",
    "assert torch.all(y >= 0)  # noqa: S101\n",
    "print(\"All outputs are non-negative. Softplus confirmed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "probly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
