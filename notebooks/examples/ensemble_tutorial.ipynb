{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b172b79",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è Status: Work in progress ‚Äì bitte noch nicht mergen <br>\n",
    "!! TODOs (vor Merge l√∂schen) !!\n",
    "KEY: (Copy and Paste to title, delete before main merge!) <br>\n",
    "‚ÄºÔ∏è: needs fix<br>\n",
    "üöß: Started<br>\n",
    "‚ùå: not finished<br>\n",
    "‚úÖ: finished<br>\n",
    "\n",
    "- [x] Grobe Struktur anlegen\n",
    "- [x] introduction ensemble\n",
    "- [x] einheitliche √úberschriften\n",
    "- [ ] deep copy belegen\n",
    "- [ ] Abweichungen zu Code anmerken oder fixen\n",
    "- [x] API-Summary (kurz erkl√§ren, wie man Ensemble benutzt)\n",
    "- [ ] Fehlermeldungen bei nicht registrierung zeigen\n",
    "- [ ] Einheitliche Abschnitte\n",
    "- [ ] wenn zeit: Visualisierungen\n",
    "- [ ] Seed setzen (Startwert f√ºr Zufallsgenerator setzen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc809e5",
   "metadata": {},
   "source": [
    "# A Brief Introduction to Ensemble Transformation\n",
    "\n",
    "The goal of this notebook is to showcase the `ensemble` function, which is based on the provided code files (`common.py`, `torch.py`, `__init__.py`). We will demonstrate how to use it to create an ensemble of models from a base PyTorch model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c8147d",
   "metadata": {},
   "source": [
    "# 0. What is an Ensemble?\n",
    "An *ensemble* in machine learning is usually a method that uses a finite set of learning algorithms. Instead of relying on a single model, ensemble combines the results of several models to create a better result.\n",
    "Those different models usually slightly differ in their parameters.\n",
    "This often improves robustness and helps quantify **uncertainty** ‚Äî for example, when the ensemble members disagree, we know the model is unsure.  \n",
    "In `probly`, the `ensemble` transformation automates the creation of such model collections directly from a base PyTorch model. <br>\n",
    "**Why use `ensemble`?** <br>\n",
    "Because it saves you from having to manually copy, reset, and manage multiple model instances yourself. `ensemble` does all of that for you automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b142e6",
   "metadata": {},
   "source": [
    "## 1. Setup: Dependencies and Code Definitions\n",
    "\n",
    "Before we can use the `ensemble` function, we'll define it and its components as described in the code files (`common.py`, `torch.py`, `__init__.py`). This ensures this notebook is self-contained.\n",
    "\n",
    "We will copy the contents of the provided files here and adjust the relative imports.\n",
    "We use two components:\n",
    "- `common.py`: defines a generic dispatcher (`ensemble_generator`) and a user-facing API `ensemble()`.\n",
    "- `torch.py`: registers a PyTorch-specific generator `generate_torch_ensemble()` that clones a model n-times, optionally resetting parameters for each member, and returns an `nn.ModuleList`.\n",
    "\n",
    "--- REREAD!!! NOT FINISHED YET!\n",
    "**Compatibility note:** In some versions, `common.ensemble(...)` passes keyword args (`n_members`, `reset_params`) \n",
    "to the dispatcher. If your `ensemble_generator` base signature does not accept these kwargs, calling\n",
    "`ensemble(...)` may raise a `TypeError`. In that case, call the PyTorch generator directly \n",
    "(`generate_torch_ensemble(...)`) or update the dispatcher signature in the codebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05c324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required third-party dependencies\n",
    "import torch\n",
    "from torch import nn\n",
    "from typing import TYPE_CHECKING, TypeVar\n",
    "from collections.abc import Callable\n",
    "from lazy_dispatch import lazydispatch\n",
    "from lazy_dispatch.isinstance import LazyType\n",
    "from pytraverse import CLONE, singledispatch_traverser, traverse, sequential as nn_compose\n",
    "\n",
    "# --- Mocks for 'probly' dependencies that were not provided ---\n",
    "class Predictor:\n",
    "    \"\"\"Mock class for probly.predictor.Predictor\"\"\"\n",
    "    pass\n",
    "\n",
    "TORCH_MODULE = nn.Module  # Mock for probly.lazy_types.TORCH_MODULE\n",
    "\n",
    "# Mock for probly.traverse_nn.nn_traverser\n",
    "nn_traverser = singledispatch_traverser[nn.Module](name=\"nn_traverser\")\n",
    "\n",
    "@nn_traverser.register(nn.Module)\n",
    "def _nn_traverse_default(obj: nn.Module, traverse: traverse) -> nn.Module:\n",
    "    \"\"\"Default traverser that maps children.\"\"\"\n",
    "    return traverse.map_children(obj)\n",
    "\n",
    "print(\"Library dependencies and mocks loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c80b7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Content from common.py ---\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from collections.abc import Callable\n",
    "    from lazy_dispatch.isinstance import LazyType\n",
    "    # from probly.predictor import Predictor # Already mocked above\n",
    "\n",
    "@lazydispatch\n",
    "def ensemble_generator[In, KwIn, Out](base: Predictor[In, KwIn, Out]) -> Predictor[In, KwIn, Out]:\n",
    "    \"\"\"Generate an ensemble from a base model.\"\"\"\n",
    "    msg = f\"No ensemble generator is registered for type {type(base)}\"\n",
    "    raise NotImplementedError(msg)\n",
    "\n",
    "def register(cls: LazyType, generator: Callable) -> None:\n",
    "    \"\"\"Register a class which can be used as a base for an ensemble.\"\"\"\n",
    "    ensemble_generator.register(cls=cls, func=generator)\n",
    "\n",
    "def ensemble[T: Predictor](base: T, num_members: int, reset_params: bool = True) -> T:\n",
    "    \"\"\"Create an ensemble predictor from a base predictor.\n",
    "\n",
    "    Args:\n",
    "        base: Predictor, The base model to be used for the ensemble.\n",
    "        num_members: The number of members in the ensemble.\n",
    "        reset_params: Whether to reset the parameters of each member.\n",
    "\n",
    "    Returns:\n",
    "        Predictor, The ensemble predictor.\n",
    "    \"\"\"\n",
    "    return ensemble_generator(base, num_members=num_members, reset_params=reset_params)\n",
    "\n",
    "print(\"Code from 'common.py' loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5926d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Content from torch.py ---\n",
    "\n",
    "from __future__ import annotations\n",
    "# from torch import nn # Already imported\n",
    "\n",
    "# from probly.traverse_nn import nn_compose, nn_traverser # Already mocked above\n",
    "# from pytraverse import CLONE, singledispatch_traverser, traverse # Already imported\n",
    "\n",
    "# from .common import register # Adapted to use the global function\n",
    "\n",
    "reset_traverser = singledispatch_traverser[nn.Module](name=\"reset_traverser\")\n",
    "\n",
    "@reset_traverser.register\n",
    "def _(obj: nn.Module) -> nn.Module:\n",
    "    if hasattr(obj, \"reset_parameters\"):\n",
    "        obj.reset_parameters()  # type: ignore[operator]\n",
    "    return obj\n",
    "\n",
    "def _reset_copy(module: nn.Module) -> nn.Module:\n",
    "    return traverse(module, nn_compose(reset_traverser), init={CLONE: True})\n",
    "\n",
    "def _copy(module: nn.Module) -> nn.Module:\n",
    "    return traverse(module, nn_traverser, init={CLONE: True})\n",
    "\n",
    "def generate_torch_ensemble(\n",
    "    obj: nn.Module,\n",
    "    num_members: int,\n",
    "    reset_params: bool = True,\n",
    ") -> nn.ModuleList:\n",
    "    \"\"\"Build a torch ensemble by copying the base model num_members times, resetting the parameters of each member.\"\"\"\n",
    "    if reset_params:\n",
    "        return nn.ModuleList([_reset_copy(obj) for _ in range(num_members)])\n",
    "    return nn.ModuleList([_copy(obj) for _ in range(num_members)])\n",
    "\n",
    "register(nn.Module, generate_torch_ensemble)\n",
    "\n",
    "print(\"Code from 'torch.py' loaded and generator registered.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f933e473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Content from __init__.py ---\n",
    "\n",
    "from __future__ import annotations\n",
    "# from probly.lazy_types import TORCH_MODULE # Already mocked above\n",
    "\n",
    "# from . import common # Adapted, as 'common' is already global\n",
    "# ensemble = common.ensemble # Already global\n",
    "# register = common.register # Already global\n",
    "\n",
    "## Torch\n",
    "# @common.ensemble_generator.delayed_register(TORCH_MODULE)\n",
    "# def _(_: type) -> None:\n",
    "#     from . import torch as torch_impl  # noqa: PLC0415\n",
    "\n",
    "# NOTE: Since we are in a notebook, we are performing the registration\n",
    "# (which already happened in the 'torch.py' cell) explicitly.\n",
    "# The 'delayed_register' logic is not needed here because we loaded 'torch.py'\n",
    "# directly.\n",
    "\n",
    "print(\"Code from '__init__.py' (logically) executed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca910ddc",
   "metadata": {},
   "source": [
    "## 3. The Problem: Manual Ensemble Creation\n",
    "\n",
    "Let's say we have a base model in PyTorch and want to create a \"Deep Ensemble\" for uncertainty quantification. For this, we need several copies of this model, each of which must have different initialized weights.\n",
    "\n",
    "The naive approach would be to manually copy the model and reset the parameters. This can be tedious, especially with complex, nested models.\n",
    "\n",
    "--- NOTE: Maybe break apart the big code chunk into smaller pieces and add explanation? ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc09165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "# Our base model\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(10, 20)\n",
    "        self.layer2 = nn.Linear(20, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        return self.layer2(x)\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        # Important for Deep Ensembles: a custom reset function\n",
    "        print(\"Custom reset_parameters of SimpleNet called!\")\n",
    "        self.layer1.reset_parameters()\n",
    "        self.layer2.reset_parameters()\n",
    "\n",
    "base_model = SimpleNet()\n",
    "print(f\"Base model weight (layer1): {base_model.layer1.weight.data[0, 0]}\")\n",
    "\n",
    "# Manual approach\n",
    "num_members = 3\n",
    "manual_ensemble = []\n",
    "for _ in range(num_members):\n",
    "    model_copy = copy.deepcopy(base_model)\n",
    "    # We have to remember to reset the parameters manually\n",
    "    if hasattr(model_copy, 'reset_parameters'):\n",
    "        model_copy.reset_parameters() #\n",
    "    manual_ensemble.append(model_copy)\n",
    "\n",
    "print(\"\\nManual ensemble created.\")\n",
    "print(f\"Weight of member 0: {manual_ensemble[0].layer1.weight.data[0, 0]}\")\n",
    "print(f\"Weight of member 1: {manual_ensemble[1].layer1.weight.data[0, 0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044b8f55",
   "metadata": {},
   "source": [
    "(Example code output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc895a3c",
   "metadata": {},
   "source": [
    "Base model weight (layer1): 0.20300185680389404\n",
    "Custom reset_parameters of SimpleNet called!\n",
    "Custom reset_parameters of SimpleNet called!\n",
    "Custom reset_parameters of SimpleNet called!\n",
    "\n",
    "Manual ensemble created.\n",
    "Weight of member 0: -0.22176861763000488\n",
    "Weight of member 1: 0.17613589763641357"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd9309c",
   "metadata": {},
   "source": [
    "This works, but it's cumbersome. We have to use `copy.deepcopy` and manually check for a `reset_parameters` method.\n",
    "\n",
    "The `torch.py` code automates this. The `_reset_copy` function uses `pytraverse` to recursively traverse the module and call `reset_parameters()` on every submodule that has it. This is a perfect example of the separation of concerns shown in `pytraverse_tutorial.ipynb` (cell `5ae1e551`): the traversal logic is separate from the reset logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01593f0",
   "metadata": {},
   "source": [
    "## 3. The Automated Solution: The ensemble() Function\n",
    "\n",
    "The `ensemble` function from `common.py` is a `lazydispatch` wrapper. It automatically selects the correct generator based on the type of the base model.\n",
    "\n",
    "Since we registered `generate_torch_ensemble` for `nn.Module` (in the `torch.py` cell above), we can apply the `ensemble` function directly to our `SimpleNet` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f37280a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating ensemble with reset (default) ---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'SimpleNet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--- Creating ensemble with reset (default) ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m base_model_2 = \u001b[43mSimpleNet\u001b[49m()\n\u001b[32m      3\u001b[39m base_weight = base_model_2.layer1.weight.data[\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m].item()\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBase model weight: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_weight\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'SimpleNet' is not defined"
     ]
    }
   ],
   "source": [
    "# Important: To prevent NameError, please run above cells first!\n",
    "print(\"--- Creating ensemble with reset (default) ---\")\n",
    "base_model_2 = SimpleNet()\n",
    "base_weight = base_model_2.layer1.weight.data[0, 0].item()\n",
    "print(f\"Base model weight: {base_weight}\")\n",
    "\n",
    "# ensemble is the function from common.py\n",
    "# reset_params=True is the default\n",
    "model_ensemble = ensemble(base_model_2, num_members=3, reset_params=True)\n",
    "\n",
    "print(f\"\\nEnsemble created: {type(model_ensemble)}\")\n",
    "print(f\"Number of members: {len(model_ensemble)}\")\n",
    "\n",
    "# Let's compare the weights to see if they are different\n",
    "weight0 = model_ensemble[0].layer1.weight.data[0, 0].item()\n",
    "weight1 = model_ensemble[1].layer1.weight.data[0, 0].item()\n",
    "weight2 = model_ensemble[2].layer1.weight.data[0, 0].item()\n",
    "\n",
    "print(f\"Weight of member 0: {weight0}\")\n",
    "print(f\"Weight of member 1: {weight1}\")\n",
    "print(f\"Weight of member 2: {weight2}\")\n",
    "\n",
    "if weight0 != base_weight and weight1 != base_weight and weight0 != weight1:\n",
    "    print(\"All weights are different (as expected).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdebc84",
   "metadata": {},
   "source": [
    "(Example code output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66ab463",
   "metadata": {},
   "source": [
    "--- Creating ensemble with reset (default) ---\n",
    "Base model weight: -0.27976858615875244\n",
    "Custom reset_parameters of SimpleNet called!\n",
    "Custom reset_parameters of SimpleNet called!\n",
    "Custom reset_parameters of SimpleNet called!\n",
    "\n",
    "Ensemble created: <class 'torch.nn.modules.container.ModuleList'>\n",
    "Number of members: 3\n",
    "\n",
    "Weight of member 0: 0.1681283712387085\n",
    "Weight of member 1: -0.06659793853759766\n",
    "Weight of member 2: -0.19827675819396973\n",
    "\n",
    "All weights are different (as expected)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c2e2ea",
   "metadata": {},
   "source": [
    "## Optional Behavior: Cloning Without Reset\n",
    "\n",
    "The `ensemble` function also accepts `reset_params=False`.\n",
    "\n",
    "In this case, `generate_torch_ensemble` calls the `_copy` function instead of `_reset_copy`. `_copy` simply uses the `nn_traverser` to clone the module without calling `reset_parameters()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2e245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Creating ensemble without reset ---\")\n",
    "base_model_3 = SimpleNet()\n",
    "base_weight_3 = base_model_3.layer1.weight.data[0, 0].item()\n",
    "print(f\"Base model weight: {base_weight_3}\")\n",
    "\n",
    "# This time we set reset_params to False\n",
    "copied_ensemble = ensemble(base_model_3, num_members=2, reset_params=False)\n",
    "\n",
    "weight0 = copied_ensemble[0].layer1.weight.data[0, 0].item()\n",
    "weight1 = copied_ensemble[1].layer1.weight.data[0, 0].item()\n",
    "\n",
    "print(f\"\\nWeight of member 0: {weight0}\")\n",
    "print(f\"Weight of member 1: {weight1}\")\n",
    "\n",
    "assert weight0 == base_weight_3\n",
    "assert weight1 == base_weight_3\n",
    "print(\"All weights are identical to the base model (as expected).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7788ca24",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "--- Creating ensemble without reset ---\n",
    "Base model weight: -0.06256282329559326\n",
    "\n",
    "Weight of member 0: -0.06256282329559326\n",
    "Weight of member 1: -0.06256282329559326\n",
    "\n",
    "All weights are identical to the base model (as expected)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96aef4a2",
   "metadata": {},
   "source": [
    "## 5. Verifying Ensemble Properties\n",
    "**TO-DO**: Proofing Deep Copy with set parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b94d02",
   "metadata": {},
   "source": [
    "## 6. Summary and Key Takeaway\n",
    "\n",
    "The `ensemble` function is a powerful dispatcher that abstracts away the complexity of creating model ensembles.\n",
    "\n",
    "By registering type-specific generators (like `generate_torch_ensemble` for `nn.Module`) with the `ensemble_generator`, it provides a clean, extensible API.\n",
    "\n",
    "Internally, the PyTorch implementation uses `pytraverse` to efficiently traverse, copy, and optionally reset parameters of the module structure. This demonstrates how the abstract concepts from `pytraverse_tutorial.ipynb` (like `singledispatch_traverser` and `traverse` with `{CLONE: True}`) are used in a real-world application to write robust and maintainable code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fbabfc",
   "metadata": {},
   "source": [
    "## 7. Further Reading and References\n",
    "**TO DO:** add references to pytraverse intro and probly documention\n",
    "- **PyTorch:** `nn.ModuleList`, `reset_parameters()`\n",
    "- **Probly documentation:**  (https://github.com/pwhofman/probly/tree/main/docs)\n",
    "- **PyTraverse intro notebook:** (https://github.com/pwhofman/probly/blob/main/notebooks/examples/pytraverse_tutorial.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
