{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dc809e5",
   "metadata": {},
   "source": [
    "# A Brief Introduction to Ensemble Transformation\n",
    "\n",
    "The goal of this notebook is to showcase the `ensemble` function, which is based on the provided code files (`common.py`, `torch.py`, `__init__.py`). We will demonstrate how to use it to create an ensemble of models from a base PyTorch model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c8147d",
   "metadata": {},
   "source": [
    "# 0. What is an Ensemble?\n",
    "An *ensemble* in machine learning is usually a method that uses a finite set of learning algorithms. Instead of relying on a single model, ensemble combines the results of several models to create a better result.\n",
    "Those different models usually slightly differ in their parameters.\n",
    "This often improves robustness and helps quantify **uncertainty** — for example, when the ensemble members disagree, we know the model is unsure.  \n",
    "In `probly`, the `ensemble` transformation automates the creation of such model collections directly from a base PyTorch model. <br>\n",
    "**Why use `ensemble`?** <br>\n",
    "Because it saves you from having to manually copy, reset, and manage multiple model instances yourself. `ensemble` does all of that for you automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b142e6",
   "metadata": {},
   "source": [
    "## 1. Setup: Dependencies and Code Definitions\n",
    "\n",
    "Before we can use the `ensemble` function, we'll define it and its components as described in the code files (`common.py`, `torch.py`, `__init__.py`). This ensures this notebook is self-contained.\n",
    "\n",
    "We will copy the contents of the provided files here and adjust the relative imports.\n",
    "We use three components: `common.py` for dispatching and `torch.py` for generating an ensemble. `init.py`connects the generic ensemnle logic with the PyTorch implementation. All components will be explained further below.\n",
    "\n",
    "To prevent errors, run the cells in the given order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e10465",
   "metadata": {},
   "source": [
    "## 1.1 How `__init__.py` connects Ensemble Components\n",
    "The `__init__.py` file defines the public interface of the ensemble module.\n",
    "It re-exports the main functions `ensemble` and `register` so they can be imported directly from `probly.ensemble`.\n",
    "Additionally, it performs a *lazy registration* of the PyTorch backend, which means the Torch implementation is only loaded when a Torch model is actually used.\n",
    "This design avoids unnecessary imports, prevents circular dependencies, and keeps the package lightweight and modular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3dd2179",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mprobly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_types\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TORCH_MODULE\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m common\n\u001b[0;32m      9\u001b[0m ensemble \u001b[38;5;241m=\u001b[39m common\u001b[38;5;241m.\u001b[39mensemble\n\u001b[0;32m     10\u001b[0m register \u001b[38;5;241m=\u001b[39m common\u001b[38;5;241m.\u001b[39mregister\n",
      "\u001b[1;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "\"\"\"Ensemble implementation for uncertainty quantification.\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from probly.lazy_types import TORCH_MODULE\n",
    "\n",
    "from . import common\n",
    "\n",
    "ensemble = common.ensemble\n",
    "register = common.register\n",
    "\n",
    "## Torch\n",
    "@common.ensemble_generator.delayed_register(TORCH_MODULE)\n",
    "def _(_: type) -> None:\n",
    "    from . import torch as torch  # noqa: PLC0415"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0d2713",
   "metadata": {},
   "source": [
    "## 1.2 How `common.py` implements the Main Logic\n",
    "The `common.py` file defines the core logic of the ensemble module.\n",
    "It introduces a generic dispatcher called `ensemble_generator`, which dynamically selects the correct ensemble creation function based on the model type.\n",
    "The register function allows developers to link new model types (such as PyTorch or custom predictors) to their specific generator implementations.\n",
    "Finally, the `ensemble()` function provides a simple, user-facing API that hides the dispatch mechanism and automatically calls the right generator.\n",
    "Together, these components make the ensemble system flexible and easily extensible to other frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abca0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Shared ensemble implementation.\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from typing import TYPE_CHECKING\n",
    "\n",
    "from lazy_dispatch import lazydispatch\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from collections.abc import Callable\n",
    "\n",
    "    from lazy_dispatch.isinstance import LazyType\n",
    "    from probly.predictor import Predictor\n",
    "\n",
    "\n",
    "@lazydispatch\n",
    "def ensemble_generator[In, KwIn, Out](base: Predictor[In, KwIn, Out]) -> Predictor[In, KwIn, Out]:\n",
    "    \"\"\"Generate an ensemble from a base model.\"\"\"\n",
    "    msg = f\"No ensemble generator is registered for type {type(base)}\"\n",
    "    raise NotImplementedError(msg)\n",
    "\n",
    "\n",
    "def register(cls: LazyType, generator: Callable) -> None:\n",
    "    \"\"\"Register a class which can be used as a base for an ensemble.\"\"\"\n",
    "    ensemble_generator.register(cls=cls, func=generator)\n",
    "\n",
    "\n",
    "def ensemble[T: Predictor](base: T, n_members: int, reset_params: bool = True) -> T:\n",
    "    \"\"\"Create an ensemble predictor from a base predictor.\n",
    "\n",
    "    Args:\n",
    "        base: Predictor, The base model to be used for the ensemble.\n",
    "        n_members: The number of members in the ensemble.\n",
    "        reset_params: Whether to reset the parameters of each member.\n",
    "\n",
    "    Returns:\n",
    "        Predictor, The ensemble predictor.\n",
    "    \"\"\"\n",
    "    return ensemble_generator(base, n_members=n_members, reset_params=reset_params)\n",
    "print(\"Code from 'commpny.py' loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37018878",
   "metadata": {},
   "source": [
    "## 1.3 The Torch Implementation: `torch.py`\n",
    "The `torch.py` file implements the ensemble generator specifically for PyTorch models.\n",
    "It uses the `pytraverse` library to recursively clone neural networks and optionally reset their parameters using each layer’s `reset_parameters()` method.\n",
    "The main function, `generate_torch_ensemble()`, creates multiple independent copies of a given base model and returns them as an nn.ModuleList.\n",
    "This ensures that each ensemble member has its own parameters, allowing the ensemble to represent independent model instances.\n",
    "At the end, the PyTorch generator is registered with the dispatcher using register(`nn.Module`, `generate_torch_ensemble`), linking it seamlessly to the common interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05c324a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library dependencies and mocks loaded.\n"
     ]
    }
   ],
   "source": [
    "# Required third-party dependencies\n",
    "import torch\n",
    "from torch import nn\n",
    "from typing import TYPE_CHECKING, TypeVar\n",
    "from collections.abc import Callable\n",
    "from lazy_dispatch import lazydispatch\n",
    "from lazy_dispatch.isinstance import LazyType\n",
    "from pytraverse import CLONE, singledispatch_traverser, traverse, sequential as nn_compose\n",
    "\n",
    "# --- Mocks for 'probly' dependencies that were not provided ---\n",
    "class Predictor:\n",
    "    \"\"\"Mock class for probly.predictor.Predictor\"\"\"\n",
    "    pass\n",
    "\n",
    "TORCH_MODULE = nn.Module  # Mock for probly.lazy_types.TORCH_MODULE\n",
    "\n",
    "# Mock for probly.traverse_nn.nn_traverser\n",
    "nn_traverser = singledispatch_traverser[nn.Module](name=\"nn_traverser\")\n",
    "\n",
    "@nn_traverser.register(nn.Module)\n",
    "def _nn_traverse_default(obj: nn.Module, traverse: traverse) -> nn.Module:\n",
    "    \"\"\"Default traverser that maps children.\"\"\"\n",
    "    return traverse.map_children(obj)\n",
    "\n",
    "print(\"Library dependencies and mocks loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5e1de5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5926d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code from 'torch.py' loaded and generator registered.\n"
     ]
    }
   ],
   "source": [
    "# --- Content from torch.py ---\n",
    "import copy\n",
    "from __future__ import annotations\n",
    "# from torch import nn # Already imported\n",
    "\n",
    "# from probly.traverse_nn import nn_compose, nn_traverser # Already mocked above\n",
    "# from pytraverse import CLONE, singledispatch_traverser, traverse # Already imported\n",
    "\n",
    "# from .common import register # Adapted to use the global function\n",
    "\n",
    "reset_traverser = singledispatch_traverser[nn.Module](name=\"reset_traverser\")\n",
    "\n",
    "@reset_traverser.register\n",
    "def _(obj: nn.Module) -> nn.Module:\n",
    "    if hasattr(obj, \"reset_parameters\"):\n",
    "        obj.reset_parameters()  # type: ignore[operator]\n",
    "    return obj\n",
    "\n",
    "def _copy(module: nn.Module) -> nn.Module:\n",
    "    # simple deep copy without relying on the nn_traverser mock\n",
    "    return copy.deepcopy(module)\n",
    "\n",
    "def _reset_copy(module: nn.Module) -> nn.Module:\n",
    "    cloned = _copy(module)\n",
    "    for m in cloned.modules():\n",
    "        if hasattr(m, \"reset_parameters\"):\n",
    "            m.reset_parameters()\n",
    "    return cloned\n",
    "\n",
    "def generate_torch_ensemble(\n",
    "    obj: nn.Module,\n",
    "    n_members: int,\n",
    "    reset_params: bool = True,\n",
    ") -> nn.ModuleList:\n",
    "    \"\"\"Build a torch ensemble by copying the base model n_members times, resetting the parameters of each member.\"\"\"\n",
    "    if reset_params:\n",
    "        return nn.ModuleList([_reset_copy(obj) for _ in range(n_members)])\n",
    "    return nn.ModuleList([_copy(obj) for _ in range(n_members)])\n",
    "\n",
    "register(nn.Module, generate_torch_ensemble)\n",
    "\n",
    "print(\"Code from 'torch.py' loaded and generator registered.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f933e473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code from '__init__.py' (logically) executed.\n"
     ]
    }
   ],
   "source": [
    "# --- Content from __init__.py ---\n",
    "\n",
    "from __future__ import annotations\n",
    "# from probly.lazy_types import TORCH_MODULE # Already mocked above\n",
    "\n",
    "# from . import common # Adapted, as 'common' is already global\n",
    "# ensemble = common.ensemble # Already global\n",
    "# register = common.register # Already global\n",
    "\n",
    "## Torch\n",
    "# @common.ensemble_generator.delayed_register(TORCH_MODULE)\n",
    "# def _(_: type) -> None:\n",
    "#     from . import torch as torch_impl  # noqa: PLC0415\n",
    "\n",
    "# NOTE: Since we are in a notebook, we are performing the registration\n",
    "# (which already happened in the 'torch.py' cell) explicitly.\n",
    "# The 'delayed_register' logic is not needed here because we loaded 'torch.py'\n",
    "# directly.\n",
    "\n",
    "print(\"Code from '__init__.py' (logically) executed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed7266b",
   "metadata": {},
   "source": [
    "Note: Since we are in a notebook, we are performing the registration explicitly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca910ddc",
   "metadata": {},
   "source": [
    "## 2. The Problem: Manual Ensemble Creation\n",
    "\n",
    "Let's say we have a base model in PyTorch and want to create a \"Deep Ensemble\" for uncertainty quantification. For this, we need several copies of this model, each of which must have different initialized weights.\n",
    "\n",
    "The naive approach would be to manually copy the model and reset the parameters. This can be tedious, especially with complex, nested models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc09165b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model weight (layer1): -0.1555764377117157\n",
      "Custom reset_parameters of SimpleNet called!\n",
      "Custom reset_parameters of SimpleNet called!\n",
      "Custom reset_parameters of SimpleNet called!\n",
      "\n",
      "Manual ensemble created.\n",
      "Weight of member 0: 0.299756795167923\n",
      "Weight of member 1: 0.045742422342300415\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "# Our base model\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(10, 20)\n",
    "        self.layer2 = nn.Linear(20, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        return self.layer2(x)\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        # Important for Deep Ensembles: a custom reset function\n",
    "        print(\"Custom reset_parameters of SimpleNet called!\")\n",
    "        self.layer1.reset_parameters()\n",
    "        self.layer2.reset_parameters()\n",
    "\n",
    "base_model = SimpleNet()\n",
    "print(f\"Base model weight (layer1): {base_model.layer1.weight.data[0, 0]}\")\n",
    "\n",
    "# Manual approach\n",
    "n_members = 3\n",
    "manual_ensemble = []\n",
    "for _ in range(n_members):\n",
    "    model_copy = copy.deepcopy(base_model)\n",
    "    # We have to remember to reset the parameters manually\n",
    "    if hasattr(model_copy, 'reset_parameters'):\n",
    "        model_copy.reset_parameters() #\n",
    "    manual_ensemble.append(model_copy)\n",
    "\n",
    "print(\"\\nManual ensemble created.\")\n",
    "print(f\"Weight of member 0: {manual_ensemble[0].layer1.weight.data[0, 0]}\")\n",
    "print(f\"Weight of member 1: {manual_ensemble[1].layer1.weight.data[0, 0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5d9481",
   "metadata": {},
   "source": [
    "ddd\n",
    "(Example code output)\n",
    "\n",
    "Base model weight (layer1): 0.20300185680389404\n",
    "Custom reset_parameters of SimpleNet called!\n",
    "Custom reset_parameters of SimpleNet called!\n",
    "Custom reset_parameters of SimpleNet called!\n",
    "\n",
    "Manual ensemble created.\n",
    "Weight of member 0: -0.22176861763000488\n",
    "Weight of member 1: 0.17613589763641357\n",
    "\n",
    "This works, but it's cumbersome. We have to use `copy.deepcopy` and manually check for a `reset_parameters` method.\n",
    "\n",
    "The `torch.py` code automates this. The `_reset_copy` function uses `pytraverse` to recursively traverse the module and call `reset_parameters()` on every submodule that has it. This is a perfect example of the separation of concerns shown in `pytraverse_tutorial.ipynb` (cell `5ae1e551`): the traversal logic is separate from the reset logic.\n",
    "In the next section, we will see how the `ensemble()` function automates this entire process, making ensemble creation both cleaner and safer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01593f0",
   "metadata": {},
   "source": [
    "## 3. The Automated Solution: The ensemble() Function\n",
    "\n",
    "TODO: Split up text in smaller cells\n",
    "The `ensemble` function from `common.py` is a `lazydispatch` wrapper. It automatically selects the correct generator based on the type of the base model.\n",
    "\n",
    "Since we registered `generate_torch_ensemble` for `nn.Module` (in the `torch.py` cell above), we can apply the `ensemble` function directly to our `SimpleNet` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f37280a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating ensemble with reset (default) ---\n",
      "Base model weight: -0.06822812557220459\n",
      "Custom reset_parameters of SimpleNet called!\n",
      "Custom reset_parameters of SimpleNet called!\n",
      "Custom reset_parameters of SimpleNet called!\n",
      "\n",
      "Ensemble created: <class 'torch.nn.modules.container.ModuleList'>\n",
      "Number of members: 3\n",
      "Weight of member 0: -0.296882301568985\n",
      "Weight of member 1: 0.16315487027168274\n",
      "Weight of member 2: -0.139506533741951\n",
      "All weights are different (as expected).\n"
     ]
    }
   ],
   "source": [
    "# Important: To prevent NameError, please run above cells first!\n",
    "print(\"--- Creating ensemble with reset (default) ---\")\n",
    "base_model_2 = SimpleNet()\n",
    "base_weight = base_model_2.layer1.weight.data[0, 0].item()\n",
    "print(f\"Base model weight: {base_weight}\")\n",
    "\n",
    "# ensemble is the function from common.py\n",
    "# reset_params=True is the default\n",
    "model_ensemble = ensemble(base_model_2, n_members=3, reset_params=True)\n",
    "\n",
    "print(f\"\\nEnsemble created: {type(model_ensemble)}\")\n",
    "print(f\"Number of members: {len(model_ensemble)}\")\n",
    "\n",
    "# Let's compare the weights to see if they are different\n",
    "weight0 = model_ensemble[0].layer1.weight.data[0, 0].item()\n",
    "weight1 = model_ensemble[1].layer1.weight.data[0, 0].item()\n",
    "weight2 = model_ensemble[2].layer1.weight.data[0, 0].item()\n",
    "\n",
    "print(f\"Weight of member 0: {weight0}\")\n",
    "print(f\"Weight of member 1: {weight1}\")\n",
    "print(f\"Weight of member 2: {weight2}\")\n",
    "\n",
    "if weight0 != base_weight and weight1 != base_weight and weight0 != weight1:\n",
    "    print(\"All weights are different (as expected).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdebc84",
   "metadata": {},
   "source": [
    "(Example code output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66ab463",
   "metadata": {},
   "source": [
    "--- Creating ensemble with reset (default) ---\n",
    "Base model weight: -0.27976858615875244\n",
    "Custom reset_parameters of SimpleNet called!\n",
    "Custom reset_parameters of SimpleNet called!\n",
    "Custom reset_parameters of SimpleNet called!\n",
    "\n",
    "Ensemble created: <class 'torch.nn.modules.container.ModuleList'>\n",
    "Number of members: 3\n",
    "\n",
    "Weight of member 0: 0.1681283712387085\n",
    "Weight of member 1: -0.06659793853759766\n",
    "Weight of member 2: -0.19827675819396973\n",
    "\n",
    "All weights are different (as expected)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c2e2ea",
   "metadata": {},
   "source": [
    "## Optional Behavior: Cloning Without Reset\n",
    "\n",
    "The `ensemble` function also accepts `reset_params=False`.\n",
    "\n",
    "In this case, `generate_torch_ensemble` calls the `_copy` function instead of `_reset_copy`. `_copy` simply uses the `nn_traverser` to clone the module without calling `reset_parameters()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2e245f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating ensemble without reset ---\n",
      "Base model weight: -0.2042517066001892\n",
      "\n",
      "Weight of member 0: -0.2042517066001892\n",
      "Weight of member 1: -0.2042517066001892\n",
      "All weights are identical to the base model (as expected).\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Creating ensemble without reset ---\")\n",
    "base_model_3 = SimpleNet()\n",
    "base_weight_3 = base_model_3.layer1.weight.data[0, 0].item()\n",
    "print(f\"Base model weight: {base_weight_3}\")\n",
    "\n",
    "# This time we set reset_params to False\n",
    "copied_ensemble = ensemble(base_model_3, n_members=2, reset_params=False)\n",
    "\n",
    "weight0 = copied_ensemble[0].layer1.weight.data[0, 0].item()\n",
    "weight1 = copied_ensemble[1].layer1.weight.data[0, 0].item()\n",
    "\n",
    "print(f\"\\nWeight of member 0: {weight0}\")\n",
    "print(f\"Weight of member 1: {weight1}\")\n",
    "\n",
    "assert weight0 == base_weight_3\n",
    "assert weight1 == base_weight_3\n",
    "print(\"All weights are identical to the base model (as expected).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7788ca24",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "--- Creating ensemble without reset ---\n",
    "Base model weight: -0.06256282329559326\n",
    "\n",
    "Weight of member 0: -0.06256282329559326\n",
    "Weight of member 1: -0.06256282329559326\n",
    "\n",
    "All weights are identical to the base model (as expected)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b94d02",
   "metadata": {},
   "source": [
    "## 6. Summary and Key Takeaway\n",
    "\n",
    "The `ensemble` function is a powerful dispatcher that abstracts away the complexity of creating model ensembles.\n",
    "\n",
    "By registering type-specific generators (like `generate_torch_ensemble` for `nn.Module`) with the `ensemble_generator`, it provides a clean, extensible API.\n",
    "\n",
    "Internally, the PyTorch implementation uses `pytraverse` to efficiently traverse, copy, and optionally reset parameters of the module structure. This demonstrates how the abstract concepts from `pytraverse_tutorial.ipynb` (like `singledispatch_traverser` and `traverse` with `{CLONE: True}`) are used in a real-world application to write robust and maintainable code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fbabfc",
   "metadata": {},
   "source": [
    "## 7. Further Reading and References\n",
    "- **Probly documentation:** ***for more information on how everything in probly works*** <br> (https://github.com/pwhofman/probly/tree/main/docs)\n",
    "- **PyTraverse intro notebook:** ***offers a deep tutorial on how pytraverse automates traversing***<br> (https://github.com/pwhofman/probly/blob/main/notebooks/examples/pytraverse_tutorial.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "probly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
