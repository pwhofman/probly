{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5b81968",
   "metadata": {},
   "source": [
    "# Posterior Network: Uncertainty Estimation without OOD Samples via Density-Based Pseudo-Counts\n",
    "\n",
    "Posterior Networks (PostNet) extend the idea of Evidential Deep Learning (EDL) by producing a full Dirichlet distribution over class probabilities for each input. However, instead of evidence being directly predicted by the neural network, PostNet does so by deriving evidence from class-conditional density estimates in a latent space. This assures that out-of-distribution (OOD) samples are not needed during training, as uncertainty increases for inputs that lie outside the learned density.\n",
    "\n",
    "In this notebook, we will:\n",
    "- Build a small encoder to map inputs into a latent space\n",
    "- Train a separate normalizing flow per class to model the class-conditional densities\n",
    "- Convert densities into evidence (pseudo-counts)\n",
    "- Construct Dirichlet posteriors and evaluate uncertainty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187fd6fa",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d22d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "%uv pip install nflows\n",
    "from nflows.distributions.normal import StandardNormal\n",
    "from nflows.flows import Flow\n",
    "from nflows.nn.nets import MLP\n",
    "from nflows.transforms import AffineCouplingTransform, CompositeTransform, ReversePermutation\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d91721",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Posterior Networks require:\n",
    "- an in-distribution (ID) dataset used for training and standard evaluation\n",
    "- an out-of-distribution dataset used only for testing epistemic uncertainty\n",
    "\n",
    "Here, we use **MNIST** as the ID dataset and **FashionMNIST** as the OOD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bbf28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([T.ToTensor()])\n",
    "\n",
    "# In-distribution data\n",
    "\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root=\"~/datasets\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root=\"~/datasets\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=256, shuffle=False)\n",
    "\n",
    "print(\"MNIST loaded (ID).\")\n",
    "\n",
    "# Out-of-distribution data\n",
    "\n",
    "ood_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"~/datasets\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "ood_loader = DataLoader(ood_data, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c437fd8",
   "metadata": {},
   "source": [
    "## Model Definition\n",
    "\n",
    "Posterior Networks are composed of:\n",
    "1. **Encoder**: maps each image to a low-dimensional latent vector.\n",
    "2. **Class-conditional normalizing flows**: one flow per class, modeling the density P(z|c) in latent space. These densities provide the evidence used to construct the Dirichlet distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4886e7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder: maps images (x) -> latent (z)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim=2) -> None:  # noqa: ANN001\n",
    "        \"\"\"Initializes an instance of the Encoder class.\"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(),  # turns a 28x28 image into a vector of size 784\n",
    "            nn.Linear(784, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, latent_dim),  # final output = latent vector z\n",
    "        )\n",
    "\n",
    "    def forward(self, x) -> None:  # noqa: ANN001, D102\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "# Normalizing Flow for P(z | c)\n",
    "\n",
    "\n",
    "class ContextIgnoreNet(nn.Module):\n",
    "    def __init__(self, in_features, out_features) -> None:  # noqa: ANN001, D107\n",
    "        super().__init__()\n",
    "        self.net = MLP(\n",
    "            in_shape=(in_features,),\n",
    "            out_shape=(out_features,),\n",
    "            hidden_sizes=[32, 32],\n",
    "        )\n",
    "\n",
    "    def forward(self, x, context=None) -> None:  # noqa: ANN001, ARG002, D102\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "def make_flow(latent_dim) -> None:  # noqa: ANN001\n",
    "    # Required function that returns a transform network\n",
    "    def transform_net_create_fn(in_features, out_features) -> None:  # noqa: ANN001\n",
    "        return ContextIgnoreNet(in_features, out_features)\n",
    "\n",
    "    base_dist = StandardNormal([latent_dim])\n",
    "\n",
    "    transform = CompositeTransform(\n",
    "        [\n",
    "            AffineCouplingTransform(\n",
    "                mask=[0, 1],\n",
    "                transform_net_create_fn=transform_net_create_fn,\n",
    "            ),\n",
    "            ReversePermutation(features=latent_dim),\n",
    "            AffineCouplingTransform(\n",
    "                mask=[1, 0],\n",
    "                transform_net_create_fn=transform_net_create_fn,\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return Flow(transform, base_dist)\n",
    "\n",
    "\n",
    "latent_dim = 2\n",
    "encoder = Encoder(latent_dim).to(device)\n",
    "flows = nn.ModuleList([make_flow(latent_dim).to(device) for _ in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45df54f",
   "metadata": {},
   "source": [
    "## Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937e8a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_postnet(encoder, flows, train_loader, epochs=5, lr=1e-3, device=\"cuda\") -> None:  # noqa: ANN001\n",
    "    encoder.train()\n",
    "    flows.train()\n",
    "\n",
    "    # Combine encoder & flows paramters so one optimizer updates all of them\n",
    "    params = list(encoder.parameters()) + list(flows.parameters())\n",
    "    optimizer = optim.Adam(params, lr=lr)\n",
    "\n",
    "    class_counts = torch.zeros(10).to(device)\n",
    "    for _, y in train_loader:\n",
    "        for c in range(10):\n",
    "            class_counts[c] += (y == c).sum()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)  # noqa: PLW2901\n",
    "\n",
    "            # Encode image -> latent vector\n",
    "            z = encoder(x)\n",
    "\n",
    "            # Compute density P(z|c) for all classes\n",
    "            densities = torch.stack(\n",
    "                [flow.log_prob(z).exp() for flow in flows],\n",
    "                dim=1,\n",
    "            )\n",
    "\n",
    "            # Compute pseudo-counts beta\n",
    "            beta = densities * class_counts\n",
    "\n",
    "            # Dirichlet parameters alpha\n",
    "            alpha = beta + 1.0\n",
    "            alpha0 = alpha.sum(dim=1, keepdim=True)\n",
    "\n",
    "            # Expected cross-entropy term\n",
    "            digamma = torch.digamma\n",
    "            expected_ce = digamma(alpha0) - digamma(alpha[range(len(y)), y])\n",
    "\n",
    "            # Entropy of Dirichlet\n",
    "            entropy = -(alpha * (digamma(alpha) - digamma(alpha0))).sum(dim=1)\n",
    "\n",
    "            # Total loss\n",
    "            loss = (expected_ce - entropy).mean()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs} - Loss: {total_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd79bb6d",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2792a911",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "    train_postnet(\n",
    "        encoder,\n",
    "        flows,\n",
    "        train_loader,\n",
    "        epochs=1,\n",
    "        lr=1e-3,\n",
    "        device=device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710a82ee",
   "metadata": {},
   "source": [
    "## Evaluation: Predictions & Accuracy\n",
    "\n",
    "For each input, we compute the Dirichlet posterior parameters, derive the posterior mean class probabilitiesm and calculate accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9d1413",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_postnet(encoder, flows, data_loader, device=\"cpu\") -> None:  # noqa: ANN001\n",
    "    encoder.eval()\n",
    "    flows.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in data_loader:\n",
    "            x, y = x.to(device), y.to(device)  # noqa: PLW2901\n",
    "\n",
    "            # Encode to latent space\n",
    "            z = encoder(x)\n",
    "\n",
    "            # Compute class-conditional densities\n",
    "            densities = torch.stack([flow.log_prob(z).exp() for flow in flows], dim=1)\n",
    "\n",
    "            # Compute Dirichlet parameters\n",
    "            beta = densities\n",
    "            alpha = beta + 1.0\n",
    "            alpha0 = alpha.sum(dim=1, keepdim=True)\n",
    "\n",
    "            # Posterior mean probabilities\n",
    "            probs = alpha / alpha0\n",
    "\n",
    "            # Predictions\n",
    "            preds = probs.argmax(dim=1)\n",
    "\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "evaluate_postnet(encoder, flows, test_loader, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc6207d",
   "metadata": {},
   "source": [
    "## Epistemic Uncertainty Extraction\n",
    "\n",
    "Posterior Networks quantify epistemic uncertainty using the total Dirichlet evidence, defined as the sum of all Dirichlet parameters for each class. High evidence indicates high confidence (in-distribution), while low evidence indicates uncertainty. Here, we compute evidence values for MNIST and FashionMNIST samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "113d2e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST α₀ shape: torch.Size([10000])\n",
      "FashionMNIST α₀ shape: torch.Size([10000])\n",
      "Mean ID α₀: 11.594731330871582\n",
      "Mean OOD α₀: 11.594731330871582\n"
     ]
    }
   ],
   "source": [
    "def compute_alpha0(encoder, flows, data_loader, device=\"cpu\") -> None:  # noqa: ANN001\n",
    "    encoder.eval()\n",
    "    flows.eval()\n",
    "\n",
    "    alpha0_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, _ in data_loader:\n",
    "            x = x.to(device)  # noqa: PLW2901\n",
    "\n",
    "            # Encode input → latent space\n",
    "            z = encoder(x)\n",
    "\n",
    "            # Compute class-conditional densities\n",
    "            densities = torch.stack([flow.log_prob(z).exp() for flow in flows], dim=1)\n",
    "\n",
    "            # Beta = density (no class-count scaling during evaluation)\n",
    "            beta = densities\n",
    "\n",
    "            # Dirichlet parameters\n",
    "            alpha = beta + 1.0\n",
    "\n",
    "            # Total evidence α₀\n",
    "            alpha0 = alpha.sum(dim=1)  # shape: [batch]\n",
    "\n",
    "            alpha0_list.append(alpha0.cpu())\n",
    "\n",
    "    # Return all α₀ values concatenated\n",
    "    return torch.cat(alpha0_list)\n",
    "\n",
    "\n",
    "id_alpha0 = compute_alpha0(encoder, flows, test_loader, device=device)\n",
    "ood_alpha0 = compute_alpha0(encoder, flows, ood_loader, device=device)\n",
    "\n",
    "print(\"MNIST α₀ shape:\", id_alpha0.shape)\n",
    "print(\"FashionMNIST α₀ shape:\", ood_alpha0.shape)\n",
    "\n",
    "print(\"Mean ID α₀:\", id_alpha0.mean().item())\n",
    "print(\"Mean OOD α₀:\", ood_alpha0.mean().item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "probly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
