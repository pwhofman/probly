{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b96f1324",
   "metadata": {},
   "source": [
    "# `probly` Tutorial — Evidential Classification Transformation\n",
    "This notebook is a practical introduction to the **Evidential Classification transformation** in `probly`. Evidential Deep Learning is a powerful and computationally efficient method for uncertainty quantification that differs significantly from sampling-based approaches like MC-Dropout.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fcf7db",
   "metadata": {},
   "source": [
    " We will start by explaining the core idea behind evidential learning and see how `probly`'s transformation helps you build such models. We will then walk through a PyTorch example to see how to get an uncertainty estimate from a **single forward pass**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca3b636",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part A — Introduction to Evidential Learning\n",
    "\n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e509ae",
   "metadata": {},
   "source": [
    "## 1. Concept: What is Evidential Classification?\n",
    "\n",
    "### 1.1 The Problem: Overconfident Softmax\n",
    "\n",
    "A standard classification network outputs logits, which are converted to probabilities using a `softmax` function. \n",
    "While useful, a high softmax probability (e.g., 0.99) is often misinterpreted as high model confidence. A model can be \"confidently wrong,\" especially on out-of-distribution data.\n",
    "\n",
    "### 1.2 The Evidential Approach: Learning \"Evidence\"\n",
    "Evidential Deep Learning reframes the problem. Instead of learning a direct mapping from input to class probabilities, the model learns to collect **evidence** for each class.\n",
    "Think of the model as a detective gathering clues for different suspects (the classes):\n",
    "-   If the model finds **many clues** pointing to one suspect and very few for others (e.g., evidence of `[100, 2, 5]`), it is very **confident**.\n",
    " -   If the model finds **very few clues for any suspect** (e.g., evidence of `[0.1, 0.2, 0.15]`), it is very **uncertain**. This might happen if the input is ambiguous or something the model has never seen before.\n",
    " The model's final output is a vector of these evidence scores. The total amount of evidence collected is a direct measure of confidence. \n",
    "\n",
    "  ### 1.3 The Evidential Transformation (probly)\n",
    "  The `probly` transformation helps you build an evidential model by ensuring the output can be interpreted as evidence.\n",
    "  -   You design your network as usual, but your final layer should output raw logits that represent the \"evidence.\"\n",
    "  -   The `evidential_classification` transformation simply **appends a `torch.nn.Softplus()` activation function.**\n",
    "  -   This ensures the evidence scores are always positive, a requirement for the underlying mathematical theory (the Dirichlet distribution).\n",
    "\n",
    "The uncertainty can then be calculated directly from these evidence scores in a **single forward pass**.\n",
    "\n",
    " ### 1.4 Short side‑by‑side comparison\n",
    "\n",
    "| Aspect                       | Evidential Classification                                        | Standard (Softmax) Classification |\n",
    "|------------------------------|------------------------------------------------------------------|-----------------------------------------            |\n",
    "| **Model Output**             | A vector of **evidence** for each class                          |  A vector of **probabilities** for each class.      |\n",
    "| **Final Activation**         | `Softplus` (to ensure positive evidence).                        | `Softmax` (to ensure probabilities sum to 1).       |\n",
    "| **Uncertainty Source**       | The **magnitude** of the total evidence.                         | No direct measure; high probability is a poor proxy.|\n",
    "| **Inference Cost**           |  **One single forward pass.**                                    | One single forward pass.                            |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e4bc88",
   "metadata": {},
   "source": [
    "## 2. Quickstart (PyTorch) \n",
    "Below: build a small MLP and apply `evidential_classification(model)` to see how the final activation is appended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fca29520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model:\n",
      " Sequential(\n",
      "  (0): Linear(in_features=10, out_features=32, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=32, out_features=3, bias=True)\n",
      ")\n",
      "\n",
      "With Evidential transformation:\n",
      " Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=32, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=32, out_features=3, bias=True)\n",
      "  )\n",
      "  (1): Softplus(beta=1.0, threshold=20.0)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from probly.transformation import evidential_classification\n",
    "\n",
    "\n",
    "def build_mlp(in_dim: int = 10, hidden: int = 32, out_dim: int = 3) -> nn.Sequential:\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_dim, hidden),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden, out_dim),\n",
    "    )\n",
    "\n",
    "\n",
    "model = build_mlp()\n",
    "print(\"Original model:\\n\", model)\n",
    "\n",
    "# Apply the Evidential Classification transformation\n",
    "model_evidential = evidential_classification(model)\n",
    "print(f\"\\nWith Evidential transformation:\\n\", model_evidential)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222cb0d8",
   "metadata": {},
   "source": [
    "### Notes on the structure\n",
    "-   Notice that the transformation has wrapped the original model in a `Sequential` module and **appended a `Softplus` layer** at the end.\n",
    "-   The output of this new model will now always be positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be99a4bf",
   "metadata": {},
   "source": [
    "## 3. Uncertainty from a Single Forward Pass\n",
    "The key advantage of evidential learning is that uncertainty can be calculated directly from the output of a single prediction.\n",
    "The output of the model gives us the evidence `alpha` for each class. The total evidence, or Dirichlet strength `S`, is the sum of all `alpha`. The uncertainty `u` is then simply the number of classes `K` divided by this strength.\n",
    " -   **High `S`** (lots of evidence) -> **Low `u`** (low uncertainty).\n",
    " -   **Low `S`** (little evidence) -> **High `u`** (high uncertainty)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7776fd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:\n",
      " tensor([[ 0.1167,  0.1689, -1.1233,  1.8116,  0.6322, -0.8759,  0.3580, -0.4363,\n",
      "         -0.7609,  1.5249]])\n",
      "\n",
      "Output Evidence (alpha):\n",
      " tensor([[0.8682, 0.9021, 0.5639]])\n",
      "\n",
      "Calculated Uncertainty: 0.5624\n",
      "\n",
      "Uncertainty for high evidence: 0.0273\n"
     ]
    }
   ],
   "source": [
    "from probly.quantification.classification import evidential_uncertainty\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Create a dummy evidential model\n",
    "model_evidential = evidential_classification(build_mlp())\n",
    "\n",
    "# A dummy input\n",
    "x = torch.randn(1, 10)\n",
    "\n",
    "# Get the evidence from a single forward pass\n",
    "with torch.no_grad():\n",
    "    evidence = model_evidential(x)\n",
    "\n",
    "# `probly` provides a function to calculate uncertainty directly\n",
    "uncertainty = evidential_uncertainty(evidence.numpy())\n",
    "\n",
    "print(\"Input data:\\n\", x)\n",
    "print(\"\\nOutput Evidence (alpha):\\n\", evidence)\n",
    "print(f\"\\nCalculated Uncertainty: {uncertainty.item():.4f}\")\n",
    "\n",
    "# Example with higher evidence (more confidence)\n",
    "high_evidence = torch.tensor([[100., 2., 5.]])\n",
    "low_uncertainty = evidential_uncertainty(high_evidence.numpy())\n",
    "print(f\"\\nUncertainty for high evidence: {low_uncertainty.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b18d18",
   "metadata": {},
   "source": [
    "## 4. Part A Summary\n",
    "\n",
    "In Part A, we introduced Evidential Deep Learning as a powerful alternative to standard softmax classification. Instead of outputting probabilities, an evidential model outputs \"evidence\" for each class. We learned that the `probly` transformation makes this easy by appending a `Softplus` activation to a standard network. The key advantage is that model uncertainty can be directly calculated from the magnitude of this evidence in a **single, deterministic forward pass**, making it much faster than sampling-based methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5f33a2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# # Part B — Applied Evidential Classification\n",
    "\n",
    "----\n",
    "\n",
    "In **Part A**, we learned the concept of the **Evidential Classification transformation**.\n",
    "In this **Part B**, we will apply it to a classification model, get a prediction, and calculate the uncertainty from a single forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35e283cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from probly.transformation import evidential_classification\n",
    "from probly.quantification.classification import evidential_uncertainty\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "class TinyNet(nn.Module):\n",
    "    \"\"\"A tiny neural network for demonstration.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(16, 32)\n",
    "        self.fc2 = nn.Linear(32, 8)\n",
    "        self.out = nn.Linear(8, 3)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.out(x)\n",
    "\n",
    "\n",
    "# Two dummy inputs: one \"easy\" (in-distribution), one \"hard\" (out-of-distribution)\n",
    "x_in_dist = torch.randn(1, 16)\n",
    "x_out_of_dist = torch.randn(1, 16) * 3 # Scaled to be \"different\"\n",
    "\n",
    "base_model = TinyNet().eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96532461",
   "metadata": {},
   "source": [
    "## 2. Apply the Evidential transformation\n",
    "We transform the base model with `evidential_classification()`. This appends the final `Softplus` activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b91e6b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): TinyNet(\n",
       "    (fc1): Linear(in_features=16, out_features=32, bias=True)\n",
       "    (fc2): Linear(in_features=32, out_features=8, bias=True)\n",
       "    (out): Linear(in_features=8, out_features=3, bias=True)\n",
       "  )\n",
       "  (1): Softplus(beta=1.0, threshold=20.0)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evidential_model = evidential_classification(base_model)\n",
    "evidential_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d91626",
   "metadata": {},
   "source": [
    "## 3. Inference and Uncertainty Quantification\n",
    "We feed both inputs through the model and compare the evidence and uncertainty scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "456d2ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- In-Distribution Sample ---\n",
      "Evidence: [[0.5922261  0.87855697 0.788048  ]]\n",
      "Probabilities: [[0.30277187 0.3572195  0.34000865]]\n",
      "Uncertainty: 0.5705\n",
      "\n",
      "--- Out-of-Distribution Sample ---\n",
      "Evidence: [[0.43761644 0.7769412  1.0811927 ]]\n",
      "Probabilities: [[0.27146605 0.33554095 0.39299297]]\n",
      "Uncertainty: 0.5665\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    evidence_in = evidential_model(x_in_dist)\n",
    "    evidence_out = evidential_model(x_out_of_dist)\n",
    "\n",
    "# Calculate predicted probabilities and uncertainty for both\n",
    "# Note: For a Dirichlet distribution, alpha_0 = sum(evidence + 1)\n",
    "# and probability_k = (evidence_k + 1) / alpha_0\n",
    "\n",
    "alpha_in = evidence_in + 1\n",
    "alpha_0_in = torch.sum(alpha_in, dim=1, keepdim=True)\n",
    "probs_in = alpha_in / alpha_0_in\n",
    "uncertainty_in = evidential_uncertainty(evidence_in.numpy()).item()\n",
    "\n",
    "alpha_out = evidence_out + 1\n",
    "alpha_0_out = torch.sum(alpha_out, dim=1, keepdim=True)\n",
    "probs_out = alpha_out / alpha_0_out\n",
    "uncertainty_out = evidential_uncertainty(evidence_out.numpy()).item()\n",
    "\n",
    "\n",
    "print(\"--- In-Distribution Sample ---\")\n",
    "print(\"Evidence:\", evidence_in.numpy())\n",
    "print(\"Probabilities:\", probs_in.numpy())\n",
    "print(f\"Uncertainty: {uncertainty_in:.4f}\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Out-of-Distribution Sample ---\")\n",
    "print(\"Evidence:\", evidence_out.numpy())\n",
    "print(\"Probabilities:\", probs_out.numpy())\n",
    "print(f\"Uncertainty: {uncertainty_out:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3065dd1",
   "metadata": {},
   "source": [
    "## 4. Visualization – Comparing Confidence\n",
    " We can visualize the predicted probabilities. Notice that for the out-of-distribution sample, the model is less \"peaked\" and the overall uncertainty score is higher, because the total evidence collected is lower.\n",
    "//TODO visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba653f5b",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    "# # Final Summary — Evidential Transformation Tutorial\n",
    "\n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bc1787",
   "metadata": {},
   "source": [
    "This tutorial demonstrated how to use the **Evidential Classification Transformation** in `probly` to build models that can directly quantify their own uncertainty.\n",
    "We learned that instead of outputting probabilities, an evidential model outputs **evidence** for each class. The `probly` transformation facilitates this by appending a `Softplus` layer to ensure evidence is positive. The key advantage of this method is its efficiency: a meaningful uncertainty score can be derived from the magnitude of the evidence in a **single forward pass**. We saw this in practice, where an out-of-distribution sample correctly resulted in lower total evidence and therefore a higher uncertainty score. This makes Evidential Learning a powerful and computationally cheap tool for building more reliable and self-aware models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "probly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
