{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc17cb015b839eba",
   "metadata": {
    "collapsed": true
   },
   "source": "# Sub-Ensembles for Fast Uncertainty Estimation"
  },
  {
   "cell_type": "markdown",
   "id": "7a82ac436b05f802",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "A common approach to obtaining high-quality estimates are **Full Ensembles**, where multiple neural networks are trained independently and their predictions are combined. While Full Ensembles are simple and highly effective, they come with substantial computational and memory cost: each model requires full training and storage. This makes them difficult to use in resource-constrained environments or during fast model development cycles.\n",
    "\n",
    "To address these limitations, recent research\n",
    "> [Deep Sub-Ensembles for Fast Uncertainty Estimation in Image Classification](https://arxiv.org/pdf/1910.08168)\n",
    "\n",
    "has proposed **Sub-Ensembles**, a technique that retains the predictive benefits of Full Ensembles while drastically reducing training time and interference overhead. Instead of training multiple full models, Sub-Ensembles share a large portion of the network (the backbone) and create several lightweight, partially independent branches (heads). These branches act as an ensemble member, providing diversity at a fraction of the computational cost.\n",
    "\n",
    "The goal of the notebook is to:\n",
    "- introduce the core idea behind (Sub-)Ensembles,\n",
    "- evaluate their ability to estimate predictive uncertainty,\n",
    "- demonstrate how they can be implemented in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756bc15d04af473b",
   "metadata": {},
   "source": "## What are Full Ensembles?"
  },
  {
   "cell_type": "markdown",
   "id": "1154a4a6e3af4ce3",
   "metadata": {},
   "source": [
    "### Ensembles\n",
    "\n",
    "offer a method where multiple models are trained independently and their predictions are combined to improve uncertainty quantification. The idea is that by aggregating the outputs of several models, we can reduce variance, improve robustness and achieve better generalization than a single model. Ensembles are particularly effective where individual models are prone to overfitting or high variance."
   ]
  },
  {
   "cell_type": "code",
   "id": "76bf56ec65ac9d68",
   "metadata": {},
   "source": [
    "from matplotlib import patches\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18, 5))\n",
    "ax.set_xlim(0, 18)\n",
    "ax.set_ylim(0, 5)\n",
    "ax.axis(\"off\")\n",
    "\n",
    "\n",
    "def draw_block(x: float, y: float, width: float, height: float, text: str, color: str = \"lightblue\") -> None:\n",
    "    rect = patches.FancyBboxPatch((x, y), width, height, boxstyle=\"round,pad=0.02\", edgecolor=\"black\", facecolor=color)\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(x + width / 2, y + height / 2, text, ha=\"center\", va=\"center\", fontsize=10)\n",
    "\n",
    "\n",
    "def draw_arrow(x1: float, y1: float, x2: float, y2: float) -> None:\n",
    "    ax.annotate(\"\", xy=(x2, y2), xytext=(x1, y1), arrowprops={\"arrowstyle\": \"->\", \"lw\": 2, \"color\": \"black\"})\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Standard Model\n",
    "draw_block(0.5, 2, 1, 1, \"Input (Image)\", color=\"skyblue\")\n",
    "draw_block(2.5, 2, 1, 1, \"Base Model\", color=\"lightgreen\")\n",
    "draw_block(4.5, 2, 1, 1, \"Output\", color=\"lightcoral\")\n",
    "draw_arrow(1.5, 2.5, 2.5, 2.5)\n",
    "draw_arrow(3.5, 2.5, 4.5, 2.5)\n",
    "ax.text(3.0, 4, \"Standard Model\", fontsize=12, fontweight=\"bold\", ha=\"center\")\n",
    "\n",
    "# -----------------------------\n",
    "# Full Ensemble\n",
    "ensemble_x = 12\n",
    "ax.text(ensemble_x + 0.5, 4.5, \"Full Ensemble\", fontsize=12, fontweight=\"bold\", ha=\"center\")\n",
    "\n",
    "# Input\n",
    "draw_block(ensemble_x - 2.0, 2.0, 1, 1, \"Input (Image)\", color=\"skyblue\")\n",
    "\n",
    "# Three independent models\n",
    "for y in [1.25, 2.5, 3.75]:\n",
    "    draw_arrow(ensemble_x - 1.0, 2.5, ensemble_x, y)\n",
    "for i, y in enumerate([3.2, 2, 0.8]):\n",
    "    draw_block(ensemble_x, y, 1, 1, f\"Base Model\\nT{i + 1}\", color=\"lightgreen\")\n",
    "\n",
    "# Combination\n",
    "for y in [1.25, 2.5, 3.75]:\n",
    "    draw_arrow(ensemble_x + 1.0, y, ensemble_x + 2.0, 2.5)\n",
    "draw_block(ensemble_x + 2.0, 2.0, 1, 1, \"Prediction\", color=\"white\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1f176a7ca67176bb",
   "metadata": {},
   "source": [
    "## What are Sub-Ensembles?\n",
    "\n",
    "A **Sub-Ensemble** generates multiple subnetworks from a single base model. This can be achieved by dividing a neural network into two subnetworks, the trunk network $T$ and the task network $K$. The full output for an input $x$ then is $K(T(x))$.\n",
    "Since all subnetworks share the same base feature extractor (**backbone**), instead of training multiple independent neural networks from scratch, the forward pass is much faster compared to evaluating multiple fully independent networks.\n",
    "Each subnetwork produces its own prediction, and the final output is obtained by averaging across all subnetworks. The **model uncertainty** is served by the variance of the predictions from each subnetwork.\n",
    "\n",
    "Overall they provide:\n",
    "- reduced memory and training cost when compared to standard Full Ensembles\n",
    "- reduced parameter overhead improves predictive performance and reliability of uncertainty estimates\n",
    "- practical solution for robust uncertainty quantification at scale\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "519eb697988e32f4",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "ax.set_xlim(0, 20)\n",
    "ax.set_ylim(0, 5)\n",
    "ax.axis(\"off\")\n",
    "\n",
    "\n",
    "def draw_block(x: float, y: float, width: float, height: float, text: str, color: str = \"lightblue\") -> None:\n",
    "    rect = patches.FancyBboxPatch((x, y), width, height, boxstyle=\"round,pad=0.02\", edgecolor=\"black\", facecolor=color)\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(x + width / 2, y + height / 2, text, ha=\"center\", va=\"center\", fontsize=10)\n",
    "\n",
    "\n",
    "def draw_arrow(x1: float, y1: float, x2: float, y2: float) -> None:\n",
    "    ax.annotate(\"\", xy=(x2, y2), xytext=(x1, y1), arrowprops={\"arrowstyle\": \"->\", \"lw\": 2, \"color\": \"black\"})\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Full Ensemble\n",
    "ensemble_x = 2.5\n",
    "ax.text(ensemble_x + 1.5, 4.5, \"Full Ensemble\", fontsize=12, fontweight=\"bold\", ha=\"center\")\n",
    "\n",
    "# Input\n",
    "draw_block(ensemble_x - 2.0, 2.0, 1, 1, \"Input (Image)\", color=\"skyblue\")\n",
    "\n",
    "# Three independent models\n",
    "for y in [1.25, 2.5, 3.75]:\n",
    "    draw_arrow(ensemble_x - 1.0, 2.5, ensemble_x, y)\n",
    "for i, y in enumerate([3.2, 2, 0.8]):\n",
    "    draw_block(ensemble_x, y, 1, 1, f\"Trunk  T{i + 1}\", color=\"lightgreen\")\n",
    "    draw_block(ensemble_x + 2.0, y, 1, 1, f\"Task T{i + 1}\", color=\"lightcoral\")\n",
    "    draw_arrow(ensemble_x + 1.0, y + 0.5, ensemble_x + 2.0, y + 0.5)\n",
    "\n",
    "# Combination\n",
    "for y in [1.25, 2.5, 3.75]:\n",
    "    draw_arrow(ensemble_x + 3.0, y, ensemble_x + 4.0, 2.5)\n",
    "draw_block(ensemble_x + 4.0, 2.0, 1, 1, \"Combination\", color=\"brown\")\n",
    "\n",
    "# Prediction\n",
    "draw_arrow(ensemble_x + 5.0, 2.5, ensemble_x + 6.0, 2.5)\n",
    "draw_block(ensemble_x + 6.0, 2.0, 1, 1, \"Prediction\", color=\"white\")\n",
    "\n",
    "# -----------------------------\n",
    "# SubEnsemble\n",
    "sub_ensemble_x = 10.0\n",
    "ax.text(sub_ensemble_x + 4.5, 4.5, \"Sub Ensemble\", fontsize=12, fontweight=\"bold\", ha=\"center\")\n",
    "\n",
    "# Input\n",
    "draw_block(sub_ensemble_x, 2.0, 1, 1, \"Input (Image)\", color=\"skyblue\")\n",
    "\n",
    "# Shared Feature Extractor\n",
    "draw_arrow(sub_ensemble_x + 1.0, 2.5, sub_ensemble_x + 2.0, 2.5)\n",
    "draw_block(sub_ensemble_x + 2.0, 2.0, 1, 1, \"Shared\\nfeature\\nextractor\", color=\"lightgreen\")\n",
    "\n",
    "# Three task models\n",
    "for y in [1.25, 2.5, 3.75]:\n",
    "    draw_arrow(sub_ensemble_x + 3.0, 2.5, sub_ensemble_x + 4.0, y)\n",
    "for i, y in enumerate([3.2, 2, 0.8]):\n",
    "    draw_block(sub_ensemble_x + 4.0, y, 1, 1, f\"Task  T{i + 1}\", color=\"lightcoral\")\n",
    "\n",
    "# Combination\n",
    "for y in [1.25, 2.5, 3.75]:\n",
    "    draw_arrow(sub_ensemble_x + 5.0, y, sub_ensemble_x + 6.0, 2.5)\n",
    "draw_block(sub_ensemble_x + 6.0, 2.0, 1, 1, \"Combination\", color=\"brown\")\n",
    "\n",
    "# Prediction\n",
    "draw_arrow(sub_ensemble_x + 7.0, 2.5, sub_ensemble_x + 8.0, 2.5)\n",
    "draw_block(sub_ensemble_x + 8.0, 2.0, 1, 1, \"Prediction\", color=\"white\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cf9819bb90692b3b",
   "metadata": {},
   "source": [
    "## Code Demo\n",
    "\n",
    "This snippet shows how a simple sequential base model is repurposed into a Sub-Ensemble model. The base model is split into a shared feature extractor and multiple independent heads. The output is obtained by averaging the head predictions during the forward pass."
   ]
  },
  {
   "cell_type": "code",
   "id": "7fa52cdd08e7a16c",
   "metadata": {},
   "source": [
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "base_model = nn.Sequential(\n",
    "    nn.Linear(2, 2),\n",
    "    nn.Linear(2, 2),\n",
    "    nn.Linear(2, 2),\n",
    ")\n",
    "\n",
    "\n",
    "class SubEnsemble(nn.Module):\n",
    "    \"\"\"Sub-Ensemble model that repurposes a base model into multiple heads sharing the same feature extractor.\n",
    "\n",
    "    Attributes:\n",
    "        n_heads: int, Number of heads.\n",
    "        feature_extractor: nn.Sequential, Feature extractor.\n",
    "        heads: nn.ModuleList, List of heads.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model: nn.Module, n_heads: int = 3) -> None:\n",
    "        \"\"\"Initializes the SubEnsemble by splitting the provided base model.\n",
    "\n",
    "        Args:\n",
    "            model: nn.Module, the sequential base model.\n",
    "            n_heads: int, optional, number of ensemble heads\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the provided model is not a nn.Sequential or contains fewer than two layers.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        if not isinstance(model, nn.Sequential) or len(model) < 2:\n",
    "            msg = \"Base model must be an nn.Sequential with at least 2 layers.\"\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        # Shared feature extractor = all layers except last\n",
    "        self.feature_extractor = nn.Sequential(*model[:-1])\n",
    "\n",
    "        # Last layer of the base model\n",
    "        last_layer = model[-1]\n",
    "\n",
    "        # Create multiple head copies\n",
    "        self.heads = nn.ModuleList()\n",
    "        for _ in range(n_heads):\n",
    "            new_head = copy.deepcopy(last_layer)\n",
    "\n",
    "            # Reinitialize parameters\n",
    "            for layer in new_head.modules():\n",
    "                if hasattr(layer, \"reset_parameters\"):\n",
    "                    layer.reset_parameters()\n",
    "\n",
    "            self.heads.append(new_head)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass through the shared feature extractor and all ensemble heads.\n",
    "\n",
    "         Returns the mean prediction across heads.\n",
    "\n",
    "        Args:\n",
    "            x: torch.Tensor, input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor, averaged predictions across all ensemble heads.\n",
    "        \"\"\"\n",
    "        # Shared feature Extractor\n",
    "        features = self.feature_extractor(x)\n",
    "\n",
    "        # Each head produces a prediction\n",
    "        outputs = [head(features) for head in self.heads]\n",
    "\n",
    "        # Stack + Mean\n",
    "        return torch.stack(outputs).mean(dim=0)\n",
    "\n",
    "\n",
    "# Transform base_model into Sub-Ensemble with 3 heads\n",
    "sub_ensemble = SubEnsemble(base_model, n_heads=3)\n",
    "\n",
    "# Output\n",
    "print(\"Base model:\", base_model)\n",
    "print(\"SubEnsemble:\", sub_ensemble)\n",
    "print(\"SubEnsemble type:\", type(sub_ensemble))\n",
    "print(\"Is Sub-Ensemble?\", isinstance(sub_ensemble, SubEnsemble))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d8a01d00b6cd8af1",
   "metadata": {},
   "source": "Note that the heads can also be created by using the already implemented **generate_torch_ensemble** function from probly"
  },
  {
   "cell_type": "code",
   "id": "a0f5f2cf95309a57",
   "metadata": {},
   "source": [
    "from src.probly.transformation.ensemble.torch import generate_torch_ensemble\n",
    "\n",
    "head, num_heads = [nn.Linear(2, 2), 3]\n",
    "\n",
    "heads = generate_torch_ensemble(head, num_heads)\n",
    "\n",
    "print(\"(heads):\", heads)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "65572edc5e514a34",
   "metadata": {},
   "source": "SubEnsemble can then be defined like this:"
  },
  {
   "cell_type": "code",
   "id": "aaf57daff4d079e4",
   "metadata": {},
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from src.probly.transformation.ensemble.torch import generate_torch_ensemble\n",
    "\n",
    "base_model = nn.Sequential(\n",
    "    nn.Linear(2, 2),\n",
    "    nn.Linear(2, 2),\n",
    "    nn.Linear(2, 2),\n",
    ")\n",
    "\n",
    "\n",
    "class SubEnsemble(nn.Module):\n",
    "    \"\"\"Sub-Ensemble model that repurposes a base model into multiple heads sharing the same feature extractor.\n",
    "\n",
    "    Attributes:\n",
    "        n_heads: int, number of heads.\n",
    "        feature_extractor: nn.Sequential, shared feature extractor.\n",
    "        heads: nn.ModuleList, list of heads.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model: nn.Module, n_heads: int = 3) -> None:\n",
    "        \"\"\"Initializes the SubEnsemble by splitting the provided base model.\n",
    "\n",
    "        Args:\n",
    "            model: nn.Module, the sequential base model.\n",
    "            n_heads: int, optional, number of ensemble heads\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the provided model is not a nn.Sequential or contains fewer than two layers.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        if not isinstance(model, nn.Sequential) or len(model) < 2:\n",
    "            msg = \"Base model must be an nn.Sequential with at least 2 layers.\"\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        # Create feature extractor\n",
    "        self.feature_extractor = nn.Sequential(*model[:-1])\n",
    "\n",
    "        # Create n_heads heads\n",
    "        self.heads = generate_torch_ensemble(model[-1], n_heads)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass through the shared feature extractor and all ensemble heads.\n",
    "\n",
    "         Returns the mean prediction across heads.\n",
    "\n",
    "        Args:\n",
    "            x: torch.Tensor, input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor, averaged predictions across all ensemble heads.\n",
    "        \"\"\"\n",
    "        features = self.feature_extractor(x)\n",
    "        outputs = [h(features) for h in self.heads]\n",
    "        return torch.stack(outputs).mean(dim=0)\n",
    "\n",
    "\n",
    "# Transform base model\n",
    "sub_ensemble = SubEnsemble(base_model, n_heads=3)\n",
    "\n",
    "# Output\n",
    "print(\"SubEnsemble:\", sub_ensemble)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "52e9be4327358826",
   "metadata": {},
   "source": [
    "## Evaluation of Sub-Ensembles\n",
    "\n",
    "To evaluate the benefits of Sub-Ensembles, we conducted a series of experiments on the CIFAR-10 dataset. We compare traditional training approaches - such as single networks - with both Full Ensembles and Sub-Ensembles.\n",
    "\n",
    "The experiment demonstrates evaluation metrics such as accuracy, confidence, negative log-likelihood (NLL) and training time. This setup provides a clear, reproducible framework to assess the performance of Sub-Ensembles relative to other probabilistic modelling techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aad4843942803ad",
   "metadata": {},
   "source": "### Understanding the metrics"
  },
  {
   "cell_type": "markdown",
   "id": "fb138c266d0cb3a7",
   "metadata": {},
   "source": [
    "1. **Accuracy**\n",
    "    - The fraction of correctly classified samples over the total number of samples.\n",
    "    - Higher accuracy indicates better overall predictive performance.\n",
    "2. **Confidence**\n",
    "    - The average predicted probability assigned to the predicted class.\n",
    "    - Higher confidence means the model is more certain about its predictions, regardless of whether they are correct.\n",
    "3. **Negative Log-Likelihood** (NLL)\n",
    "    - Measures how well the predicted probabilities match the true labels.\n",
    "    - Lower NLL indicates the model assigns higher probability to the correct labels, capturing both correctness and confidence.\n",
    "4. **Training Time**\n",
    "    -  The total time (in s) the model takes to complete training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82caac84cba3e0d7",
   "metadata": {},
   "source": [
    "**Keeping it simple**\n",
    "- **Accuracy:** how often the model gets the label right,\n",
    "- **Confidence:** how sure the model is about its predictions,\n",
    "- **Negative log-likelihood:** how well the modelÂ´s probabilities match the true label,\n",
    "- **Training Time:** how long the model took to complete training (in seconds)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237b70aabe4dca24",
   "metadata": {},
   "source": "### The CIFAR experiment"
  },
  {
   "cell_type": "markdown",
   "id": "8766c36034973c2c",
   "metadata": {},
   "source": [
    "We used a lightweight model designed for CIFAR-10 classification. It consists of two stages:\n",
    "1. Features:\n",
    "Two convolutional blocks that map the input images to 32-channel feature maps, extracting low-level features.\n",
    "\n",
    "2. Classifier:\n",
    "Two additional convolutional blocks with increasing channel depth (32 $\\to$ 64 $\\to$ 128) and spatial downsampling via stride 2. The resulting feature maps are globally pooled, flattened and passed through a linear layer to produce predictions for the 10 classes.\n",
    "\n",
    "Furthermore, 10 epochs were used for training with 5 ensemble members and subensemble heads respectively."
   ]
  },
  {
   "cell_type": "code",
   "id": "45264aae278f0f30",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "results = {\n",
    "    \"Base\": {\n",
    "        \"Accuracy\": 0.7012999999999999,\n",
    "        \"Confidence\": 0.7491816083590189,\n",
    "        \"Negative log-likelihood\": 0.8654566344579061,\n",
    "        \"train_time\": 111.25705416997273,\n",
    "    },\n",
    "    \"Full Ensemble\": {\n",
    "        \"Accuracy\": 0.7285333333333334,\n",
    "        \"Confidence\": 0.6695056756337484,\n",
    "        \"Negative log-likelihood\": 0.7785670175552367,\n",
    "        \"train_time\": 565.2635641892751,\n",
    "    },\n",
    "    \"Sub-Ensemble\": {\n",
    "        \"Accuracy\": 0.7333333333333334,\n",
    "        \"Confidence\": 0.4354797601699829,\n",
    "        \"Negative log-likelihood\": 1.0467662965138753,\n",
    "        \"train_time\": 229.0507171948751,\n",
    "    },\n",
    "}\n",
    "\n",
    "colors = [\"tab:green\", \"tab:blue\", \"tab:purple\"]\n",
    "models = list(results.keys())\n",
    "\n",
    "# Plot 1: Accuracy & Uncertainty Comparison\n",
    "metrics = [\"Accuracy\", \"Confidence\", \"Negative log-likelihood\"]\n",
    "x = np.arange(len(metrics))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "for i, m in enumerate(models):\n",
    "    values = [float(results[m][met]) for met in metrics]\n",
    "    ax.bar(x + i * bar_width, values, bar_width, color=colors[i], label=m)\n",
    "\n",
    "ax.set_xticks(x + bar_width * (len(models) - 1) / 2)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.set_ylabel(\"Value\")\n",
    "ax.set_title(\"Model Comparison: Accuracy, Uncertainty & NLL\")\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Training Time Comparison\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.bar(models, [float(results[m][\"train_time\"]) for m in models], color=colors)\n",
    "ax.set_ylabel(\"Training Time (s)\")\n",
    "ax.set_title(\"Training Time Comparison\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "845d2fc81fb1dbcd",
   "metadata": {},
   "source": [
    "- The **Base model** reaches an accuracy of 70.1%, with relatively high confidence (0.75) and a negative log-likelihood of 0.87, indicating that while it performs reasonably well, it may be overconfident in its predictions.\n",
    "\n",
    "- The **Full Ensemble** model achieves slightly higher accuracy (72.9%), with moderate confidence (0.67) and the lowest negative log-likelihood (0.78), showing that combining multiple models improves predictive performance und uncertainty estimation.\n",
    "\n",
    "- The **Sub-Ensemble** model achieves balance between efficiency and performance: accuracy of 73.3%, lower confidence (0.44), and higher negative log-likelihood (1.05), while requiring much less training time (speedup of ~2.46) than the Full Ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197a7bc98714008a",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "Full Ensembles deliver the most robust predictions and the most reliable uncertainty estimates at high computational cost.\n",
    "Sub-Ensembles, achieve a strong balance between performance and efficiency. They offer a **practical middle ground** with comparable uncertainty quality at a fraction of the training time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc45b24d95df488",
   "metadata": {},
   "source": "## Live experiment"
  },
  {
   "cell_type": "markdown",
   "id": "71d9e08a338dc662",
   "metadata": {},
   "source": "Using sklearn we can generate a synthetic dataset for a demonstration. This dataset of `3.000 samples` with `20 features` is generated using make_classification, followed by a train-validation split and standardization. A small fully connected neural network serves as the base architecture, which is then transformed into different model variants: Base, Full Ensemble (`3 members`) and Sub-Ensemble (`3 heads`). All models are trained for `100 epochs` and evaluated on the validation set in terms of accuracy, confidence, negative log-likelihood and training time."
  },
  {
   "cell_type": "markdown",
   "id": "a96b54c09534989c",
   "metadata": {},
   "source": "#### Imports"
  },
  {
   "cell_type": "markdown",
   "id": "4d316ce6fb22c0a6",
   "metadata": {},
   "source": "Necessary imports:"
  },
  {
   "cell_type": "code",
   "id": "8205342422bb5b69",
   "metadata": {},
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from src.probly.transformation.ensemble.torch import generate_torch_ensemble"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "342f1a6f8e5d9750",
   "metadata": {},
   "source": "#### Models"
  },
  {
   "cell_type": "markdown",
   "id": "9d5c90aa357832c3",
   "metadata": {},
   "source": "Let`s begin with a base model:"
  },
  {
   "cell_type": "code",
   "id": "d5784f86a8557fe5",
   "metadata": {},
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(20, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 2),\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "233bd5570e9e3574",
   "metadata": {},
   "source": "We then need to define the class Ensemble which will be done using `generate_torch_ensemble` from probly:"
  },
  {
   "cell_type": "code",
   "id": "7f36fe116c1a00f3",
   "metadata": {},
   "source": [
    "class Ensemble(nn.Module):\n",
    "    \"\"\"Sub-Ensemble model that repurposes a base model into multiple Ensemble-members.\"\"\"\n",
    "\n",
    "    def __init__(self, model: nn.Module, n_members: int = 3) -> None:\n",
    "        \"\"\"Initializes the Ensemble by splitting the provided base model n_members times.\"\"\"\n",
    "        super().__init__()\n",
    "        self.models = generate_torch_ensemble(model, n_members)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass with Stack + Mean for all ensemble members.\"\"\"\n",
    "        outputs = [m(x) for m in self.models]\n",
    "        return torch.stack(outputs).mean(dim=0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ecd7986c7ff7b7cb",
   "metadata": {},
   "source": "Now we can transform the models needed:"
  },
  {
   "cell_type": "code",
   "id": "34376aa33dbd93f2",
   "metadata": {},
   "source": [
    "base_model = model\n",
    "ensemble_model = Ensemble(model=model, n_members=3)\n",
    "sub_ensemble_model = SubEnsemble(model=model, n_heads=3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e1edd0b94e3f1c2c",
   "metadata": {},
   "source": "#### Data"
  },
  {
   "cell_type": "markdown",
   "id": "69fc5f680db5ccce",
   "metadata": {},
   "source": "To generating data!"
  },
  {
   "cell_type": "code",
   "id": "ca810352a5a8052c",
   "metadata": {},
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=3000,\n",
    "    n_features=20,\n",
    "    n_informative=5,\n",
    "    n_redundant=5,\n",
    "    n_classes=2,\n",
    "    class_sep=0.5,\n",
    "    flip_y=0.1,\n",
    "    random_state=0,\n",
    ")\n",
    "X = X.astype(\"float32\")\n",
    "y = y.astype(\"int64\")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=0,\n",
    "    stratify=y,\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "train_dataset = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "val_dataset = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5e6cfdfd886a67e3",
   "metadata": {},
   "source": "#### What about training?"
  },
  {
   "cell_type": "markdown",
   "id": "f0af06a2af8a0b76",
   "metadata": {},
   "source": "We begin with a training function for a single model:"
  },
  {
   "cell_type": "code",
   "id": "1f6d37133e58b181",
   "metadata": {},
   "source": [
    "def train_single(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader = train_loader,\n",
    "    criterion: nn.CrossEntropyLoss = criterion,\n",
    "    epochs: int = 100,\n",
    ") -> None:\n",
    "    model.train()\n",
    "\n",
    "    single_optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    for _ in range(epochs):\n",
    "        for xb, yb in loader:\n",
    "            single_optimizer.zero_grad()\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            loss.backward()\n",
    "            single_optimizer.step()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "42848a2cd2f64912",
   "metadata": {},
   "source": "To train an Ensemble we can call  `train_single` for each ensemble member like this:"
  },
  {
   "cell_type": "code",
   "id": "844ef9ced1a7bfcd",
   "metadata": {},
   "source": [
    "def train_ensemble(\n",
    "    ensemble: Ensemble,\n",
    "    loader: DataLoader = train_loader,\n",
    "    criterion: nn.CrossEntropyLoss = criterion,\n",
    "    epochs: int = 100,\n",
    ") -> None:\n",
    "    for _, member in enumerate(ensemble.models):\n",
    "        train_single(member, loader, criterion, epochs)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e40b54a737ca0ebd",
   "metadata": {},
   "source": "Finally, training the SubEnsemble. We will train the feature_extractor together with the first head, while the other heads are frozen. We then freeze the feature_extractor and train the remaining heads."
  },
  {
   "cell_type": "code",
   "id": "d10bdcd6a06863d0",
   "metadata": {},
   "source": [
    "def train_subensemble(\n",
    "    subensemble: SubEnsemble,\n",
    "    loader: DataLoader = train_loader,\n",
    "    criterion: nn.CrossEntropyLoss = criterion,\n",
    "    epochs: int = 100,\n",
    ") -> None:\n",
    "    subensemble.feature_extractor.train()\n",
    "    subensemble.heads[0].train()\n",
    "    # Freeze all heads except first\n",
    "    for h in subensemble.heads[1:]:\n",
    "        h.eval()\n",
    "\n",
    "    optimizer_fe = torch.optim.Adam(\n",
    "        list(subensemble.feature_extractor.parameters()) + list(subensemble.heads[0].parameters()),\n",
    "        lr=0.001,\n",
    "    )\n",
    "    # Training feature_extractor + first head\n",
    "    for _ in range(epochs):\n",
    "        for xb, yb in loader:\n",
    "            optimizer_fe.zero_grad()\n",
    "            features = subensemble.feature_extractor(xb)\n",
    "            preds = subensemble.heads[0](features)\n",
    "            loss = criterion(preds, yb)\n",
    "            loss.backward()\n",
    "            optimizer_fe.step()\n",
    "\n",
    "    # Freeze feature_extractor\n",
    "    subensemble.feature_extractor.eval()\n",
    "    for head in subensemble.heads:\n",
    "        head.train()\n",
    "    # Training remaining heads\n",
    "    optimizer_head = torch.optim.Adam(head.parameters(), lr=0.001)\n",
    "    for _ in range(epochs):\n",
    "        for xb, yb in loader:\n",
    "            optimizer_head.zero_grad()\n",
    "            with torch.no_grad():\n",
    "                features = subensemble.feature_extractor(xb)\n",
    "            loss = 0.0\n",
    "            for head in subensemble.heads[1:]:\n",
    "                preds = head(features)\n",
    "                loss = criterion(preds, yb)\n",
    "            loss.backward()\n",
    "            optimizer_head.step()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1edfdfc5a33cffda",
   "metadata": {},
   "source": "#### Evaluation"
  },
  {
   "cell_type": "markdown",
   "id": "37898b49b6d7f040",
   "metadata": {},
   "source": "To properly evaluate we define:"
  },
  {
   "cell_type": "code",
   "id": "3ddce04241fcd48e",
   "metadata": {},
   "source": [
    "def evalu(model: nn.Module, loader: DataLoader = val_loader) -> None:\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    nll = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            preds = model(xb)\n",
    "            nll += F.cross_entropy(preds, yb, reduction=\"sum\").item()\n",
    "            probs = F.softmax(preds, dim=1)\n",
    "            all_probs.append(probs)\n",
    "            all_preds.append(torch.argmax(probs, dim=1))\n",
    "            all_labels.append(yb)\n",
    "\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "\n",
    "    acc = accuracy_score(all_labels.cpu(), all_preds.cpu())\n",
    "    confidence = (probs.max(dim=1)).values.mean().item()\n",
    "\n",
    "    return {\n",
    "        \"Accuracy\": acc,\n",
    "        \"Confidence\": confidence,\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ae07e329a61071af",
   "metadata": {},
   "source": "#### Let's get to it!"
  },
  {
   "cell_type": "markdown",
   "id": "3a15651411ac833f",
   "metadata": {},
   "source": "We train each model, calling the appropriate function."
  },
  {
   "cell_type": "code",
   "id": "260d27683887ae2a",
   "metadata": {},
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start_time = time.time()\n",
    "train_single(model, train_loader, criterion, epochs=100)\n",
    "base_time = time.time() - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "train_ensemble(ensemble_model, train_loader, criterion, epochs=100)\n",
    "ensemble_time = time.time() - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "train_subensemble(sub_ensemble_model, train_loader, criterion, epochs=100)\n",
    "subensemble_time = time.time() - start_time"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "db11514bc79ab73b",
   "metadata": {},
   "source": "To evaluation and beyond!"
  },
  {
   "cell_type": "code",
   "id": "df316dd2550279f1",
   "metadata": {},
   "source": [
    "models = [\n",
    "    (\"Base\", base_model),\n",
    "    (\"Full Ensemble\", ensemble_model),\n",
    "    (\"Sub-Ensemble\", sub_ensemble_model),\n",
    "]\n",
    "\n",
    "results = {}\n",
    "\n",
    "res_base = evalu(base_model, val_loader)\n",
    "res_base[\"train_time\"] = base_time\n",
    "results[\"Base\"] = res_base\n",
    "\n",
    "res_ensemble = evalu(ensemble_model, val_loader)\n",
    "res_ensemble[\"train_time\"] = ensemble_time\n",
    "results[\"Full Ensemble\"] = res_ensemble\n",
    "\n",
    "res_subensemble = evalu(sub_ensemble_model, val_loader)\n",
    "res_subensemble[\"train_time\"] = subensemble_time\n",
    "results[\"Sub-Ensemble\"] = res_subensemble"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4548b7160ac65f65",
   "metadata": {},
   "source": "### The results"
  },
  {
   "cell_type": "code",
   "id": "20afb84419c2152",
   "metadata": {},
   "source": [
    "colors = [\"tab:green\", \"tab:blue\", \"tab:purple\"]\n",
    "models = list(results.keys())\n",
    "\n",
    "# Plot 1: Accuracy & Confidence Comparison\n",
    "metrics = [\"Accuracy\", \"Confidence\"]\n",
    "x = np.arange(len(metrics))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "for i, m in enumerate(models):\n",
    "    values = [float(results[m][met]) for met in metrics]\n",
    "    ax.bar(x + i * bar_width, values, bar_width, color=colors[i], label=m)\n",
    "\n",
    "ax.set_xticks(x + bar_width * (len(models) - 1) / 2)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.set_ylabel(\"Value\")\n",
    "ax.set_title(\"Model Comparison: Accuracy & Confidence\")\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Training Time Comparison\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.bar(models, [float(results[m][\"train_time\"]) for m in models], color=colors)\n",
    "ax.set_ylabel(\"Training Time (s)\")\n",
    "ax.set_title(\"Training Time Comparison\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8c31af4e01f64841",
   "metadata": {},
   "source": [
    "### Disclaimer\n",
    "\n",
    "Keep in mind that this experiment uses synthetic data, the results can vary.\n",
    "\n",
    "Furthermore, this live experiment was primarily included to show how Sub-Ensembles can be created and roughly show the possible advantages they have over Full Ensembles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82085766ad5c351",
   "metadata": {},
   "source": [
    "### Anyways, take with a grain of salt\n",
    "\n",
    "We should see these trends:\n",
    "- **Accuracy:** highest for Full Ensemble, with Sub-Ensemble next.\n",
    "- **Confidence:** lowest for Sub-Ensemble, while Full Ensemble is closer to the base model.\n",
    "- **Training Time:** highest for Full Ensemble, while Sub-Ensemble creates a speedup of roughly 1.5-3.0\n",
    "\n",
    "Feel free to play around with these values (they were kept low to improve the runtime of this notebook):\n",
    "- Models: `n_members`, `n_heads`\n",
    "- Data: `n_samples`, `batch_size`\n",
    "- Training: `epochs`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
