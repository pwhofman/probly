{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f838e68",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16430318",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook provides a practical introduction to the core utility functions in `probly`.\n",
    "These helpers are essential building blocks for training probabilistic models and quantifying uncertainty.\n",
    "\n",
    "We will focus on two main categories:\n",
    "\n",
    "- **Model traversal functions**, which inspect a model’s architecture\n",
    "- **Uncertainty quantification functions**, which compute meaningful uncertainty scores from model predictions\n",
    "\n",
    "---\n",
    "\n",
    "## Key Utility Functions in `probly`\n",
    "\n",
    "### 1. `collect_kl_divergence` (for BNNs)\n",
    "\n",
    "**What it does:**\n",
    "Automatically traverses a Bayesian Neural Network and sums the KL divergence from each Bayesian layer.\n",
    "\n",
    "**Why it’s useful:**\n",
    "This function is critical for computing the **ELBO loss** during training.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. `total_entropy`, `conditional_entropy`, `mutual_information`\n",
    "\n",
    "**What they do:**\n",
    "These functions take a set of predictions (for example, from an ensemble) and decompose predictive uncertainty.\n",
    "\n",
    "**Why they’re useful:**\n",
    "They allow you to separately measure:\n",
    "\n",
    "- **Aleatoric uncertainty** (inherent randomness in the data)\n",
    "- **Epistemic uncertainty** (uncertainty due to limited model knowledge)\n",
    "\n",
    "---\n",
    "\n",
    "### 3. `evidential_uncertainty` (for Evidential Models)\n",
    "\n",
    "**What it does:**\n",
    "Computes an uncertainty score directly from the **evidence vector** produced by an evidential model.\n",
    "\n",
    "**Why it’s useful:**\n",
    "It provides a fast, single-pass way to determine whether a model is uncertain about its prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae301b23",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Example 1: collect_kl_divergence for Bayesian Neural Networks\n",
    "from probly.transformation import bayesian\n",
    "from probly.train.bayesian.torch import collect_kl_divergence\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Create and transform a model to Bayesian\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(10, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 3)\n",
    ")\n",
    "bnn_model = bayesian(model)\n",
    "\n",
    "# Create dummy input\n",
    "inputs = torch.randn(4, 10)\n",
    "\n",
    "# Forward pass (this samples weights from distributions)\n",
    "outputs = bnn_model(inputs)\n",
    "\n",
    "# Collect KL divergence from all Bayesian layers\n",
    "kl = collect_kl_divergence(bnn_model)\n",
    "\n",
    "print(f\"Total KL Divergence: {kl.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f651fcc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Example 2: Decomposing uncertainty with entropy functions\n",
    "from probly.quantification.classification import total_entropy, conditional_entropy, mutual_information\n",
    "import numpy as np\n",
    "\n",
    "# Simulated predictions from a 3-member ensemble for 2 instances, 3 classes\n",
    "# Shape: (num_instances, num_samples, num_classes)\n",
    "ensemble_predictions = np.array([\n",
    "    # Instance 1: High agreement (low epistemic uncertainty)\n",
    "    [[0.8, 0.1, 0.1],\n",
    "     [0.75, 0.15, 0.1],\n",
    "     [0.85, 0.1, 0.05]],\n",
    "    \n",
    "    # Instance 2: High disagreement (high epistemic uncertainty)\n",
    "    [[0.7, 0.2, 0.1],\n",
    "     [0.2, 0.7, 0.1],\n",
    "     [0.1, 0.2, 0.7]]\n",
    "])\n",
    "\n",
    "# Compute uncertainty metrics\n",
    "total_ent = total_entropy(ensemble_predictions)\n",
    "cond_ent = conditional_entropy(ensemble_predictions)  # Aleatoric uncertainty\n",
    "mutual_info = mutual_information(ensemble_predictions)  # Epistemic uncertainty\n",
    "\n",
    "print(\"Instance 1 (models agree):\")\n",
    "print(f\"  Total Entropy: {total_ent[0]:.4f}\")\n",
    "print(f\"  Aleatoric Uncertainty: {cond_ent[0]:.4f}\")\n",
    "print(f\"  Epistemic Uncertainty: {mutual_info[0]:.4f}\")\n",
    "\n",
    "print(\"\\nInstance 2 (models disagree):\")\n",
    "print(f\"  Total Entropy: {total_ent[1]:.4f}\")\n",
    "print(f\"  Aleatoric Uncertainty: {cond_ent[1]:.4f}\")\n",
    "print(f\"  Epistemic Uncertainty: {mutual_info[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1316ca",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Example 3: evidential_uncertainty for Evidential Models\n",
    "from probly.quantification.classification import evidential_uncertainty\n",
    "import numpy as np\n",
    "\n",
    "# Simulated evidence vectors (alpha values) from an evidential model\n",
    "# High evidence = confident, low evidence = uncertain\n",
    "\n",
    "# Confident prediction: lots of evidence for class 0\n",
    "confident_evidence = np.array([[100.0, 2.0, 3.0]])\n",
    "\n",
    "# Uncertain prediction: little evidence for any class\n",
    "uncertain_evidence = np.array([[1.0, 1.0, 1.0]])\n",
    "\n",
    "# Compute uncertainty scores\n",
    "confident_uncertainty = evidential_uncertainty(confident_evidence)\n",
    "uncertain_uncertainty = evidential_uncertainty(uncertain_evidence)\n",
    "\n",
    "print(f\"Confident prediction evidence: {confident_evidence[0]}\")\n",
    "print(f\"  Uncertainty score: {confident_uncertainty[0]:.4f}\")\n",
    "\n",
    "print(f\"\\nUncertain prediction evidence: {uncertain_evidence[0]}\")\n",
    "print(f\"  Uncertainty score: {uncertain_uncertainty[0]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
