{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07f0a36c",
   "metadata": {},
   "source": [
    "# Credal Sets Exploration Notebook\n",
    "\n",
    "This notebook gives a very simple, beginner-friendly view of credal sets.\n",
    "We start from standard probability distributions, which are vectors of nonnegative numbers that sum to 1.\n",
    "An ensemble model can produce multiple probability distributions for the same input.\n",
    "The **credal set** is the set of all these probability distributions produced by the ensemble.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8039ab",
   "metadata": {},
   "source": [
    "## Minimal intuition\n",
    "\n",
    "To summarize an ensemble of probability distributions, we can look at **lower** and **upper** probabilities per class.\n",
    "For each class, the **lower** value is the minimum probability that any ensemble member gives to that class.\n",
    "For each class, the **upper** value is the maximum probability that any ensemble member gives to that class.\n",
    "These lower/upper values form an interval that tells us a simple range of belief for each class.\n",
    "First, we will create a small NumPy matrix P, that represents the ensemble output/predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "720b61f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f45f3ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.array(\n",
    "    [\n",
    "        [0.6, 0.3, 0.1],\n",
    "        [0.5, 0.4, 0.1],\n",
    "        [0.7, 0.2, 0.1],\n",
    "        [0.4, 0.4, 0.2],\n",
    "        [0.55, 0.25, 0.20],\n",
    "    ],\n",
    "    dtype=float,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088d04e7",
   "metadata": {},
   "source": [
    "Now, we have to do basic sanity checks on P, to make sure that no probability is negative. It will also sum each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4659688",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonneg_msg = \"Probabilities must be nonnegative.\"\n",
    "row_sum_msg = \"Each row must sum to 1.0.\"\n",
    "\n",
    "if not np.all(P >= 0.0):\n",
    "    raise ValueError(nonneg_msg)\n",
    "\n",
    "if not np.allclose(P.sum(axis=1), 1.0):\n",
    "    raise ValueError(row_sum_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43e249c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble probabilities P (rows = members, columns = classes):\n",
      "[[0.6  0.3  0.1 ]\n",
      " [0.5  0.4  0.1 ]\n",
      " [0.7  0.2  0.1 ]\n",
      " [0.4  0.4  0.2 ]\n",
      " [0.55 0.25 0.2 ]]\n",
      "\n",
      "Lower envelope per class:\n",
      "[0.4 0.2 0.1]\n",
      "\n",
      "Upper envelope per class:\n",
      "[0.7 0.4 0.2]\n"
     ]
    }
   ],
   "source": [
    "# Lower and upper probability envelopes per class\n",
    "lower = P.min(axis=0)\n",
    "upper = P.max(axis=0)\n",
    "\n",
    "print(\"Ensemble probabilities P (rows = members, columns = classes):\")\n",
    "print(P)\n",
    "print()\n",
    "print(\"Lower envelope per class:\")\n",
    "print(lower)\n",
    "print()\n",
    "print(\"Upper envelope per class:\")\n",
    "print(upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a015d30",
   "metadata": {},
   "source": [
    "## Interpreting lower and upper envelopes\n",
    "\n",
    "The **lower** value for a class is the most conservative belief across all ensemble members.\n",
    "It says, \"even the least confident member does not go below this probability for this class.\"\n",
    "The **upper** value for a class is the most optimistic belief across all ensemble members.\n",
    "It says, \"at least one member goes up to this probability for this class.\"\n",
    "If the interval between lower and upper is **wide**, the ensemble members disagree a lot, so uncertainty is high.\n",
    "If the interval is **narrow**, the ensemble members are more in agreement, so uncertainty is lower.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "559be8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: lower=0.400, upper=0.700, width=0.300\n",
      "Class 1: lower=0.200, upper=0.400, width=0.200\n",
      "Class 2: lower=0.100, upper=0.200, width=0.100\n"
     ]
    }
   ],
   "source": [
    "# Simple summary table: lower, upper, width per class\n",
    "interval_width = upper - lower\n",
    "\n",
    "for class_idx, (lo, up, width) in enumerate(zip(lower, upper, interval_width, strict=True)):\n",
    "    print(f\"Class {class_idx}: lower={lo:.3f}, upper={up:.3f}, width={width:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a00d4f",
   "metadata": {},
   "source": [
    "## What is the credal set here?\n",
    "\n",
    "Each row of `P` is one probability distribution over the 3 classes.\n",
    "The whole matrix `P` collects several such distributions from different ensemble members.\n",
    "The **credal set** in this example is simply the set of all these rows.\n",
    "It is a small, discrete set of possible beliefs about the same input.\n",
    "The lower and upper envelopes we computed are a basic summary of this credal set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26afef1a",
   "metadata": {},
   "source": [
    "## Relation to Probly (high-level only)\n",
    "\n",
    "In Probly, credal sets are organized in a small hierarchy, with classes like `CredalSet`, `DiscreteCredalSet`, and `CategoricalCredalSet`.\n",
    "The idea is that a credal set is a set of probability distributions, with some structure and operations defined on it.\n",
    "In the NumPy implementation, these distributions are stored in arrays with shapes that look roughly like `(..., num_members, num_classes)`.\n",
    "This means we track, for each input, several members (distributions) over a fixed number of classes.\n",
    "Our simple matrix `P` in this notebook mirrors that idea conceptually, but in a tiny, stand-alone form.\n",
    "Here we only explain the concept and do not import or depend on Probly code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1576d0bf",
   "metadata": {},
   "source": [
    "## Basic Experimentation\n",
    "\n",
    "Now we run a few simple experiments to build intuition about credal sets and envelope bounds.\n",
    "All experiments use small ensembles (3 classes, a few to tens of members) and focus on how disagreement affects the lower/upper intervals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f58a58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "\n",
    "\n",
    "# Helper function to validate probability distributions\n",
    "def validate_probs(p: np.ndarray) -> None:\n",
    "    nonneg_msg = \"Probabilities must be nonnegative.\"\n",
    "    row_sum_msg = \"Each row must sum to 1.0.\"\n",
    "    if not np.all(p >= 0.0):\n",
    "        raise ValueError(nonneg_msg)\n",
    "    if not np.allclose(p.sum(axis=1), 1.0):\n",
    "        raise ValueError(row_sum_msg)\n",
    "\n",
    "\n",
    "# Helper function to compute envelopes\n",
    "def envelope(p: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "    lower = p.min(axis=0)\n",
    "    upper = p.max(axis=0)\n",
    "    return lower, upper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de46990",
   "metadata": {},
   "source": [
    "### Experiment 1: Low vs High disagreement\n",
    "\n",
    "We compare two ensembles: one where members agree (low disagreement) and one where they disagree more (high disagreement).\n",
    "We expect wider uncertainty intervals when disagreement is higher.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cb49772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low disagreement ensemble:\n",
      "  Average interval width: 0.0133\n",
      "  Lower: [0.59 0.29 0.1 ]\n",
      "  Upper: [0.61 0.31 0.1 ]\n",
      "\n",
      "High disagreement ensemble:\n",
      "  Average interval width: 0.4000\n",
      "  Lower: [0.2  0.15 0.05]\n",
      "  Upper: [0.8 0.6 0.2]\n",
      "\n",
      "P_high has wider bounds: True\n"
     ]
    }
   ],
   "source": [
    "# Low disagreement: all members are very similar\n",
    "P_low = np.array(\n",
    "    [\n",
    "        [0.6, 0.3, 0.1],\n",
    "        [0.61, 0.29, 0.1],\n",
    "        [0.59, 0.31, 0.1],\n",
    "        [0.6, 0.3, 0.1],\n",
    "        [0.6, 0.3, 0.1],\n",
    "    ],\n",
    "    dtype=float,\n",
    ")\n",
    "validate_probs(P_low)\n",
    "\n",
    "# High disagreement: members differ more\n",
    "P_high = np.array(\n",
    "    [\n",
    "        [0.8, 0.15, 0.05],\n",
    "        [0.3, 0.5, 0.2],\n",
    "        [0.5, 0.3, 0.2],\n",
    "        [0.2, 0.6, 0.2],\n",
    "        [0.4, 0.4, 0.2],\n",
    "    ],\n",
    "    dtype=float,\n",
    ")\n",
    "validate_probs(P_high)\n",
    "\n",
    "# Compute envelopes and widths\n",
    "lower_low, upper_low = envelope(P_low)\n",
    "width_low = upper_low - lower_low\n",
    "avg_width_low = width_low.mean()\n",
    "\n",
    "lower_high, upper_high = envelope(P_high)\n",
    "width_high = upper_high - lower_high\n",
    "avg_width_high = width_high.mean()\n",
    "\n",
    "print(\"Low disagreement ensemble:\")\n",
    "print(f\"  Average interval width: {avg_width_low:.4f}\")\n",
    "print(f\"  Lower: {lower_low}\")\n",
    "print(f\"  Upper: {upper_low}\")\n",
    "print()\n",
    "print(\"High disagreement ensemble:\")\n",
    "print(f\"  Average interval width: {avg_width_high:.4f}\")\n",
    "print(f\"  Lower: {lower_high}\")\n",
    "print(f\"  Upper: {upper_high}\")\n",
    "print()\n",
    "print(f\"P_high has wider bounds: {avg_width_high > avg_width_low}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7555d292",
   "metadata": {},
   "source": [
    "As expected, the high disagreement ensemble has wider uncertainty intervals.\n",
    "When ensemble members disagree more, the gap between lower and upper bounds grows, reflecting higher uncertainty.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb9cf8f",
   "metadata": {},
   "source": [
    "### Experiment 2: Effect of number of ensemble members\n",
    "\n",
    "We generate ensembles with different numbers of members, all centered around the same distribution but with small random variations.\n",
    "This shows how the number of members affects the bounds we observe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "528b3eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n= 3 members: average interval width = 0.0917\n",
      "n= 5 members: average interval width = 0.0772\n",
      "n=20 members: average interval width = 0.1119\n",
      "\n",
      "Summary: More members can reveal more extreme values, affecting bounds.\n"
     ]
    }
   ],
   "source": [
    "# Center distribution\n",
    "c = np.array([0.6, 0.3, 0.1])\n",
    "\n",
    "# Generate ensembles with different member counts\n",
    "member_counts = [3, 5, 20]\n",
    "scale = 0.05  # Noise scale\n",
    "\n",
    "results = []\n",
    "for n in member_counts:\n",
    "    # Generate noise and add to center\n",
    "    noise = rng.normal(0, scale, size=(n, 3))\n",
    "    P_n = c + noise\n",
    "    # Clip to nonnegative and renormalize\n",
    "    P_n = np.clip(P_n, 0, None)\n",
    "    P_n = P_n / P_n.sum(axis=1, keepdims=True)\n",
    "    validate_probs(P_n)\n",
    "\n",
    "    # Compute envelopes\n",
    "    lower_n, upper_n = envelope(P_n)\n",
    "    width_n = upper_n - lower_n\n",
    "    avg_width_n = width_n.mean()\n",
    "\n",
    "    results.append((n, avg_width_n, lower_n, upper_n))\n",
    "    print(f\"n={n:2d} members: average interval width = {avg_width_n:.4f}\")\n",
    "\n",
    "print()\n",
    "print(\"Summary: More members can reveal more extreme values, affecting bounds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec35ac5",
   "metadata": {},
   "source": [
    "The bounds depend on both the variability of the distributions and the sample size (number of members).\n",
    "With more members, we are more likely to observe extreme values, which can widen the lower/upper bounds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f512c968",
   "metadata": {},
   "source": [
    "### Experiment 3: Averaging loses information\n",
    "\n",
    "A common approach is to average ensemble predictions into a single distribution.\n",
    "However, this hides the disagreement between members.\n",
    "We show that the average lies within the bounds but does not capture the uncertainty range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983d1964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged distribution (p_mean):\n",
      "[0.44 0.39 0.17]\n",
      "\n",
      "Credal set bounds (lower, upper):\n",
      "  Class 0: [0.200, 0.800]\n",
      "    p_mean[0] = 0.440 (inside bounds: True)\n",
      "  Class 1: [0.150, 0.600]\n",
      "    p_mean[1] = 0.390 (inside bounds: True)\n",
      "  Class 2: [0.050, 0.200]\n",
      "    p_mean[2] = 0.170 (inside bounds: True)\n",
      "\n",
      "The average lies within the bounds but does not show the width of uncertainty.\n"
     ]
    }
   ],
   "source": [
    "p_mean = P_high.mean(axis=0)\n",
    "\n",
    "\n",
    "validate_probs(p_mean.reshape(1, -1))\n",
    "\n",
    "\n",
    "lower_high, upper_high = envelope(P_high)\n",
    "\n",
    "print(\"Averaged distribution (p_mean):\")\n",
    "print(p_mean)\n",
    "print()\n",
    "print(\"Credal set bounds (lower, upper):\")\n",
    "for class_idx in range(3):\n",
    "    lo = lower_high[class_idx]\n",
    "    up = upper_high[class_idx]\n",
    "    pm = p_mean[class_idx]\n",
    "    inside = lo <= pm <= up\n",
    "    print(f\"  Class {class_idx}: [{lo:.3f}, {up:.3f}]\")\n",
    "    print(f\"    p_mean[{class_idx}] = {pm:.3f} (inside bounds: {inside})\")\n",
    "print()\n",
    "print(\"The average lies within the bounds but does not show the width of uncertainty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428e0b7a",
   "metadata": {},
   "source": [
    "## ProbabilityIntervals (bounds-based credal set)\n",
    "\n",
    "A **ProbabilityIntervals** credal set describes our uncertainty using **per-class lower and upper probability bounds** instead of listing all individual distributions.\n",
    "This representation was explicitly discussed as a next, simple step in the sprint: we only store intervals, not the full set of distributions.\n",
    "\n",
    "For a vector of lower bounds `lower` and upper bounds `upper` (one entry per class), we require:\n",
    "- **Validity of each bound**: \\(0 \\leq \\text{lower}_i \\leq \\text{upper}_i \\leq 1\\)\n",
    "- **Global mass constraints**: \\(\\sum_i \\text{lower}_i \\leq 1 \\leq \\sum_i \\text{upper}_i\\)\n",
    "\n",
    "These conditions ensure that there exists at least one probability distribution that respects all the intervals at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6695840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid intervals example:\n",
      "  OK: intervals are valid.\n",
      "\n",
      "Invalid intervals example:\n",
      "  Error: Sum of lower bounds must be <= 1.\n"
     ]
    }
   ],
   "source": [
    "# Example ProbabilityIntervals for 3 classes\n",
    "lower_bounds = np.array([0.1, 0.2, 0.0], dtype=float)\n",
    "upper_bounds = np.array([0.6, 0.7, 0.4], dtype=float)\n",
    "\n",
    "\n",
    "def validate_probability_intervals(lower: np.ndarray, upper: np.ndarray) -> None:\n",
    "    \"\"\"Validate simple bounds-based credal set conditions.\n",
    "\n",
    "    Conditions:\n",
    "    - Shapes match and are 1D.\n",
    "    - 0 <= lower <= upper <= 1 elementwise.\n",
    "    - sum(lower) <= 1 <= sum(upper).\n",
    "    \"\"\"\n",
    "    lower = np.asarray(lower, dtype=float)\n",
    "    upper = np.asarray(upper, dtype=float)\n",
    "\n",
    "    same_shape_msg = \"Lower and upper must have the same shape.\"\n",
    "    one_dim_msg = \"Lower and upper must be 1D arrays (one entry per class).\"\n",
    "    bounds_range_msg = \"Bounds must satisfy 0 <= lower and upper <= 1 for all classes.\"\n",
    "    order_msg = \"Each lower bound must be <= the corresponding upper bound.\"\n",
    "    sum_lower_msg = \"Sum of lower bounds must be <= 1.\"\n",
    "    sum_upper_msg = \"Sum of upper bounds must be >= 1.\"\n",
    "\n",
    "    if lower.shape != upper.shape:\n",
    "        raise ValueError(same_shape_msg)\n",
    "    if lower.ndim != 1:\n",
    "        raise ValueError(one_dim_msg)\n",
    "\n",
    "    if np.any(lower < 0.0) or np.any(upper > 1.0):\n",
    "        raise ValueError(bounds_range_msg)\n",
    "    if np.any(lower > upper):\n",
    "        raise ValueError(order_msg)\n",
    "\n",
    "    sum_lower = float(lower.sum())\n",
    "    sum_upper = float(upper.sum())\n",
    "    if sum_lower > 1.0 + 1e-8:\n",
    "        raise ValueError(sum_lower_msg)\n",
    "    if sum_upper < 1.0 - 1e-8:\n",
    "        raise ValueError(sum_upper_msg)\n",
    "\n",
    "\n",
    "# Demonstrate one valid and one invalid example\n",
    "print(\"Valid intervals example:\")\n",
    "validate_probability_intervals(lower_bounds, upper_bounds)\n",
    "print(\"  OK: intervals are valid.\\n\")\n",
    "\n",
    "# Invalid example: sum of lower bounds is too large\n",
    "lower_bad = np.array([0.5, 0.6, 0.2], dtype=float)  # sums to 1.3 (> 1)\n",
    "upper_bad = np.array([0.7, 0.8, 0.9], dtype=float)\n",
    "\n",
    "print(\"Invalid intervals example:\")\n",
    "try:\n",
    "    validate_probability_intervals(lower_bad, upper_bad)\n",
    "except ValueError as e:\n",
    "    print(\"  Error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01265a9",
   "metadata": {},
   "source": [
    "## Membership check (is a distribution inside the credal set?)\n",
    "\n",
    "Once we have interval bounds `lower` and `upper`, we can ask whether a candidate probability vector `p` is **compatible** with them.\n",
    "In this simple view, membership means that `p` is a valid probability distribution and, for every class, it stays inside the interval:\n",
    "\n",
    "- `p[i]` must satisfy \\(\\text{lower}_i \\leq p[i] \\leq \\text{upper}_i\\) for all classes `i`.\n",
    "\n",
    "This is the basic \"is-in-check\" functionality discussed in the sprint: a lightweight way to test whether a single distribution lies inside the bounds-based credal set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4878b8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membership checks:\n",
      "  p_inside: [0.3 0.5 0.2] -> True\n",
      "  p_outside: [0.7 0.2 0.1] -> False\n"
     ]
    }
   ],
   "source": [
    "def validate_prob_vector(p: np.ndarray) -> None:\n",
    "    \"\"\"Validate that p is a single probability vector.\n",
    "\n",
    "    Conditions:\n",
    "    - 1D array.\n",
    "    - Nonnegative entries.\n",
    "    - Sum equals 1 (within numerical tolerance).\n",
    "    \"\"\"\n",
    "    p = np.asarray(p, dtype=float)\n",
    "\n",
    "    one_dim_msg = \"p must be a 1D probability vector.\"\n",
    "    nonneg_msg = \"Probabilities must be nonnegative.\"\n",
    "    sum_msg = \"Probabilities must sum to 1.\"\n",
    "\n",
    "    if p.ndim != 1:\n",
    "        raise ValueError(one_dim_msg)\n",
    "    if np.any(p < 0.0):\n",
    "        raise ValueError(nonneg_msg)\n",
    "    if not np.isclose(p.sum(), 1.0):\n",
    "        raise ValueError(sum_msg)\n",
    "\n",
    "\n",
    "def is_in_intervals(p: np.ndarray, lower: np.ndarray, upper: np.ndarray) -> bool:\n",
    "    \"\"\"Check if p lies inside the probability intervals credal set.\n",
    "\n",
    "    This reuses the interval validation and then checks elementwise\n",
    "    lower <= p <= upper.\n",
    "    \"\"\"\n",
    "    validate_probability_intervals(lower, upper)\n",
    "    validate_prob_vector(p)\n",
    "\n",
    "    p = np.asarray(p, dtype=float)\n",
    "    lower = np.asarray(lower, dtype=float)\n",
    "    upper = np.asarray(upper, dtype=float)\n",
    "\n",
    "    return bool(np.all(p >= lower - 1e-8) and np.all(p <= upper + 1e-8))\n",
    "\n",
    "\n",
    "# Example distributions\n",
    "p_inside = np.array([0.3, 0.5, 0.2], dtype=float)  # fits inside the example intervals\n",
    "p_outside = np.array([0.7, 0.2, 0.1], dtype=float)  # first entry exceeds upper bound\n",
    "\n",
    "print(\"Membership checks:\")\n",
    "print(\"  p_inside:\", p_inside, \"->\", is_in_intervals(p_inside, lower_bounds, upper_bounds))\n",
    "print(\"  p_outside:\", p_outside, \"->\", is_in_intervals(p_outside, lower_bounds, upper_bounds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22c4608",
   "metadata": {},
   "source": [
    "## Sampling for intuition\n",
    "\n",
    "Before implementing more advanced operations on credal sets, it can be very helpful just to **sample** from them.\n",
    "Sampling gives a concrete feel for \"what is inside\" the credal set without requiring full analytical formulas.\n",
    "\n",
    "In this simple notebook, we:\n",
    "- Sample a random ensemble member (a random row of `P`) from a **discrete credal set**.\n",
    "- Sample from **probability intervals** using basic rejection sampling, relying only on NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3395f579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample from discrete credal set (random ensemble member):\n",
      "   [0.4 0.4 0.2]\n",
      "\n",
      "Sample from ProbabilityIntervals credal set:\n",
      "   [0.4080684  0.22291303 0.36901857]\n"
     ]
    }
   ],
   "source": [
    "def sample_from_discrete_credal_set(p_members: np.ndarray, rng: np.random.Generator) -> np.ndarray:\n",
    "    \"\"\"Return a random row of P (one ensemble member).\"\"\"\n",
    "    p_members = np.asarray(p_members, dtype=float)\n",
    "    two_d_msg = \"P must be a 2D array: (num_members, num_classes).\"\n",
    "    if p_members.ndim != 2:\n",
    "        raise ValueError(two_d_msg)\n",
    "    num_members = p_members.shape[0]\n",
    "    idx = rng.integers(0, num_members)\n",
    "    return p_members[idx]\n",
    "\n",
    "\n",
    "def sample_from_probability_intervals(\n",
    "    lower: np.ndarray, upper: np.ndarray, rng: np.random.Generator, max_tries: int = 10000\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Sample a probability vector from the intervals via simple rejection.\n",
    "\n",
    "    The procedure is:\n",
    "    1. Validate the intervals.\n",
    "    2. Repeatedly draw a random probability vector from a symmetric Dirichlet\n",
    "       (uniform over the simplex) using NumPy only.\n",
    "    3. Accept the sample if all coordinates lie within [lower, upper].\n",
    "\n",
    "    This is not optimized but is simple and good for building intuition.\n",
    "    \"\"\"\n",
    "    validate_probability_intervals(lower, upper)\n",
    "    lower = np.asarray(lower, dtype=float)\n",
    "    upper = np.asarray(upper, dtype=float)\n",
    "    k = lower.shape[0]\n",
    "\n",
    "    for _ in range(max_tries):\n",
    "        candidate = rng.dirichlet(np.ones(k, dtype=float))\n",
    "        if np.all(candidate >= lower - 1e-8) and np.all(candidate <= upper + 1e-8):\n",
    "            return candidate\n",
    "\n",
    "    error_msg = \"Failed to find a sample inside the intervals. Try loosening bounds or increasing max_tries.\"\n",
    "    raise RuntimeError(error_msg)\n",
    "\n",
    "\n",
    "# Demonstrate sampling (rng defined in Basic Experimentation section)\n",
    "sampled_discrete = sample_from_discrete_credal_set(P, rng)\n",
    "sampled_interval = sample_from_probability_intervals(lower_bounds, upper_bounds, rng)\n",
    "\n",
    "validate_prob_vector(sampled_discrete)\n",
    "validate_prob_vector(sampled_interval)\n",
    "\n",
    "print(\"Sample from discrete credal set (random ensemble member):\")\n",
    "print(\"  \", sampled_discrete)\n",
    "print()\n",
    "print(\"Sample from ProbabilityIntervals credal set:\")\n",
    "print(\"  \", sampled_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4e3474",
   "metadata": {},
   "source": [
    "## Shape and axis conventions\n",
    "\n",
    "In the Probly codebase, discrete credal sets are represented using NumPy arrays with shapes that look like `(..., num_members, num_classes)`.\n",
    "- The **last axis** (size = `num_classes`) holds the class probabilities.\n",
    "- The axis just before that (size = `num_members`) indexes the different ensemble members (or distributions) for the same input.\n",
    "\n",
    "The lower and upper envelopes are then computed by reducing (taking `min`/`max`) over the **member axis**.\n",
    "In Probly, the discrete credal set representation uses arrays shaped `(..., num_members, num_classes)` and computes envelopes by reducing over the member axis (`axis=-2`).\n",
    "For our 2D example `P.shape == (num_members, num_classes)`, `axis=0` is equivalent to `axis=-2`.\n",
    "Our small example matrix `P` already follows this idea in a very simple way: it is just `(num_members, num_classes)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c1f3c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of P (members x classes): (5, 3)\n",
      "Shape of lower (per-class): (3,)\n",
      "Shape of upper (per-class): (3,)\n",
      "\n",
      "In this notebook, axis 0 of P indexes ensemble members,\n",
      "and axis 1 indexes classes. Lower/upper are 1D over the class axis.\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of P (members x classes):\", P.shape)\n",
    "print(\"Shape of lower (per-class):\", lower.shape)\n",
    "print(\"Shape of upper (per-class):\", upper.shape)\n",
    "print()\n",
    "print(\"In this notebook, axis 0 of P indexes ensemble members,\")\n",
    "print(\"and axis 1 indexes classes. Lower/upper are 1D over the class axis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4c80da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P3 = P[None, :, :] shape: (1, 5, 3)\n",
      "lower3 = P3.min(axis=-2) shape: (1, 3)\n",
      "upper3 = P3.max(axis=-2) shape: (1, 3)\n",
      "\n",
      "lower3 (same as lower): [[0.4 0.2 0.1]]\n",
      "upper3 (same as upper): [[0.7 0.4 0.2]]\n"
     ]
    }
   ],
   "source": [
    "P3 = P[None, :, :]\n",
    "lower3 = P3.min(axis=-2)\n",
    "upper3 = P3.max(axis=-2)\n",
    "\n",
    "print(\"P3 = P[None, :, :] shape:\", P3.shape)\n",
    "print(\"lower3 = P3.min(axis=-2) shape:\", lower3.shape)\n",
    "print(\"upper3 = P3.max(axis=-2) shape:\", upper3.shape)\n",
    "print()\n",
    "print(\"lower3 (same as lower):\", lower3)\n",
    "print(\"upper3 (same as upper):\", upper3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
