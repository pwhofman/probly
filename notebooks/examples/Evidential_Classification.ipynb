{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d97c4ec8",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# **Your Guide to: Evidential CLassification** *(with probly)*\n",
    "\n",
    "The goal of this wonderful Notebook is to showcase what Evidential Classification means and why it is so important for the use of uncertainty awareness. Enjoy!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b9d006",
   "metadata": {},
   "source": [
    "## 1. What even is Evidential Classification\n",
    "\n",
    "Have you ever asked yourself, when turning to a machine with a question: \"How certain are you about this answer and how do I know that I can trust you?\" ü§î\n",
    "<br> Well, you can¬¥t. But that is when Evidential Classification helps us!\n",
    "<br> With it, we can understand how certain our machine is about its own prediction. In normal classifiers, we only get a probability vector ‚Äî but not how confident the model is about that probability.\n",
    "<br> This transformation adds uncertainty-awareness in a single forward pass.\n",
    "\n",
    "Let¬¥s look at how this works! üëá\n",
    "\n",
    "### 1.1 Its use in uncertainty\n",
    "\n",
    "Now you might be asking yourself: *\"Why are you telling me about this and when would I ever need this?\"* üôÑ\n",
    "I¬¥m glad you asked! \n",
    "\n",
    "**Evidential Classification** becomes important when we talk about **uncertainty in machine learning**. \n",
    "<br> Usually, your machine will tell you **which option is probably correct** but it won¬¥t tell **how certain** it is about this prediction.\n",
    "<br> In other words, you¬¥ll get *a probability* for a class but not *a confidence* about that probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc27bfb",
   "metadata": {},
   "source": [
    "### 1.2 Now: *How* is it used?\n",
    "\n",
    "Now that we know *what* it is and its necessity, we can move on to how we use it. Before I can show you, we have to learn how it¬¥s structured. ü´†\n",
    "<br> Don¬¥t worry, it¬¥s short, I promise.\n",
    "\n",
    "> #### Softmax vs. Softplus vs. Dirichlet\n",
    "These 3 functions are doing all the work for us, so listen up. \n",
    "\n",
    "***Softmax***: converts the input value to a value between 0-1, which all together sum up to 1‚Äã $$ \\mathbb{p_i} = \\frac{e^{x_i}}{\\sum_j e^{x_j}} $$\n",
    "\n",
    "***Softplus***: approaches zeros (but never reaches them) and negative values, turning them positive $$ \\text{Softplus} (x) = \\log(1 + e^x) $$\n",
    "\n",
    "***Dirichlet***: shows the distribution of the probabilities. $$ \\mathbb{E}[p_k] = \\frac{\\alpha_k}{\\sum_i \\alpha_i} $$\n",
    "\n",
    "See, it wasn¬¥t that bad, right? üòÅ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbf6b1e",
   "metadata": {},
   "source": [
    "### 2. Turning a Base Model into Evidential Model \n",
    "\n",
    "Now we really start! üö¶\n",
    "<br> Like we established in the beginning, we are using probly! yeey ü•≥ So let¬¥s look at it.\n",
    "<br> probly provides a transformation that appends a Softplus layer after each Module to ensure positive outputs. So let¬¥s look at how the base for this would look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4ca881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install probly & torch via: pip install probly torch\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# base model\n",
    "base = nn.Sequential(\n",
    "    nn.Linear(10, 3),\n",
    ")\n",
    "\n",
    "# add softplus activation to ensure positive outputs\n",
    "model = nn.Sequential(base, nn.Softplus())\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4727d735",
   "metadata": {},
   "source": [
    "Perfect! Now we have a *base* nn.Linear layer that gets 10 inputs and outputs 3 values (also called **logits**) while nn.Softplus ensures that the logits stay *positive*. For anyone wondering: nn.Sequential simply lets us *chain* layers. Easy right? üòÅ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13e3f8f",
   "metadata": {},
   "source": [
    "### 3. What do the logits (Œ±-values) tell us?\n",
    "\n",
    "We all know some statistics, right? We also know that a higher probability is usually better - unless you¬¥re calculating the odds of getting famous. \n",
    "<br> In that case... we *love* uncertainty! üòå\n",
    "<br> But back to the important stuff: the larger our Œ±-values are, the higher our confidence and certainty become ‚Äî and the smaller they are, the less confident our predictions are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a900f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_confident = torch.tensor([10.0, 0.5, 0.5])\n",
    "alpha_uncertain = torch.tensor([1.1, 1.1, 1.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5af9fa8",
   "metadata": {},
   "source": [
    "As you can see, our first set of logits represents a Dirichlet distribution that makes us confident about our predictions - <br> meanwhile the second one shows that we have absolutely no clue which class is correct, and every answer could be the right one. üòÖ <br> And we don¬¥t like that!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272d33b2",
   "metadata": {},
   "source": [
    "Okay, now let¬¥s say we have a picture of a cat and our machine tells us what it thinks it is.  \n",
    "<br> Let¬¥s visualize our machines prediction! Run the codeee! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1a1be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "classes = [\"cat\", \"dog\", \"octopus\"]\n",
    "\n",
    "# confident\n",
    "plt.bar(classes, [10, 0.5, 0.5])\n",
    "plt.title(\"Confident Model (High alpha)\")\n",
    "plt.show()\n",
    "print(\"This a cat!  I am sure!\")\n",
    "\n",
    "# uncertain\n",
    "plt.bar(classes, [1.1, 1.1, 1.1])\n",
    "plt.title(\"Uncertain Model (Low alpha)\")\n",
    "plt.show()\n",
    "print(\"Hmm... I have no idea what this is. Could be anything.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d3f9e8",
   "metadata": {},
   "source": [
    "You can perfectly see the distribution and the difference between the two models.üßê\n",
    "<br> It is very clear, that the Dirichlet distribution, really shows us the uncertainty of the answer, at first glance, in contrast to our softmax values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555b97f6",
   "metadata": {},
   "source": [
    "### 4. Measuring Uncertainty with Entropy and Evidence\n",
    "\n",
    "Now that we¬¥ve seen this ongoing battle between the probabilities and uncertaintyü•ä - let‚Äôs add a small quantitative view:\n",
    "<br> We can measure **how uncertain** our model is by calculating the *entropy* of its probabilities. \n",
    "<br> Entropy might sound like a fancy word, but it simply tells us the extent to which the uncertainty of our machine goes.\n",
    "<br> To understand the code a little better, you need to know 2 simple functions:\n",
    "\n",
    "This is the mean of our Dirichlet distribution: $$ \\mathbb{E}[p_k] = \\frac{\\alpha_k}{\\sum_i \\alpha_i} $$\n",
    "This is our entropy: $$ \\mathbb{H}[p] = - {\\sum_i} {p_i} {log(p_i)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a66d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def p_mean(alpha: torch.Tensor) -> torch.Tensor:\n",
    "    return alpha / alpha.sum()\n",
    "\n",
    "\n",
    "def entropy(p: torch.Tensor) -> torch.Tensor:\n",
    "    return -(p * torch.log(p)).sum()\n",
    "\n",
    "\n",
    "alpha_confident = torch.tensor([10.0, 0.5, 0.5])\n",
    "alpha_uncertain = torch.tensor([1.1, 1.1, 1.1])\n",
    "\n",
    "for name, a in [(\"Confident\", alpha_confident), (\"Uncertain\", alpha_uncertain)]:\n",
    "    p = p_mean(a)\n",
    "    H = entropy(p)\n",
    "    print(f\"{name} | Probabilities: {p.tolist()} | Entropy: {H:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47c5330",
   "metadata": {},
   "source": [
    "We can see:\n",
    "<br> ‚¶Å low entropy ‚Üí more confident predictions \n",
    "<br> ‚¶Å high entropy ‚Üí model uncertainty \n",
    "\n",
    "‚Üí So if your entropy is high, your model is basically screaming at you:\n",
    "‚ÄúI don‚Äôt know, don‚Äôt trust me!‚Äù ü•≤\n",
    "\n",
    "On the other hand,, we also have something called *evidence*. Yes, just like the evidence you¬¥d need in court, to get out of a ticket - so drive slowly! üöóüí®\n",
    "<br> Anyway, it¬¥s the same concept:\n",
    "<br> ‚¶Å **high evidence** ‚Üí the model has seen similar examples before ‚Üí **high confidence**\n",
    "<br> ‚¶Å **low evidence** ‚Üí the model isn‚Äôt sure ‚Üí **high uncertainty**\n",
    "<br> So this is another cool way to tell **how uncertain our machine really is!**\n",
    "\n",
    "<u> So all in all: </u>\n",
    "<br> Entropy measures **how uncertain** a prediction is,\n",
    "while evidence tells us **how strongly** the model **supports** that prediction.\n",
    "\n",
    "In practice, both work hand in hand:\n",
    "<br> low entropy and high evidence means the model is confident -\n",
    "<br> high entropy and low evidence means it‚Äôs confused. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975af35e",
   "metadata": {},
   "source": [
    "Let¬¥s visualize this a little!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e114210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Raw values\n",
    "entropy_values = np.array([0.368, 1.099])\n",
    "evidence_values = np.array([10, 1.1])\n",
    "\n",
    "# Normalize for better visualization\n",
    "entropy_norm = entropy_values / entropy_values.max()\n",
    "evidence_norm = evidence_values / evidence_values.max()\n",
    "\n",
    "labels = [\"Confident Model\", \"Uncertain Model\"]\n",
    "x = np.arange(len(labels))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.bar(x - width / 2, entropy_norm, width, label=\"Entropy (Uncertainty)\", color=\"tomato\")\n",
    "ax.bar(x + width / 2, evidence_norm, width, label=\"Evidence (Confidence)\", color=\"mediumseagreen\")\n",
    "\n",
    "ax.set_ylabel(\"Normalized scale (0-1)\")\n",
    "ax.set_title(\"Normalized Entropy vs Evidence\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9a5ba4",
   "metadata": {},
   "source": [
    "<br> We could also imagine this as a line ‚Äî\n",
    "when entropy goes up, evidence goes down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c70c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "entropy = np.linspace(0, 1, 6)\n",
    "evidence = 1 - entropy  # inverse relationship\n",
    "\n",
    "plt.plot(entropy, evidence, marker=\"o\", color=\"mediumseagreen\")\n",
    "plt.xlabel(\"Entropy (Uncertainty)\")\n",
    "plt.ylabel(\"Evidence (Confidence)\")\n",
    "plt.title(\"Relationship between Entropy and Evidence\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef2a695",
   "metadata": {},
   "source": [
    "### 5. Comparing Softmax vs. Evidential\n",
    "\n",
    "Now to really get the difference between using just softmax vs. evidential.\n",
    "Softmax gives us probabilities that *always* **look** confident ‚Äî  \n",
    "even when the model has never seen the data before.\n",
    "Evidential models, on the other hand, keep track of **how much evidence** supports each prediction.  \n",
    "They can say:  \n",
    "> ‚ÄúI think it‚Äôs a cat‚Ä¶ but I‚Äôm not really sure.‚Äù üòÖ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4df605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "logits = torch.tensor([2.0, 5.0, 3.0])\n",
    "softmax_probs = F.softmax(logits, dim=0)\n",
    "print(\"Softmax probabilities:\", softmax_probs.tolist())\n",
    "\n",
    "alpha = torch.nn.functional.softplus(logits) + 1\n",
    "dirichlet_mean = alpha / alpha.sum()\n",
    "print(\"Evidential mean (alpha):\", dirichlet_mean.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77996f24",
   "metadata": {},
   "source": [
    "At first glance the results look very similiar but theres is a small but distinct difference.\n",
    "<br> **Softmax** converts logits into clean probabilities that always add up to 1.  \n",
    "<br> That‚Äôs why one value (here around 0.8) dominates ‚Äî it always looks **confident**. \n",
    "\n",
    "**Evidential** models use Œ±-values that include evidence.\n",
    "<br> Their probabilities look *flatter*, because they account for how much the model actually *knows*.  \n",
    "<br> So even if both predict the same class, Evidential is usually more *honest* about its uncertainty. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e924e30",
   "metadata": {},
   "source": [
    "### 6. Confidence ‚â† Correctness\n",
    "\n",
    "This is very important! You can never forget that a model can be very confident and still completely wrong.\n",
    "\n",
    "This happens when it has never seen similar data before ‚Äî it simply doesn‚Äôt know that it doesn‚Äôt know. You can¬¥t know what you haven¬¥t learned üòû\n",
    "\n",
    "Evidential models help fix this:\n",
    "they express how sure the model is, and how much evidence that certainty is based on. Without it you wouldn¬¥t know if you can trust your machine.\n",
    "\n",
    "In other words, they don‚Äôt just say ‚ÄúI‚Äôm 95 % sure‚Äù,\n",
    "they also tell us ‚Äúand I actually have good reasons for that. And I can show you my evidence.‚Äù üòÑ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5434709f",
   "metadata": {},
   "source": [
    "### 7. Takeaway\n",
    "Evidential Classification teaches our models not only *what* to predict, but also *how sure* they are about it.\n",
    "<br> So next time your model says ‚ÄúI‚Äôm 95% sure‚Äù ‚Äî you can finally ask ‚Äúand how much evidence do you have for that?‚Äù üòâ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
