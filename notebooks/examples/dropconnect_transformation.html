<!doctype html>
<html class="no-js" lang="en" data-content_root="../../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../../genindex.html" /><link rel="search" title="Search" href="../../search.html" /><link rel="next" title="Dropout Transformation" href="dropout_transformation.html" /><link rel="prev" title="Bayesian Transformation" href="bayesian_transformation.html" />

    <!-- Generated with Sphinx 8.2.3 and Furo 2024.08.06 -->
        <title>Dropconnect Transformation - probly 0.3.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo.css?v=354aac6f" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo-extensions.css?v=302659d7" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css?v=201d0c9a" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #272822;
  --color-code-foreground: #f8f8f2;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #272822;
  --color-code-foreground: #f8f8f2;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../index.html"><div class="brand">probly 0.3.1 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><div class="sidebar-scroll"><a class="sidebar-brand" href="../../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo only-light" src="../../_static/logo/logo_light.png" alt="Light Logo"/>
    <img class="sidebar-logo only-dark" src="../../_static/logo/logo_dark.png" alt="Dark Logo"/>
  </div>
  
  
</a><form class="sidebar-search-container" method="get" action="../../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Content</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">The <code class="docutils literal notranslate"><span class="pre">probly</span></code> Python Package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../core_concepts.html">Core Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../main_components.html">Main Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced_topics.html">Advanced Topics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../examples_and_tutorials.html">Examples and Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../methods.html">Implemented methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contributing.html">Contributing to probly üèîÔ∏è</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../references.html">References and Further Reading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq.html">FAQ and Troubleshooting</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Notebooks</span></p>
<ul class="current">
<li class="toctree-l1 current has-children"><a class="reference internal" href="index.html">Notebook Examples</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Notebook Examples</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2 has-children"><a class="reference internal" href="utilities_and_layers/index.html">Utilities and Layers</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of Utilities and Layers</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="utilities_and_layers/custom_loss_functions.html">Custom Loss Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilities_and_layers/metrics.html">Evaluation Metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilities_and_layers/probabilistic_layers.html">Key Probabilistic Layers in <code class="docutils literal notranslate"><span class="pre">probly</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="utilities_and_layers/utility_functions.html">Utility Functions</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="evaluation_and_quantification/index.html">Evaluation and Quantification</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of Evaluation and Quantification</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="evaluation_and_quantification/calibration_metrics.html">Calibration Metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="evaluation_and_quantification/interpretation_techniques.html">Interpretation techniques</a></li>
<li class="toctree-l3"><a class="reference internal" href="evaluation_and_quantification/visualization_tools.html">Visualisation Tools</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="bayesian_transformation.html">Bayesian Transformation</a></li>
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">Dropconnect Transformation</a></li>
<li class="toctree-l2"><a class="reference internal" href="dropout_transformation.html">Dropout Transformation</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble_transformation.html">Ensemble Transformation</a></li>
<li class="toctree-l2"><a class="reference internal" href="evidential_classification_transformation.html">Evidential Classification Transformation</a></li>
<li class="toctree-l2"><a class="reference internal" href="evidential_regression_transformation.html">Evidential Regression Transformation</a></li>
<li class="toctree-l2"><a class="reference internal" href="fashionmnist_ood_ensemble.html">Out-of-Distribution Detection with an Ensemble</a></li>
<li class="toctree-l2"><a class="reference internal" href="label_relaxation_calibration.html">Calibration with Label Relaxation</a></li>
<li class="toctree-l2"><a class="reference internal" href="lazy_dispatch_test.html">Lazy Dispatch Test</a></li>
<li class="toctree-l2"><a class="reference internal" href="multilib_demo.html">Multilib Demo</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytraverse_tutorial.html">A Brief Introduction to PyTraverse</a></li>
<li class="toctree-l2"><a class="reference internal" href="sklearn_selective_prediction.html">Using probly with scikit-learn</a></li>
<li class="toctree-l2"><a class="reference internal" href="temperature_scaling_calibration.html">Calibration using Temperature Scaling</a></li>
<li class="toctree-l2"><a class="reference internal" href="train_bnn_classification.html">Bayesian Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="train_evidential_classification.html">Evidential Model for Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="train_evidential_regression.html">Evidential Regression Model</a></li>
</ul>
</li>
</ul>

</div>
</div><div style="text-align: center; margin-top: 1rem; margin-bottom: 1rem;">
  <a href="https://github.com/pwhofman/probly" target="_blank" rel="noopener noreferrer" title="GitHub Repository">
    <img src="../../_static/github-mark.svg" alt="GitHub Logo" width="28" height="28" style="display: inline-block;">
  </a>
</div>
      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          

<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="dropconnect-transformation">
<h1>Dropconnect Transformation<a class="headerlink" href="#dropconnect-transformation" title="Link to this heading">¬∂</a></h1>
<p>This notebook is meant as a, practical introduction to the <strong>Dropconnect transformation</strong> in <code class="docutils literal notranslate"><span class="pre">probly</span></code>.
The goal is not to be mathematically perfect, but to give you an intuition.</p>
<p>We will slowly build up from the very basic idea of <em>normal</em> Dropout to the slightly more advanced idea of
a <strong>Dropout transformation that makes a model uncertainty‚Äëaware</strong>. After that, we look at a small PyTorch
example and inspect how the transformation changes the model.</p>
<hr class="docutils" />
<section id="part-a-introduction-to-dropconnect-and-the-dropconnect-transformation">
<h2>Part A: Introduction to Dropconnect and the Dropconnect Transformation<a class="headerlink" href="#part-a-introduction-to-dropconnect-and-the-dropconnect-transformation" title="Link to this heading">¬∂</a></h2>
</section>
<hr class="docutils" />
<section id="concept-what-is-dropconnect-normal-vs-dropconnect-transformation">
<h2>1. Concept: What is Dropconnect (normal) vs Dropconnect Transformation?<a class="headerlink" href="#concept-what-is-dropconnect-normal-vs-dropconnect-transformation" title="Link to this heading">¬∂</a></h2>
<p>To understand the DropConnect transformation, it‚Äôs helpful to first compare it to the more common Dropout.</p>
<section id="normal-dropout-recap">
<h3>1.1 Normal Dropout (Recap)<a class="headerlink" href="#normal-dropout-recap" title="Link to this heading">¬∂</a></h3>
<p>Dropout is a regularization technique that works on activations. During training, it randomly sets the outputs of some neurons to zero.
This prevents the network from relying too heavily on any single neuron.</p>
</section>
<section id="normal-dropconnect">
<h3>1.2 Normal DropConnect<a class="headerlink" href="#normal-dropconnect" title="Link to this heading">¬∂</a></h3>
<p>DropConnect is a similar regularization technique, but it works on weights. Instead of setting a neuron‚Äôs entire output to zero,
DropConnect randomly sets a fraction p of the individual weights within a layer to zero for each training step.
You can imagine this as temporarily deleting connections between neurons.</p>
<p>This is considered a more generalized form of Dropout. Like Dropout, its main purpose during normal training is to prevent overfitting
and improve the model‚Äôs robustness. At inference time <code class="docutils literal notranslate"><span class="pre">(model.eval())</span></code>, this randomness is disabled, and the model becomes deterministic.</p>
</section>
<section id="dropconnect-transformation-probly">
<h3>1.3 DropConnect Transformation (probly)<a class="headerlink" href="#dropconnect-transformation-probly" title="Link to this heading">¬∂</a></h3>
<p>The DropConnect transformation in <code class="docutils literal notranslate"><span class="pre">probly</span></code>takes this idea and uses it to make a model <strong>uncertainty‚Äëaware</strong> at prediction time.</p>
<p>The transformation does the following:</p>
<ul class="simple">
<li><p>It walks through your PyTorch model and finds the relevant linear layers (e.g., <code class="docutils literal notranslate"><span class="pre">nn.Linear</span></code>).</p></li>
<li><p>It programmatically replaces each <code class="docutils literal notranslate"><span class="pre">nn.Linear</span></code>layer with a custom <code class="docutils literal notranslate"><span class="pre">DropConnectLinear</span></code> layer.</p></li>
<li><p>Crucially, this custom layer keeps the DropConnect mechanism <strong>active during inference</strong>.</p></li>
</ul>
<p>If we now feed the same input through the transformed model multiple times, we get a cloud of slightly different predictions. The variation in this cloud is a direct measure of the model‚Äôs uncertainty.</p>
</section>
<section id="a-short-sidebyside-comparison">
<h3>1.4 A Short side‚Äëby‚Äëside comparison<a class="headerlink" href="#a-short-sidebyside-comparison" title="Link to this heading">¬∂</a></h3>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Aspect</p></th>
<th class="head"><p>DropConnect Transformation (probly)</p></th>
<th class="head"><p>Dropout Transformation (probly)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>What is dropped?</p></td>
<td><p>Individual weights inside a layer</p></td>
<td><p>Entire activations (neuron outputs)</p></td>
</tr>
<tr class="row-odd"><td><p>How it modifies the model</p></td>
<td><p>Replaces <code class="docutils literal notranslate"><span class="pre">nn.Linear</span></code> with <code class="docutils literal notranslate"><span class="pre">DropConnectLinear</span></code></p></td>
<td><p>Inserts <code class="docutils literal notranslate"><span class="pre">nn.Dropout</span> <span class="pre">layers</span></code> before <code class="docutils literal notranslate"><span class="pre">nn.Linear</span></code></p></td>
</tr>
<tr class="row-even"><td><p>When it‚Äôs active</p></td>
<td><p>Intentionally in <code class="docutils literal notranslate"><span class="pre">model.eval()</span></code></p></td>
<td><p>Intentionally in <code class="docutils literal notranslate"><span class="pre">model.eval()</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>Main purpose</p></td>
<td><p>Make predictions uncertainty‚Äëaware</p></td>
<td><p>Make predictions uncertainty‚Äëaware</p></td>
</tr>
<tr class="row-even"><td><p>Output behaviour in eval</p></td>
<td><p>Stochastic (same input ‚Üí slightly different outputs)</p></td>
<td><p>Stochastic (same input ‚Üí slightly different outputs)</p></td>
</tr>
</tbody>
</table>
</div>
<p>The rest of this notebook now assumes this picture: <strong>‚Äúnormal‚Äù Dropout is a training regulariser, the
Dropout transformation turns the same mechanism into a tool for estimating uncertainty.</strong></p>
</section>
</section>
<section id="quickstart-pytorch">
<h2>2. Quickstart (PyTorch)<a class="headerlink" href="#quickstart-pytorch" title="Link to this heading">¬∂</a></h2>
<p>Below: build a small MLP, apply <code class="docutils literal notranslate"><span class="pre">dropconnect(model,</span> <span class="pre">p)</span></code>, and inspect the modified architecture.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">probly.transformation</span><span class="w"> </span><span class="kn">import</span> <span class="n">dropconnect</span>


<span class="k">def</span><span class="w"> </span><span class="nf">build_mlp</span><span class="p">(</span><span class="n">in_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">hidden</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">hidden</span><span class="p">),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">hidden</span><span class="p">),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">),</span>
    <span class="p">)</span>


<span class="n">p</span> <span class="o">=</span> <span class="mf">0.2</span>  <span class="c1"># dropconnect probability</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">build_mlp</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Original model:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>

<span class="n">model_dc</span> <span class="o">=</span> <span class="n">dropconnect</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">With DropConnect transformation (p=</span><span class="si">{</span><span class="n">p</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">):</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">model_dc</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Original model:
 Sequential(
  (0): Linear(in_features=10, out_features=32, bias=True)
  (1): ReLU()
  (2): Linear(in_features=32, out_features=32, bias=True)
  (3): ReLU()
  (4): Linear(in_features=32, out_features=1, bias=True)
)

With DropConnect transformation (p=0.20):
 Sequential(
  (0): Linear(in_features=10, out_features=32, bias=True)
  (1): ReLU()
  (2): DropConnectLinear(in_features=32, out_features=32, bias=True)
  (3): ReLU()
  (4): DropConnectLinear(in_features=32, out_features=1, bias=True)
)
</pre></div>
</div>
</div>
</div>
<section id="notes-on-the-structure">
<h3>Notes on the structure<a class="headerlink" href="#notes-on-the-structure" title="Link to this heading">¬∂</a></h3>
<p>Notice that each <code class="docutils literal notranslate"><span class="pre">Linear</span></code> layer has been replaced by a <code class="docutils literal notranslate"><span class="pre">DropConnectLinear</span></code> layer.</p>
<p>The overall architecture (<code class="docutils literal notranslate"><span class="pre">Sequential</span></code>, <code class="docutils literal notranslate"><span class="pre">ReLU</span></code>) remains the same, but the core linear modules are now uncertainty-aware.</p>
</section>
</section>
<section id="uncertainty-via-dropconnect">
<h2>3. Uncertainty via DropConnect<a class="headerlink" href="#uncertainty-via-dropconnect" title="Link to this heading">¬∂</a></h2>
<p>To obtain predictive uncertainty, we run multiple stochastic forward passes (with DropConnect active) and compute the mean and variance of the predictions. The process is identical to MC-Dropout.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Toy regression data</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">true_w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">true_w</span> <span class="o">+</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Build and transform the model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">build_mlp</span><span class="p">(</span><span class="n">in_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">hidden</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">out_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model_dc</span> <span class="o">=</span> <span class="n">dropconnect</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="c1"># Simple training loop</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model_dc</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">)</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>

<span class="n">model_dc</span><span class="o">.</span><span class="n">train</span><span class="p">()</span> <span class="c1"># Activate DropConnect for training</span>
<span class="k">for</span> <span class="n">_step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">200</span><span class="p">):</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">model_dc</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>


<span class="c1"># MC prediction function</span>
<span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span><span class="w"> </span><span class="nf">mc_predict</span><span class="p">(</span>
    <span class="n">model_with_dropconnect</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
    <span class="c1"># Activate training mode to enable the stochasticity of DropConnect</span>
    <span class="n">model_with_dropconnect</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">):</span>
        <span class="n">preds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model_with_dropconnect</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
    <span class="n">stacked</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># [n_samples, N, out_dim]</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="n">stacked</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">var</span> <span class="o">=</span> <span class="n">stacked</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">unbiased</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mean</span><span class="p">,</span> <span class="n">var</span>


<span class="n">mean_pred</span><span class="p">,</span> <span class="n">var_pred</span> <span class="o">=</span> <span class="n">mc_predict</span><span class="p">(</span><span class="n">model_dc</span><span class="p">,</span> <span class="n">X</span><span class="p">[:</span><span class="mi">5</span><span class="p">],</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Predictive mean (first 5):</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">mean_pred</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Predictive variance (first 5):</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">var_pred</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predictive mean (first 5):
 tensor([-1.2788,  3.1010,  1.6500, -1.6051, -0.8758])

Predictive variance (first 5):
 tensor([0.0370, 0.1376, 0.0453, 0.0445, 0.0266])
</pre></div>
</div>
</div>
</div>
</section>
<section id="good-practices">
<h2>4. Good practices<a class="headerlink" href="#good-practices" title="Link to this heading">¬∂</a></h2>
<ul class="simple">
<li><p>Tune the DropConnect probability <code class="docutils literal notranslate"><span class="pre">p</span></code> (e.g., 0.1‚Äì0.5) as a hyperparameter.</p></li>
<li><p>Use a reasonable number of Monte Carlo samples (e.g., 20‚Äì200). More samples give smoother estimates but are computationally slower.</p></li>
<li><p>Since DropConnect replaces layers, it‚Äôs a good idea to confirm your model‚Äôs performance doesn‚Äôt degrade significantly after transformation.</p></li>
</ul>
</section>
<section id="common-errors">
<h2>5. Common errors<a class="headerlink" href="#common-errors" title="Link to this heading">¬∂</a></h2>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">ValueError:</span> <span class="pre">p</span> <span class="pre">must</span> <span class="pre">be</span> <span class="pre">between</span> <span class="pre">0</span> <span class="pre">and</span> <span class="pre">1</span></code> ‚Äî ensure <code class="docutils literal notranslate"><span class="pre">0</span> <span class="pre">‚â§</span> <span class="pre">p</span> <span class="pre">‚â§</span> <span class="pre">1</span></code>.</p></li>
<li><p>Seeing no <code class="docutils literal notranslate"><span class="pre">DropConnectLinear</span></code> layers? Confirm your model contains <code class="docutils literal notranslate"><span class="pre">nn.Linear</span></code> modules that probly can detect and replace.</p></li>
</ul>
</section>
<section id="next-steps">
<h2>6. Next steps<a class="headerlink" href="#next-steps" title="Link to this heading">¬∂</a></h2>
<ul class="simple">
<li><p>Explore how DropConnect behaves with different architectures.</p></li>
<li><p>Compare the uncertainty estimates from DropConnect with those from the Dropout transformation on the same task.</p></li>
</ul>
</section>
<section id="part-a-summary">
<h2>7. Part A Summary<a class="headerlink" href="#part-a-summary" title="Link to this heading">¬∂</a></h2>
<p>In Part A, we distinguished between Dropout and DropConnect and explored how the DropConnect Transformation works in <code class="docutils literal notranslate"><span class="pre">probly</span></code>.
While standard DropConnect is a regularization technique that drops individual weights during training, the <code class="docutils literal notranslate"><span class="pre">probly</span></code> transformation adapts this mechanism for uncertainty estimation.
It achieves this by replacing standard <code class="docutils literal notranslate"><span class="pre">nn.Linear</span> </code> layers with custom <code class="docutils literal notranslate"><span class="pre">DropConnectLinear</span></code> layers that remain stochastic even during inference.
This allows us to generate a distribution of predictions for a single input, where the variance serves as a measure of model uncertainty.</p>
</section>
<hr class="docutils" />
<section id="part-b-applied-mc-dropconnect">
<h2>Part B ‚Äî Applied MC-Dropconnect<a class="headerlink" href="#part-b-applied-mc-dropconnect" title="Link to this heading">¬∂</a></h2>
<hr class="docutils" />
<p>In <strong>Part A</strong> , we learned what the <code class="docutils literal notranslate"><span class="pre">DropConnect</span></code>transformation in <code class="docutils literal notranslate"><span class="pre">probly</span></code> does by replacing layers to make a model stochastic.
In this <strong>Part B</strong> , we will apply that transformation, run several stochastic predictions, and visualize the resulting uncertainty.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">probly.transformation</span><span class="w"> </span><span class="kn">import</span> <span class="n">dropconnect</span>

<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">TinyNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A tiny neural network for demonstration, built with standard layers.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>


<span class="c1"># dummy input</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>
<span class="n">base_model</span> <span class="o">=</span> <span class="n">TinyNet</span><span class="p">()</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="apply-the-dropconnect-transformation">
<h2>2. Apply the DropConnect transformation<a class="headerlink" href="#apply-the-dropconnect-transformation" title="Link to this heading">¬∂</a></h2>
<p>We now transform the base model with <code class="docutils literal notranslate"><span class="pre">dropconnect()</span></code>. This will replace its <code class="docutils literal notranslate"><span class="pre">nn.Linear</span></code> layers with <code class="docutils literal notranslate"><span class="pre">DropConnectLinear</span></code>layers that stay active during inference.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mc_model_dc</span> <span class="o">=</span> <span class="n">dropconnect</span><span class="p">(</span><span class="n">base_model</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>
<span class="n">mc_model_dc</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># Activate stochasticity for MC passes</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>TinyNet(
  (fc1): Linear(in_features=16, out_features=32, bias=True)
  (fc2): DropConnectLinear(in_features=32, out_features=8, bias=True)
  (out): DropConnectLinear(in_features=8, out_features=3, bias=True)
)
</pre></div>
</div>
</div>
</div>
</section>
<section id="monte-carlo-inference-repeated-forward-passes">
<h2>3. Monte-Carlo inference: repeated forward passes<a class="headerlink" href="#monte-carlo-inference-repeated-forward-passes" title="Link to this heading">¬∂</a></h2>
<p>We feed the same input through the model multiple times and collect the stochastic outputs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_passes</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">logits_list</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_passes</span><span class="p">):</span>
        <span class="n">logits_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mc_model_dc</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="n">logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">logits_list</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># [num_passes, 3]</span>
<span class="n">probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># convert to probabilities</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="quantify-uncertainty">
<h2>4. Quantify uncertainty<a class="headerlink" href="#quantify-uncertainty" title="Link to this heading">¬∂</a></h2>
<p>Compute the mean and standard deviation across all passes ‚Äî these capture the central tendency and spread (uncertainty).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">probly.quantification</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification</span> <span class="k">as</span> <span class="n">q</span>

<span class="c1"># Reshape for probly&#39;s quantification functions: [n_instances, n_samples, n_classes]</span>
<span class="n">probs_reshaped</span> <span class="o">=</span> <span class="n">probs</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">mean_probs</span> <span class="o">=</span> <span class="n">probs</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">std_probs</span> <span class="o">=</span> <span class="n">probs</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">unbiased</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">pred_class</span> <span class="o">=</span> <span class="n">mean_probs</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="n">predictive_entropy</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">total_entropy</span><span class="p">(</span><span class="n">probs_reshaped</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean probabilities:&quot;</span><span class="p">,</span> <span class="n">mean_probs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Std probabilities:&quot;</span><span class="p">,</span> <span class="n">std_probs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Predicted class:&quot;</span><span class="p">,</span> <span class="n">pred_class</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Predictive entropy: </span><span class="si">{</span><span class="n">predictive_entropy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mean probabilities: tensor([0.3199, 0.3917, 0.2884])
Std probabilities: tensor([0., 0., 0.])
Predicted class: 1
Predictive entropy: 1.5730
</pre></div>
</div>
</div>
</div>
</section>
<section id="visualization-inspecting-uncertainty-distributions">
<h2>5. Visualization ‚Äì Inspecting uncertainty distributions<a class="headerlink" href="#visualization-inspecting-uncertainty-distributions" title="Link to this heading">¬∂</a></h2>
<p>We visualize how much the predicted probabilities fluctuate across the runs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">winning_class</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">mean_probs</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">probs</span><span class="p">[:,</span> <span class="n">winning_class</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;skyblue&quot;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Distribution of predicted probability - class </span><span class="si">{</span><span class="n">winning_class</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted probability&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Frequency&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/b35c75ee517381829b978860f61056fd0bde74950ab2b6f1e1d4d3831d023514.png" src="../../_images/b35c75ee517381829b978860f61056fd0bde74950ab2b6f1e1d4d3831d023514.png" />
</div>
</div>
<blockquote>
<div><p><strong>Interpretation:</strong><br />
‚Äì Narrow peak near 1.0 ‚Üí model confident<br />
‚Äì Wide or multimodal distribution ‚Üí model uncertain</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">C</span> <span class="o">=</span> <span class="n">mean_probs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">C</span><span class="p">),</span> <span class="n">mean_probs</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">yerr</span><span class="o">=</span><span class="n">std_probs</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">capsize</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;lightcoral&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">C</span><span class="p">),</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;Class </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">C</span><span class="p">)])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Predicted probability&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Mean ¬± Std of predicted probabilities per class&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/ed7280cf1ed7f9454fcb41732aa4896519a536e5004ae6160b35a04e4e723ab8.png" src="../../_images/ed7280cf1ed7f9454fcb41732aa4896519a536e5004ae6160b35a04e4e723ab8.png" />
</div>
</div>
</section>
<hr class="docutils" />
<section id="final-summary-dropconnect-transformation-tutorial">
<h2>Final Summary ‚Äî Dropconnect Transformation Tutorial<a class="headerlink" href="#final-summary-dropconnect-transformation-tutorial" title="Link to this heading">¬∂</a></h2>
<hr class="docutils" />
<p>This tutorial showed how the concept of <code class="docutils literal notranslate"><span class="pre">DropConnect</span></code> can be used as a powerful tool for uncertainty-aware deep learning with <code class="docutils literal notranslate"><span class="pre">probly</span></code>.
We began by understanding that <code class="docutils literal notranslate"><span class="pre">DropConnect</span></code> regularizes a model by randomly dropping individual weights, a more generalized approach than Dropout‚Äôs method of dropping entire neuron activations.
We then saw how the <code class="docutils literal notranslate"><span class="pre">DropConnect</span></code> Transformation in <code class="docutils literal notranslate"><span class="pre">probly</span></code> operationalizes this for uncertainty: it replaces standard linear layers with custom, stochastic versions that remain active during inference.
By running multiple forward passes, the model reveals not only its predictions but also its confidence, which we quantified and visualized.
Through this process, we transformed <code class="docutils literal notranslate"><span class="pre">DropConnect</span></code> from a training regularizer into a practical tool for providing valuable insight into a model‚Äôs confidence and reliability.</p>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="dropout_transformation.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Dropout Transformation</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="bayesian_transformation.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Bayesian Transformation</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2025, probly team
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Dropconnect Transformation</a><ul>
<li><a class="reference internal" href="#part-a-introduction-to-dropconnect-and-the-dropconnect-transformation">Part A: Introduction to Dropconnect and the Dropconnect Transformation</a></li>
<li><a class="reference internal" href="#concept-what-is-dropconnect-normal-vs-dropconnect-transformation">1. Concept: What is Dropconnect (normal) vs Dropconnect Transformation?</a><ul>
<li><a class="reference internal" href="#normal-dropout-recap">1.1 Normal Dropout (Recap)</a></li>
<li><a class="reference internal" href="#normal-dropconnect">1.2 Normal DropConnect</a></li>
<li><a class="reference internal" href="#dropconnect-transformation-probly">1.3 DropConnect Transformation (probly)</a></li>
<li><a class="reference internal" href="#a-short-sidebyside-comparison">1.4 A Short side‚Äëby‚Äëside comparison</a></li>
</ul>
</li>
<li><a class="reference internal" href="#quickstart-pytorch">2. Quickstart (PyTorch)</a><ul>
<li><a class="reference internal" href="#notes-on-the-structure">Notes on the structure</a></li>
</ul>
</li>
<li><a class="reference internal" href="#uncertainty-via-dropconnect">3. Uncertainty via DropConnect</a></li>
<li><a class="reference internal" href="#good-practices">4. Good practices</a></li>
<li><a class="reference internal" href="#common-errors">5. Common errors</a></li>
<li><a class="reference internal" href="#next-steps">6. Next steps</a></li>
<li><a class="reference internal" href="#part-a-summary">7. Part A Summary</a></li>
<li><a class="reference internal" href="#part-b-applied-mc-dropconnect">Part B ‚Äî Applied MC-Dropconnect</a></li>
<li><a class="reference internal" href="#apply-the-dropconnect-transformation">2. Apply the DropConnect transformation</a></li>
<li><a class="reference internal" href="#monte-carlo-inference-repeated-forward-passes">3. Monte-Carlo inference: repeated forward passes</a></li>
<li><a class="reference internal" href="#quantify-uncertainty">4. Quantify uncertainty</a></li>
<li><a class="reference internal" href="#visualization-inspecting-uncertainty-distributions">5. Visualization ‚Äì Inspecting uncertainty distributions</a></li>
<li><a class="reference internal" href="#final-summary-dropconnect-transformation-tutorial">Final Summary ‚Äî Dropconnect Transformation Tutorial</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../../_static/documentation_options.js?v=4621528c"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/scripts/furo.js?v=5fa4622c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=ccdb6887"></script>
    </body>
</html>