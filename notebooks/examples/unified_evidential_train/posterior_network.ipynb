{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5b81968",
   "metadata": {},
   "source": [
    "# Posterior Network: Uncertainty Estimation without OOD Samples via Density-Based Pseudo-Counts\n",
    "\n",
    "Posterior Networks (PostNet) extend the idea of Evidential Deep Learning (EDL) by producing a full Dirichlet distribution over class probabilities for each input. However, instead of evidence being directly predicted by the neural network, PostNet does so by deriving evidence from class-conditional density estimates in a latent space. This assures that out-of-distribution (OOD) samples are not needed during training, as uncertainty increases for inputs that lie outside the learned density.\n",
    "\n",
    "In this notebook, we will:\n",
    "- Build a small encoder to map inputs into a latent space\n",
    "- Train a single batched radial flow that models all class-conditional densities\n",
    "- Convert densities into evidence (Dirichlet pseudo-counts) and train with a unified evidential trainer\n",
    "- Evaluate accuracy and plot epistemic evidence for in-distribution (ID) and OOD data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187fd6fa",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00d22d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torch.distributions import Dirichlet\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from probly.layers.evidential import torch as t\n",
    "import probly.layers.evidential.torch as l\n",
    "from probly.losses.evidential.torch import postnet_loss\n",
    "import probly.models.evidential.torch as m\n",
    "from probly.train.evidential.torch import unified_evidential_train\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d91721",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Posterior Networks require:\n",
    "- an ID dataset used for training and standard evaluation\n",
    "- an OOD dataset used only for testing epistemic uncertainty\n",
    "\n",
    "Here, we use **MNIST** as the ID dataset and **FashionMNIST** as the OOD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93bbf28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded MNIST (ID) and FashionMNIST (OOD)\n"
     ]
    }
   ],
   "source": [
    "transform = T.transforms.Compose(\n",
    "    [\n",
    "        T.transforms.ToTensor(),\n",
    "        T.transforms.Normalize((0.5,), (0.5,)),\n",
    "    ],\n",
    ")\n",
    "\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root=\"~/datasets\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root=\"~/datasets\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "ood_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"~/datasets\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=256, shuffle=False)\n",
    "ood_loader = DataLoader(ood_data, batch_size=256, shuffle=False)\n",
    "\n",
    "print(\"Loaded MNIST (ID) and FashionMNIST (OOD)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c437fd8",
   "metadata": {},
   "source": [
    "## Model Definition\n",
    "\n",
    "Posterior Networks are composed of:\n",
    "1. **Encoder**: maps each image to a low-dimensional latent vector.\n",
    "2. **Class-conditional normalizing flows**: instead of training one flow per class, we use a single batched radial-flow model that jointly computes all class-conditional densities P(z|c). These densities provide the evidence used to construct the Dirichlet distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4886e7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder (x -> z)\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim=6) -> None:  # noqa: ANN001\n",
    "        \"\"\"Initialize encoder with a small MLP and BatchNorm.\"\"\"\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(784, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, latent_dim),\n",
    "        )\n",
    "        self.bn = nn.BatchNorm1d(latent_dim)\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:  # noqa: ANN001\n",
    "        \"\"\"Encode a batch of images x into latent vectors z.\"\"\"\n",
    "        z = self.net(x)\n",
    "        z = self.bn(z)\n",
    "        return z\n",
    "\n",
    "\n",
    "# Normalizing flows\n",
    "\n",
    "\n",
    "class RadialFlowLayer(nn.Module):\n",
    "    \"\"\"Single radial flow transformation shared across all classes.\"\"\"\n",
    "\n",
    "    def __init__(self, num_classes: int, dim: int) -> None:\n",
    "        \"\"\"Initialize parameters for a radial flow transform.\"\"\"\n",
    "        super().__init__()\n",
    "        self.c = num_classes\n",
    "        self.dim = dim\n",
    "\n",
    "        self.x0 = nn.Parameter(torch.zeros(self.c, self.dim))\n",
    "        self.alpha_prime = nn.Parameter(torch.zeros(self.c))\n",
    "        self.beta_prime = nn.Parameter(torch.zeros(self.c))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        \"\"\"Reset learnable parameters with a small uniform init.\"\"\"\n",
    "        stdv = 1.0 / math.sqrt(self.dim)\n",
    "        self.x0.data.uniform_(-stdv, stdv)\n",
    "        self.alpha_prime.data.uniform_(-stdv, stdv)\n",
    "        self.beta_prime.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, zc) -> tuple[torch.Tensor, torch.Tensor]:  # noqa: ANN001\n",
    "        \"\"\"Apply the radial flow to latent inputs zc.\"\"\"\n",
    "        alpha = torch.nn.functional.softplus(self.alpha_prime)\n",
    "        beta = -alpha + torch.nn.functional.softplus(self.beta_prime)\n",
    "\n",
    "        x0 = self.x0.unsqueeze(1)\n",
    "        diff = zc - x0\n",
    "        r = diff.norm(dim=-1)\n",
    "\n",
    "        h = 1.0 / (alpha.unsqueeze(1) + r)\n",
    "        h_prime = -h * h\n",
    "        beta_h = beta.unsqueeze(1) * h\n",
    "\n",
    "        z_new = zc + beta_h.unsqueeze(-1) * diff\n",
    "\n",
    "        term1 = (self.dim - 1) * torch.log1p(beta_h)\n",
    "        term2 = torch.log1p(beta_h + beta.unsqueeze(1) * h_prime * r)\n",
    "        log_abs_det = term1 + term2\n",
    "\n",
    "        return z_new, log_abs_det\n",
    "\n",
    "\n",
    "class BatchedRadialFlowDensity(nn.Module):\n",
    "    \"\"\"Radial-flow density estimator that computes P(z|c) for all classes.\"\"\"\n",
    "\n",
    "    def __init__(self, num_classes: int, dim: int, flow_length: int = 6) -> None:\n",
    "        \"\"\"Create a sequence of radial flow layers and base distribution.\"\"\"\n",
    "        super().__init__()\n",
    "        self.c = num_classes\n",
    "        self.dim = dim\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [RadialFlowLayer(num_classes, dim) for _ in range(flow_length)],\n",
    "        )\n",
    "\n",
    "        self.log_base_const = -0.5 * self.dim * math.log(2 * math.pi)\n",
    "\n",
    "    def forward(self, x) -> tuple[torch.Tensor, torch.Tensor]:  # noqa: ANN001\n",
    "        \"\"\"Expand input x for all classes and apply flow layers.\"\"\"\n",
    "        B = x.size(0)  # noqa: N806\n",
    "        zc = x.unsqueeze(0).expand(self.c, B, self.dim)\n",
    "        sum_log_jac = torch.zeros(self.c, B, device=x.device)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            zc, log_j = layer(zc)\n",
    "            sum_log_jac = sum_log_jac + log_j\n",
    "\n",
    "        return zc, sum_log_jac\n",
    "\n",
    "    def log_prob(self, x) -> torch.Tensor:  # noqa: ANN001\n",
    "        \"\"\"Return class-conditional log densities log P(x|c).\"\"\"\n",
    "        zc, sum_log_jac = self.forward(x)  # zc: [C,B,D]\n",
    "\n",
    "        base_logp = self.log_base_const - 0.5 * (zc**2).sum(dim=-1)\n",
    "        logp = base_logp + sum_log_jac  # [C,B]\n",
    "\n",
    "        return logp.transpose(0, 1)  # [B,C]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45df54f",
   "metadata": {},
   "source": [
    "## PostNet Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937e8a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postnet_loss2(\n",
    "    z: Tensor,\n",
    "    y: Tensor,\n",
    "    flow: t.BatchedRadialFlowDensity,\n",
    "    class_counts: Tensor,\n",
    "    entropy_weight: float = 1e-5,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Posterior Networks (PostNet) loss.\"\"\"\n",
    "    log_dens = flow.log_prob(z)  # [B,C]\n",
    "    dens = log_dens.exp()\n",
    "\n",
    "    beta = dens * class_counts.unsqueeze(0)\n",
    "    alpha = beta + 1.0\n",
    "    alpha0 = alpha.sum(dim=1)\n",
    "\n",
    "    digamma = torch.digamma\n",
    "    batch_idx = torch.arange(len(y), device=y.device)\n",
    "    expected_ce = digamma(alpha0) - digamma(alpha[batch_idx, y])\n",
    "\n",
    "    entropy = Dirichlet(alpha).entropy()\n",
    "\n",
    "    loss = (expected_ce - entropy_weight * entropy).mean()\n",
    "    return loss, alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd79bb6d",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2792a911",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "empty(): argument 'size' failed to unpack the object at pos 2 with error \"type must be tuple of ints,but got Tensor\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m         class_counts[c] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (y \u001b[38;5;241m==\u001b[39m c)\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m      9\u001b[0m latent_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m\n\u001b[1;32m---> 10\u001b[0m encoder \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPostNetModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_counts\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m postnet_loss\n\u001b[0;32m     12\u001b[0m flow \u001b[38;5;241m=\u001b[39m l\u001b[38;5;241m.\u001b[39mBatchedRadialFlowDensity(num_classes\u001b[38;5;241m=\u001b[39mnum_classes, dim\u001b[38;5;241m=\u001b[39mlatent_dim, flow_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32m~\\probly\\src\\probly\\models\\evidential\\torch.py:209\u001b[0m, in \u001b[0;36mPostNetModel.__init__\u001b[1;34m(self, encoder, num_classes, latent_dim, head, input_dim)\u001b[0m\n\u001b[0;32m    207\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPostNetModel: either provide encoder or input_dim.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    208\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m--> 209\u001b[0m     encoder \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFlattenMLPEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlatent_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(encoder, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatent_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    212\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoder must define `latent_dim`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\probly\\src\\probly\\layers\\evidential\\torch.py:389\u001b[0m, in \u001b[0;36mFlattenMLPEncoder.__init__\u001b[1;34m(self, input_dim, hidden_dim, latent_dim)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatent_dim \u001b[38;5;241m=\u001b[39m latent_dim\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[0;32m    388\u001b[0m     nn\u001b[38;5;241m.\u001b[39mFlatten(start_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m--> 389\u001b[0m     \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    390\u001b[0m     nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[0;32m    391\u001b[0m     nn\u001b[38;5;241m.\u001b[39mLinear(hidden_dim, latent_dim),\n\u001b[0;32m    392\u001b[0m     nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[0;32m    393\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\abdou\\probly\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:109\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[1;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_features \u001b[38;5;241m=\u001b[39m in_features\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_features \u001b[38;5;241m=\u001b[39m out_features\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m Parameter(\n\u001b[1;32m--> 109\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_features\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m )\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m Parameter(torch\u001b[38;5;241m.\u001b[39mempty(out_features, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs))\n",
      "\u001b[1;31mTypeError\u001b[0m: empty(): argument 'size' failed to unpack the object at pos 2 with error \"type must be tuple of ints,but got Tensor\""
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "class_counts = torch.zeros(num_classes, device=device)\n",
    "\n",
    "for _, y in train_loader:\n",
    "    y = y.to(device)  # noqa: PLW2901\n",
    "    for c in range(num_classes):\n",
    "        class_counts[c] += (y == c).sum()\n",
    "\n",
    "latent_dim = 6\n",
    "encoder = m.PostNetModel(latent_dim=latent_dim, input_dim=class_counts).to(device)\n",
    "loss = postnet_loss\n",
    "flow = l.BatchedRadialFlowDensity(num_classes=num_classes, dim=latent_dim, flow_length=6).to(device)\n",
    "\n",
    "unified_evidential_train(\n",
    "    \"PostNet\",\n",
    "    encoder,\n",
    "    train_loader,\n",
    "    loss,\n",
    "    flow=flow,\n",
    "    class_count=class_counts,\n",
    "    epochs=5,\n",
    "    lr=1e-3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710a82ee",
   "metadata": {},
   "source": [
    "## Evaluation: Predictions & Accuracy\n",
    "Compute Dirichlet posteriors and accuracy on the MNIST test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9d1413",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, flow, loader, class_counts) -> float:  # noqa: ANN001\n",
    "    encoder.eval()\n",
    "    flow.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)  # noqa: PLW2901\n",
    "            z = encoder(x)\n",
    "\n",
    "            log_dens = flow.log_prob(z)\n",
    "            dens = log_dens.exp()\n",
    "            beta = dens * class_counts.unsqueeze(0)\n",
    "            alpha = beta + 1.0\n",
    "            alpha0 = alpha.sum(dim=1, keepdim=True)\n",
    "\n",
    "            probs = alpha / alpha0\n",
    "            preds = probs.argmax(dim=1)\n",
    "\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += len(y)\n",
    "\n",
    "    acc = correct / total\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    return acc\n",
    "\n",
    "\n",
    "evaluate(encoder, flow, test_loader, class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc6207d",
   "metadata": {},
   "source": [
    "## Epistemic Uncertainty Extraction\n",
    "\n",
    "Posterior Networks quantify epistemic uncertainty using the total Dirichlet evidence, defined as the sum of all Dirichlet parameters for each class. High evidence indicates high confidence (in-distribution), while low evidence indicates uncertainty. Here, we compute evidence values for MNIST and FashionMNIST samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113d2e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_alpha0(encoder, flow, loader, class_counts) -> torch.Tensor:  # noqa: ANN001\n",
    "    encoder.eval()\n",
    "    flow.eval()\n",
    "\n",
    "    out = []\n",
    "    with torch.no_grad():\n",
    "        for x, _ in loader:\n",
    "            x = x.to(device)  # noqa: PLW2901\n",
    "            z = encoder(x)\n",
    "            log_dens = flow.log_prob(z)\n",
    "            dens = log_dens.exp()\n",
    "            beta = dens * class_counts.unsqueeze(0)\n",
    "            alpha = beta + 1.0\n",
    "            alpha0 = alpha.sum(dim=1)\n",
    "            out.append(alpha0.cpu())\n",
    "    return torch.cat(out)\n",
    "\n",
    "\n",
    "id_alpha0 = compute_alpha0(encoder, flow, test_loader, class_counts)\n",
    "ood_alpha0 = compute_alpha0(encoder, flow, ood_loader, class_counts)\n",
    "\n",
    "print(\"Mean ID α₀:\", id_alpha0.mean().item())\n",
    "print(\"Mean OOD α₀:\", ood_alpha0.mean().item())\n",
    "\n",
    "eps = 1e-12\n",
    "id_log = np.log10(id_alpha0.numpy() + eps)\n",
    "ood_log = np.log10(ood_alpha0.numpy() + eps)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(id_log, bins=60, density=True, alpha=0.6, label=\"ID (MNIST)\")\n",
    "plt.hist(ood_log, bins=60, density=True, alpha=0.6, label=\"OOD (FashionMNIST)\")\n",
    "plt.xlabel(r\"$\\log_{10}(\\alpha_0)$ (total evidence)\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"PostNet evidence: ID vs OOD\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "probly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
