{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad65fcd7",
   "metadata": {},
   "source": [
    "# Information Robust Dirichlet Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cb53a5",
   "metadata": {},
   "source": [
    "In this notebook, we implement the specialized training loss proposed in the paper _Information Robust Dirichlet Networks for Predictive Uncertainty Estimation_ by Tsiligkaridis (2019). The method models predictive uncertainty by having a neural network output Dirichlet concentration parameters ð›¼ instead of just a pointwise softmax.\n",
    "\n",
    "The total loss is composed of three terms:\n",
    "\n",
    "1. Calibration term: implemented in the function  lp_fn\n",
    "2. Regularization term: implemented in the function  regularization_fn\n",
    "3. Adversiarial Entropy penalty: implemented in the function  dirichlet_entropy\n",
    "\n",
    "In the paper and in this notenbook, L_p loss is not directly computed but rather an upper bound for it, denoted by F_i (for sample i)  \n",
    "\n",
    "The regularization term penalizes high alpha values for incorrect classes.  \n",
    "\n",
    "The final term uses the alpha values the model assigns to adversarial inputs.\n",
    "The model is rewarded for outputting a Dirichlet-distribution with high entropy on these inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb20a7ec",
   "metadata": {},
   "source": [
    "### 1. The Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c812c84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import torch\n",
    "from torch.special import digamma\n",
    "\n",
    "\n",
    "def lp_fn(alpha: torch.Tensor, y: torch.Tensor, p: float = 2.0) -> torch.Tensor:\n",
    "    \"\"\"Compute the Lp calibration loss (upper bound Fi).\n",
    "\n",
    "    Computes F_i using the expectation-based formulation:\n",
    "        F_i = ( E[(1-p_c)^p] + Î£_{jâ‰ c} E[p_j^p] )^(1/p)\n",
    "\n",
    "    Args:\n",
    "        alpha: Dirichlet concentration parameters, shape (B, K), must be > 0\n",
    "        y: One-hot encoded labels, shape (B, K)\n",
    "        p: Lp norm exponent (default: 2.0)\n",
    "\n",
    "    Returns:\n",
    "        Scalar loss summed over batch\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If alpha contains non-positive values or shapes don't match\n",
    "    \"\"\"\n",
    "    if not torch.all(alpha > 0):\n",
    "        msg = f\"All alpha values must be > 0, got min={alpha.min().item()}\"\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    if alpha.shape != y.shape:\n",
    "        msg = f\"alpha and y shape mismatch: {alpha.shape} vs {y.shape}\"\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    # total concentration alpha0\n",
    "    alpha0 = alpha.sum(dim=1, keepdim=True)  # (B,1)\n",
    "\n",
    "    # extract alpha_c (correct class)\n",
    "    alpha_c = (alpha * y).sum(dim=1, keepdim=True)  # (B,1)\n",
    "    alpha0_minus_c = alpha0 - alpha_c  # (B,1)\n",
    "\n",
    "    # log B(a,b) used for expectations: E[X^p] = B(a+p,b)/B(a,b)\n",
    "    def log_b(a: torch.Tensor, b: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.lgamma(a) + torch.lgamma(b) - torch.lgamma(a + b)\n",
    "\n",
    "    # E[(1 - p_c)^p]   where (1 - p_c) ~ Beta( alpha0 - alpha_c , alpha_c )\n",
    "    log_e1 = log_b(alpha0_minus_c + p, alpha_c) - log_b(alpha0_minus_c, alpha_c)\n",
    "    e1 = torch.exp(log_e1)  # (B,1)\n",
    "\n",
    "    # Per-class E[p_j^p] for all j\n",
    "    log_ep = log_b(alpha + p, alpha0 - alpha) - log_b(alpha, alpha0 - alpha)\n",
    "    ep = torch.exp(log_ep)\n",
    "\n",
    "    # zero-out the true class term so we sum only jâ‰ c\n",
    "    ep = ep * (1 - y)\n",
    "\n",
    "    # final expectation sum\n",
    "    e_sum = e1 + ep.sum(dim=1, keepdim=True)  # (B,1)\n",
    "\n",
    "    # apply the 1/p power to the expectation sum\n",
    "    fi = torch.exp(torch.log(e_sum + 1e-8) / p).squeeze(1)  # (B,)\n",
    "\n",
    "    return fi.sum()\n",
    "\n",
    "\n",
    "def regularization_fn(alpha: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Compute the regularization term using trigamma functions.\n",
    "\n",
    "    Penalizes high alpha values for incorrect classes to encourage confident\n",
    "    but calibrated predictions.\n",
    "\n",
    "    Args:\n",
    "        alpha: Dirichlet concentration parameters, shape (B, K), must be > 0\n",
    "        y: One-hot encoded labels, shape (B, K)\n",
    "\n",
    "    Returns:\n",
    "        Scalar regularization loss\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If shapes don't match\n",
    "    \"\"\"\n",
    "    if alpha.shape != y.shape:\n",
    "        msg = f\"alpha and y shape mismatch: {alpha.shape} vs {y.shape}\"\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    # Build alpha_tilde by replacing correct-class alpha with 1\n",
    "    alpha_tilde = alpha * (1 - y) + y\n",
    "\n",
    "    # Compute alpha_tilde_0 = 1 + sum over incorrect classes\n",
    "    alpha_tilde_0 = torch.sum(alpha_tilde, dim=1, keepdim=True)\n",
    "\n",
    "    # Polygamma(1, x) = trigamma(x)\n",
    "    trigamma_alpha = torch.polygamma(1, alpha_tilde)\n",
    "    trigamma_alpha0 = torch.polygamma(1, alpha_tilde_0)\n",
    "\n",
    "    # (alpha_tilde - 1)^2 term\n",
    "    diff_sq = (alpha_tilde - 1.0) ** 2\n",
    "\n",
    "    # Penalty only for incorrect classes â†’ mask out true class\n",
    "    mask = 1 - y\n",
    "\n",
    "    # Compute elementwise contribution\n",
    "    term = 0.5 * diff_sq * (trigamma_alpha - trigamma_alpha0) * mask\n",
    "\n",
    "    # Sum over classes and batch\n",
    "    return torch.sum(term)\n",
    "\n",
    "\n",
    "def dirichlet_entropy(alpha: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Compute Dirichlet entropy.\n",
    "\n",
    "    For adversarial examples, we want to maximize entropy (reward the model for\n",
    "    being uncertain), which appears as a negative term in the loss.\n",
    "\n",
    "    Entropy formula (a stands for alpha):\n",
    "        H(a) = log B(a) + (a_0 - K) * Ïˆ(a_0) - Î£_k (a_k - 1) * Ïˆ(a_k)\n",
    "\n",
    "    Args:\n",
    "        alpha: Dirichlet concentration parameters, shape (B_a, K), must be > 0\n",
    "\n",
    "    Returns:\n",
    "        Scalar entropy summed over batch\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If alpha contains non-positive values\n",
    "    \"\"\"\n",
    "    if not torch.all(alpha > 0):\n",
    "        msg = f\"All alpha values must be > 0, got min={alpha.min().item()}\"\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    k = alpha.size(-1)\n",
    "    alpha0 = alpha.sum(dim=-1)\n",
    "\n",
    "    log_b = torch.lgamma(alpha).sum(dim=-1) - torch.lgamma(alpha0)\n",
    "\n",
    "    term1 = log_b\n",
    "    term2 = (alpha0 - k) * digamma(alpha0)\n",
    "    term3 = ((alpha - 1) * digamma(alpha)).sum(dim=-1)\n",
    "    entropy = term1 + term2 - term3\n",
    "\n",
    "    return entropy.sum()\n",
    "\n",
    "\n",
    "def loss_ird(\n",
    "    alpha: torch.Tensor,\n",
    "    y: torch.Tensor,\n",
    "    adversarial_alpha: torch.Tensor | None = None,\n",
    "    p: float = 2.0,\n",
    "    lam: float = 1e-1,\n",
    "    gamma: float = 5e-3,\n",
    "    normalize: bool = True,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Compute the IRD loss.\n",
    "\n",
    "    This implements the lossintroduced in the paper:\n",
    "    \"Information Robust Dirichlet Networks for Predictive Uncertainty Estimation\".\n",
    "\n",
    "    Args:\n",
    "        alpha : (B, K) Dirichlet concentration parameters\n",
    "        adversarial_alpha : (B_a, K) adversarial_alpha concentration parameters for adversarial inputs\n",
    "        y     : (B, K) one-hot labels\n",
    "        p     : scalar exponent\n",
    "        lam   : Weight of the regularization term\n",
    "        gamma : Weight of the adversarial entropy term\n",
    "        normalize : Whether to normalize loss terms by batch size\n",
    "\n",
    "    Returns:\n",
    "        loss_IRD : the IRD loss comprised of all three terms, summed over all input examples.\n",
    "    \"\"\"\n",
    "    # Input validation\n",
    "    if alpha.dim() != 2 or y.dim() != 2:\n",
    "        msg = f\"alpha and y must be 2D, got {alpha.dim()}, {y.dim()}\"\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    if alpha.shape != y.shape:\n",
    "        msg = f\"alpha and y shape mismatch: {alpha.shape} vs {y.shape}\"\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    if not torch.all(alpha > 0):\n",
    "        msg = f\"All alpha values must be > 0, got min={alpha.min().item()}\"\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    # Compute Loss Components\n",
    "    lp_term = lp_fn(alpha, y, p)\n",
    "    reg_term = regularization_fn(alpha, y)\n",
    "\n",
    "    if adversarial_alpha is not None:\n",
    "        if adversarial_alpha.dim() != 2:\n",
    "            msg = f\"adversarial_alpha must be 2D, got {adversarial_alpha.dim()}\"\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        if adversarial_alpha.shape[1] != alpha.shape[1]:\n",
    "            msg = (\n",
    "                f\"adversarial_alpha must have same number of classes as alpha: \"\n",
    "                f\"{adversarial_alpha.shape[1]} vs {alpha.shape[1]}\"\n",
    "            )\n",
    "            raise ValueError(\n",
    "                msg,\n",
    "            )\n",
    "\n",
    "        entropy_term = dirichlet_entropy(adversarial_alpha)\n",
    "    else:\n",
    "        entropy_term = 0.0\n",
    "\n",
    "    # Normalize by batch sizes for stable training across different batch sizes\n",
    "    if normalize:\n",
    "        b = alpha.shape[0]\n",
    "        k = alpha.shape[1]\n",
    "        lp_term = lp_term / b\n",
    "        reg_term = reg_term / (b * k)\n",
    "\n",
    "        if adversarial_alpha is not None and isinstance(entropy_term, torch.Tensor):\n",
    "            b_a = adversarial_alpha.shape[0]\n",
    "            entropy_term = entropy_term / b_a\n",
    "\n",
    "    loss = lp_term + lam * reg_term - gamma * entropy_term\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1beb6163",
   "metadata": {},
   "source": [
    "### 2. Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf03556",
   "metadata": {},
   "source": [
    "#### LetÂ´s assume the user passes a dataset to us\n",
    "In this example we use MNIST as an example, but the code works for any torch.util.data.Dataset class.\n",
    "\n",
    "If the user has a dataset, which he passes to us, we can automatically adapt the models input channels and output dimension (num_classes), based on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a02af417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed loading the dataset\n",
      "Training set size: 54000, Validation set size: 6000\n"
     ]
    }
   ],
   "source": [
    "# example dataset\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Load full MNIST training set\n",
    "full_train_dataset = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "# split into training and validation sets\n",
    "train_size = int(0.9 * len(full_train_dataset))\n",
    "val_size = len(full_train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
    "\n",
    "print(\"Completed loading the dataset\")\n",
    "print(f\"Training set size: {len(train_dataset)}, Validation set size: {len(val_dataset)}\")\n",
    "\n",
    "# wrap into a DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35356e4",
   "metadata": {},
   "source": [
    "#### Determine the input channels and number of class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c97b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1, 28, 28), Number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "def get_num_classes(dataset: torch.utils.data.Dataset) -> int:\n",
    "    \"\"\"Determine number of classes by checking in order.\n",
    "\n",
    "    1) dataset.classes\n",
    "    2) dataset.targets\n",
    "    3) full dataset scan (max label + 1).\n",
    "    \"\"\"\n",
    "    # Try Torchvision-style classes attribute\n",
    "    if hasattr(dataset, \"classes\"):\n",
    "        try:\n",
    "            return len(dataset.classes)\n",
    "        except (TypeError, AttributeError):\n",
    "            pass\n",
    "\n",
    "    # Else try Torchvision-style targets tensor\n",
    "    if hasattr(dataset, \"targets\"):\n",
    "        targets = dataset.targets\n",
    "        if isinstance(targets, torch.Tensor):\n",
    "            return int(targets.max().item()) + 1\n",
    "        return max(targets) + 1\n",
    "\n",
    "    # Fallback: scan entire dataset\n",
    "    max_label = -1\n",
    "    for _, y in dataset:\n",
    "        label = y.item() if isinstance(y, torch.Tensor) else y\n",
    "        max_label = max(max_label, int(label))\n",
    "\n",
    "    return max_label + 1\n",
    "\n",
    "\n",
    "# to get the number of input channels, take the first image from the dataset and check its shape\n",
    "c_in, H, W = full_train_dataset[0][0].shape  # assuming dataset returns (image, label) tuples\n",
    "\n",
    "# to get the number of classes, use the get_num_classes function\n",
    "num_classes = get_num_classes(full_train_dataset)\n",
    "\n",
    "print(f\"Input shape: ({c_in}, {H}, {W}), Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df1da84",
   "metadata": {},
   "source": [
    "We train the model using different parameters like the model we are using, the loss function we are using (loss_fn), or the number of training epochs, etc. \n",
    "\n",
    "Because in the paper that this notebook is based on, OOD inputs are used for the robustness of the model, so we also test our model on OOD inputs using the validate function. The confidence for these inputs should be lower than for the ID inputs.\n",
    "\n",
    "We also add different uncertainty metrics, the predictive entropy (aleatoric & epistemic uncertainty) and mutual information (epistemic uncertainty). Using these metrics, we can further estimate the correctness and uncertainty of our model. The value of the entropy for the uniform distribution over 10 classes is around 2.3. This is the highest uncertainty the model can assign, so the values of the predictive entropy should be around 2.3, never higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ec0447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(\n",
    "    model: torch.nn.Module,\n",
    "    val_loader: DataLoader = val_loader,\n",
    "    device: torch.device | None = None,\n",
    ") -> None:\n",
    "    \"\"\"Validation loop.\"\"\"\n",
    "    model.eval()\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    all_pe_id = []\n",
    "    all_mi_id = []\n",
    "    all_pe_ood = []\n",
    "    all_mi_ood = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, _ in val_loader:\n",
    "            x_device = x.to(device)\n",
    "\n",
    "            # In-distribution\n",
    "            alpha_id = model(x_device)\n",
    "            pe_id, mi_id = dirichlet_mi(alpha_id)\n",
    "            all_pe_id.append(pe_id)\n",
    "            all_mi_id.append(mi_id)\n",
    "\n",
    "            # OOD: Permuted MNIST\n",
    "            b = x_device.shape[0]\n",
    "            perm = torch.randperm(28 * 28, device=device)\n",
    "            x_permuted = x_device.reshape(b, 1, -1)[:, :, perm]\n",
    "            x_permuted = x_permuted.reshape(b, 1, 28, 28)\n",
    "\n",
    "            alpha_ood = model(x_permuted)\n",
    "            pe_ood, mi_ood = dirichlet_mi(alpha_ood)\n",
    "            all_pe_ood.append(pe_ood)\n",
    "            all_mi_ood.append(mi_ood)\n",
    "        # Concatenate tensors\n",
    "        pe_id = torch.cat(all_pe_id)\n",
    "        mi_id = torch.cat(all_mi_id)\n",
    "        pe_ood = torch.cat(all_pe_ood)\n",
    "        mi_ood = torch.cat(all_mi_ood)\n",
    "\n",
    "        print(\"=== Uncertainty Summary ===\")\n",
    "        print(f\"ID  â€” Predictive Entropy: mean {pe_id.mean().item():.4f}, std {pe_id.std().item():.4f}\")\n",
    "        print(f\"ID  â€” Mutual Information: mean {mi_id.mean().item():.4f}, std {mi_id.std().item():.4f}\")\n",
    "        print(f\"OOD â€” Predictive Entropy: mean {pe_ood.mean().item():.4f}, std {pe_ood.std().item():.4f}\")\n",
    "        print(f\"OOD â€” Mutual Information: mean {mi_ood.mean().item():.4f}, std {mi_ood.std().item():.4f}\")\n",
    "        return {\n",
    "            \"pe_id\": pe_id,\n",
    "            \"mi_id\": mi_id,\n",
    "            \"pe_ood\": pe_ood,\n",
    "            \"mi_ood\": mi_ood,\n",
    "        }\n",
    "\n",
    "\n",
    "def dirichlet_mi(alpha: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Computes predictive entropy and mutual information for a Dirichlet prior.\n",
    "\n",
    "    Args:\n",
    "        alpha: (B, K) Dirichlet concentration\n",
    "\n",
    "    Returns:\n",
    "        predictive_entropy: (B,)\n",
    "        mutual_information: (B,)\n",
    "    \"\"\"\n",
    "    eps = 1e-12\n",
    "    alpha = torch.clamp(alpha, min=1e-6)\n",
    "    alpha0 = alpha.sum(dim=1, keepdim=True)  # (B,1)\n",
    "\n",
    "    # Predictive probabilities\n",
    "    p = alpha / alpha0\n",
    "\n",
    "    # Predictive entropy H[Y]\n",
    "    predictive_entropy = -(p * torch.log(p + eps)).sum(dim=1)\n",
    "\n",
    "    # Expected conditional entropy E_p[H[Y|p]]\n",
    "    digamma_alpha = torch.digamma(alpha + 1.0)\n",
    "    digamma_alpha0 = torch.digamma(alpha0 + 1.0)  # (B,1)\n",
    "\n",
    "    expected_cond_entropy = -torch.sum(\n",
    "        (alpha / alpha0) * (digamma_alpha - digamma_alpha0),\n",
    "        dim=1,\n",
    "    )\n",
    "\n",
    "    # Mutual information = H[pred] - E[cond]\n",
    "    mutual_information = predictive_entropy - expected_cond_entropy\n",
    "\n",
    "    return predictive_entropy, mutual_information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4204b2cf",
   "metadata": {},
   "source": [
    "Now, we implement the function responsible for calculating the loss, accuracy and confidence for in-distribution samples and the confidence for out-of-distribution samples. The confidence for the OOD-samples should be lower than the confidence for the ID-samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c780bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for OOD inputs\n",
    "@torch.no_grad()\n",
    "def evaluate(\n",
    "    model: nn.Module,\n",
    "    criterion: callable,\n",
    "    data_loader: DataLoader = train_loader,\n",
    "    device: torch.device | None = None,\n",
    ") -> None:\n",
    "    \"\"\"Evaluate model on given data_loader.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss_id = 0.0\n",
    "    correct_id = 0\n",
    "    confidence_id = 0.0\n",
    "    confidence_ood = 0.0\n",
    "    length = len(data_loader.dataset)  # Number of samples\n",
    "\n",
    "    for batch_x, batch_y in data_loader:\n",
    "        x_device = batch_x.to(device)\n",
    "        y_onehot = nn.functional.one_hot(batch_y, num_classes=10).float().to(device)\n",
    "\n",
    "        # OOD Noise inputs\n",
    "        noise = torch.randn_like(x_device).to(device)\n",
    "        alpha_noise = model(noise)\n",
    "\n",
    "        # Calculate loss for in-distribution\n",
    "        alpha = model(x_device)  # (B, num_classes)\n",
    "        total_loss_id += criterion(alpha, y_onehot)\n",
    "\n",
    "        # Calculate accuracy for in-distribution inputs\n",
    "        pred = torch.max(alpha, -1).indices\n",
    "        y_labels = torch.argmax(y_onehot, -1)\n",
    "        correct_id += (pred == y_labels).sum().item()\n",
    "\n",
    "        # Calculate confidence for in-distribution and OOD inputs\n",
    "        confidence_id += (torch.max(alpha, -1).values / torch.sum(alpha, -1)).sum().item()\n",
    "        confidence_ood += (torch.max(alpha_noise, -1).values / torch.sum(alpha_noise, -1)).sum().item()\n",
    "\n",
    "    total_loss_id /= length\n",
    "    accuracy_id = correct_id / length\n",
    "    confidence_ood /= length\n",
    "    confidence_id /= length\n",
    "\n",
    "    print(\"Loss In-Distribution: \", total_loss_id.item())\n",
    "    print(\"Confidence In-Distribution: \", confidence_id)\n",
    "    print(\"Confidence OOD: \", confidence_ood)  # Ideally should be low\n",
    "    print(f\"Evaluation In-Distribution Accuracy: {accuracy_id:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afd6df6",
   "metadata": {},
   "source": [
    "In the following code, we will be plotting a histogram which should visualize our uncertainty for ID and OOD-data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c1118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_uncertainty(\n",
    "    pe_id: torch.Tensor,\n",
    "    pe_ood: torch.Tensor,\n",
    "    mi_id: torch.Tensor,\n",
    "    mi_ood: torch.Tensor,\n",
    ") -> None:\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Predictive Entropy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(\n",
    "        pe_id.cpu().numpy(),\n",
    "        bins=50,\n",
    "        density=True,\n",
    "        alpha=0.6,\n",
    "        label=\"ID\",\n",
    "        color=\"#4C72B0\",\n",
    "    )\n",
    "    plt.hist(\n",
    "        pe_ood.cpu().numpy(),\n",
    "        bins=50,\n",
    "        density=True,\n",
    "        alpha=0.6,\n",
    "        label=\"OOD\",\n",
    "        color=\"#DC1489\",\n",
    "    )\n",
    "    plt.xlabel(\"Predictive Entropy\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.title(\"Predictive Entropy: ID vs OOD\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Mutual Information\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(\n",
    "        mi_id.cpu().numpy(),\n",
    "        bins=50,\n",
    "        density=True,\n",
    "        alpha=0.6,\n",
    "        label=\"ID\",\n",
    "        color=\"#4C72B0\",\n",
    "    )\n",
    "    plt.hist(\n",
    "        mi_ood.cpu().numpy(),\n",
    "        bins=50,\n",
    "        density=True,\n",
    "        alpha=0.6,\n",
    "        label=\"OOD\",\n",
    "        color=\"#DC1489\",\n",
    "    )\n",
    "    plt.xlabel(\"Mutual Information\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.title(\"Mutual Information: ID vs OOD\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feab02d6",
   "metadata": {},
   "source": [
    "#### Showcase of the modular and extensible design\n",
    "\n",
    "Now, you can easily swap the encoder for another encoder. The same goes for the model you want to use, making this setup suitable\n",
    "for a wide range of architectures.\n",
    "\n",
    "Here is a more detailed explanation:\n",
    "\n",
    "â€¢ Importing Module:\n",
    "  IRDModel is a model wrapper that outputs Dirichlet parameters for uncertainty estimation.\n",
    "\n",
    "â€¢ The Encoder:\n",
    "  The example uses a simple MLP encoder (DirichletMLPEncoder) to transform input data (such as flattened images) into\n",
    "  feature embeddings.\n",
    "  However, the design is modular; you can easily swap out the encoder for any other feature extractor (e.g., a CNN, ResNet, or\n",
    "  custom architecture) as long as it is a valid PyTorch nn.Module.\n",
    "  This makes the setup adaptable to different data types and tasks (images, tabular data, etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8847f3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from probly.models.evidential.torch import IRDModel\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class IRDHead(nn.Module):\n",
    "    \"\"\"Head that converts encoded features into Dirichlet concentration parameters (alpha).\n",
    "\n",
    "    For multi-class classification, this head outputs K alpha values (one per class),\n",
    "    where alpha forms a K-dimensional Dirichlet distribution.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, latent_dim: int, num_classes: int) -> None:\n",
    "        \"\"\"Initialize the Dirichlet head.\n",
    "\n",
    "        Args:\n",
    "            latent_dim: Dimension of input features from the encoder.\n",
    "            num_classes: Number of output classes (K in Dirichlet(a)).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.linear = nn.Linear(latent_dim, num_classes)\n",
    "\n",
    "    def forward(self, features: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Convert features into Dirichlet concentration parameters (alpha).\n",
    "\n",
    "        Args:\n",
    "            features: Feature tensor (batch_size, latent_dim) from encoder.\n",
    "\n",
    "        Returns:\n",
    "            Alpha parameters of shape (batch_size, num_classes), all > 0.\n",
    "        \"\"\"\n",
    "        # Linear projection to num_classes dimensions\n",
    "        logits = self.linear(features)\n",
    "\n",
    "        # Ensure alpha > 0 by applying softplus and adding small offset\n",
    "        # alpha = softplus(logits) + 1.0 ensures all values >= 1.0\n",
    "        alpha = F.softplus(logits) + 1.0\n",
    "\n",
    "        return alpha\n",
    "\n",
    "\n",
    "class DirichletMLPEncoder(nn.Module):\n",
    "    \"\"\"Simple MLP encoder for transforming inputs into feature embeddings.\n",
    "\n",
    "    This module contains no evidential logic, only feature extraction.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        hidden_dim: int = 128,\n",
    "        latent_dim: int = 128,\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize the MLP encoder.\n",
    "\n",
    "        Args:\n",
    "            input_dim: Size of input features (flattened or 1D).\n",
    "            hidden_dim: Number of neurons in hidden layers (default: 128).\n",
    "            latent_dim: Dimension of output feature representation (default: 128).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, latent_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute feature embedding.\n",
    "\n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, input_dim).\n",
    "\n",
    "        Returns:\n",
    "            Feature tensor of shape (batch_size, latent_dim).\n",
    "        \"\"\"\n",
    "        # Accepts both flat and image input, always flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "enc = DirichletMLPEncoder(input_dim=28 * 28)\n",
    "model = IRDModel(encoder=enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a019191",
   "metadata": {},
   "source": [
    "Now we implement the main function. We set the parameters and define the mode and loss_fn we are using. In my case, that is the loss proposed in the paper _Information Robust Dirichlet Networks_ by Tsiligkaridis (2019).\n",
    "\n",
    "We also import the unified_evidential_train function now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7bcb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from probly.train.evidential.torch import unified_evidential_train\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    \"\"\"This code presumes that the loss function takes in alpha and y with shape (B, num_classes).\"\"\"\n",
    "    # --------------- Standard setup --------------\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\nDevice: {device}\")\n",
    "    print(\"\\nLoading MNIST dataset...\")\n",
    "\n",
    "    # Define input dimensions and number of classes\n",
    "    input_dim = 784\n",
    "    num_classes = 10\n",
    "\n",
    "    print(\"\\nInitialize model...\")\n",
    "\n",
    "    encoder = DirichletMLPEncoder(input_dim=input_dim)\n",
    "    model = IRDModel(encoder=encoder, num_classes=num_classes)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Train for a few epochs\n",
    "    print(\"\\nStarting training...\")\n",
    "    unified_evidential_train(\n",
    "        mode=\"IRD\",\n",
    "        model=model,\n",
    "        dataloader=train_loader,\n",
    "        loss_fn=loss_ird,\n",
    "        oodloader=train_loader,\n",
    "        class_count=None,\n",
    "        epochs=5,\n",
    "        lr=1e-3,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    # Validate to get uncertainty metrics\n",
    "    results = validate(model, val_loader, device=device)\n",
    "    pe_id = results[\"pe_id\"]\n",
    "    mi_id = results[\"mi_id\"]\n",
    "    pe_ood = results[\"pe_ood\"]\n",
    "    mi_ood = results[\"mi_ood\"]\n",
    "\n",
    "    # Evaluate on train set\n",
    "    evaluate(model, loss_ird, train_loader, device=device)\n",
    "\n",
    "    # Plot uncertainty metrics\n",
    "    plot_uncertainty(pe_id, pe_ood, mi_id, mi_ood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4129f12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Device: cpu\n",
      "\n",
      "Loading MNIST dataset...\n",
      "\n",
      "Initialize model...\n",
      "\n",
      "Starting training...\n",
      "Epoch [1/5] - Loss: 0.5564\n",
      "Epoch [2/5] - Loss: 0.3978\n",
      "Epoch [3/5] - Loss: 0.3727\n",
      "Epoch [4/5] - Loss: 0.3557\n",
      "Epoch [5/5] - Loss: 0.3478\n",
      "=== Uncertainty Summary ===\n",
      "ID  â€” Predictive Entropy: mean 0.3543, std 0.2974\n",
      "ID  â€” Mutual Information: mean 0.0267, std 0.0388\n",
      "OOD â€” Predictive Entropy: mean 1.5034, std 0.5267\n",
      "OOD â€” Mutual Information: mean 0.1780, std 0.1031\n",
      "Loss In-Distribution:  0.0020795876625925303\n",
      "Confidence In-Distribution:  0.933053491168552\n",
      "Confidence OOD:  0.6673500259540699\n",
      "Evaluation In-Distribution Accuracy: 0.9426\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "probly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
