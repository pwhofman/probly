{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6224021b",
   "metadata": {},
   "source": [
    "# `probly` Tutorial â€” Bayesian Transformation \n",
    "\n",
    "This notebook is a practical introduction to the Bayesian transformation in `probly`. Bayesian Neural Networks are a more advanced topic than Dropout or DropConnect,\n",
    "so this tutorial aims to provide an intuitive, hands-on understanding.\n",
    "\n",
    "We will start by explaining the core idea behind Bayesian Neural Networks (BNNs) and then see how the `probly` transformation enables you to create them. After that, we will look at a PyTorch example to inspect the transformed model and use it to estimate uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842a7f1e",
   "metadata": {},
   "source": [
    "---\n",
    "# Part A: Introduction to BNNs and the Bayesian Transformation\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea4b1b6",
   "metadata": {},
   "source": [
    "## 1.Concept: What is a Bayesian Neural Network?\n",
    "\n",
    "To understand the Bayesian transformation, we first need to understand the difference between a standard neural network and a Bayesian one.\n",
    "\n",
    "### 1.1 Standard Neural Networks\n",
    "\n",
    "In a standard neural network, each weight is a single, deterministic number. After training, these weights are fixed. \n",
    "When you pass an input through the model, it follows one exact path, producing one exact output.\n",
    "The model has no inherent way to express how \"sure\" it is about the values of its weights.\n",
    "\n",
    "### 1.2 Bayesian Neural Networks (BNNs)\n",
    "\n",
    "In a Bayesian Neural Network, we replace the deterministic weights with probability distributions.\n",
    "Instead of a weight being a single number, it might be represented by a Gaussian (normal) distribution \n",
    "with a mean and a standard deviation.\n",
    "\n",
    "- The mean represents the most likely value for that weight.\n",
    "\n",
    "- The standard deviation represents the model's uncertainty about that weight. A small standard deviation means the model\n",
    " is very confident in the weight's value, while a large one means it is very unsure.\n",
    "\n",
    "During a forward pass, we don't use the mean value directly. Instead, we sample a value for each weight from its distribution.\n",
    "Because we get a slightly different set of weights every time, each forward pass on the same input will produce a slightly different\n",
    " output. This natural variation is a direct reflection of the model's parameter uncertainty.\n",
    "\n",
    "### 1.3 The Bayesian Transformation `(probly)`\n",
    "\n",
    "The Bayesian transformation in `probly` automates the process of converting a standard network into a BNN.\n",
    "\n",
    "The transformation does the following:\n",
    "\n",
    "It walks through your PyTorch model and finds all compatible layers (e.g., nn.Linear and nn.Conv2d).\n",
    "It programmatically replaces each standard layer with a corresponding custom Bayesian layer (e.g., BayesLinear, BayesConv2d).\n",
    "These new layers contain weight distributions instead of single values and are inherently stochastic, even during inference.\n",
    "\n",
    "This allows us to get a distribution of predictions by running multiple forward passes, which we can then use to quantify the model's uncertainty.\n",
    "\n",
    "\n",
    "### 1.4. What that entails\n",
    "| Aspect                       |Bayesian Transformation `(probly)`                                                |\n",
    "|------------------------------|--------------------------------------------------------                          |\n",
    "| **Main Idea**                | \"Weights are distributions\"                                                      | \n",
    "| Stochastic Element           | Weights are sampled from probability distributions.                              | \n",
    "| Architectural Change         | Replaces `nn.Linear` and `nn.Conv2d` with `BayesLinear`/`BayesConv2d` layers.    | \n",
    "| Uncertainty Interpretation   | A principled, direct measure of the model's parameter uncertainty.               | \n",
    "|Supported Layers              | `Linear` and `Conv2d`                                                            | \n",
    "|Key Parameters                | `prior_mean`, `prior_std`, `posterior_std`                                       | "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdee989c",
   "metadata": {},
   "source": [
    "## 2. Quickstart (PyTorch)\n",
    "\n",
    "Below: build a small MLP, apply `bayesian(model)`, and inspect the modified architecture to see the layer replacement.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
