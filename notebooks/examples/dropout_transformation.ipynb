{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dc33501",
   "metadata": {},
   "source": [
    "# probly Tutorial — Dropout Transformation \n",
    "\n",
    "*Date:* 2025-11-03\n",
    "\n",
    "**Audience:** New probly users · **Framework:** PyTorch · **Author:** Nidhi Jain and Julia Goihman\n",
    "\n",
    "This notebook is meant as a gentle, practical introduction to the **Dropout transformation** in `probly`.\n",
    "The goal is not to be mathematically perfect, but to give you an intuition you can actually use when you\n",
    "work on models in PyTorch.\n",
    "\n",
    "We will slowly build up from the very basic idea of *normal* Dropout to the slightly more advanced idea of\n",
    "a **Dropout transformation that makes a model uncertainty‑aware**. After that, we look at a tiny PyTorch\n",
    "example and inspect how the transformation changes the model.
    # Part A — Introduction to Dropout and the Dropout Transformation \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e52834e",
   "metadata": {},
   "source": [
    "## 1. Concept: What is Dropout (normal) vs Dropout Transformation?\n",
    "\n",
    "The original question for this part is:\n",
    "\n",
    "> **“What is Dropout (normal) vs Dropout Transformation?”**  \n",
    "> **1.1 Normal Dropout (no probly, just PyTorch)**  \n",
    "> In “normal” deep learning, Dropout is a layer used during training to reduce overfitting.  \n",
    "> Overfitting = model memorizes training data and sucks on new data.\n",
    "\n",
    "Below is a more detailed version of that explanation, in my own words.\n",
    "\n",
    "### 1.1 Normal Dropout (standard PyTorch Dropout layer)\n",
    "\n",
    "When we train a neural network, there is always the risk of **overfitting**. That means the model becomes\n",
    "very good at the training set but fails on new data, because it has more or less *memorised* patterns that\n",
    "only appear in the training examples.\n",
    "\n",
    "**Normal Dropout** is a simple trick to make overfitting less likely. During training, a `Dropout(p)` layer\n",
    "will, for every mini‑batch, randomly set a fraction `p` of its input activations to zero. You can imagine\n",
    "this as:\n",
    "\n",
    "- with probability `p` a neuron is “switched off” for this training step,\n",
    "- with probability `1 − p` it behaves as usual.\n",
    "\n",
    "Because different neurons get switched off in every step, the network is forced to **spread the information**\n",
    "across many neurons instead of relying on a few very strong ones. This usually makes the model **more robust**\n",
    "and helps it generalise better.\n",
    "\n",
    "Important detail: in **normal PyTorch usage**\n",
    "\n",
    "- Dropout is **active only in training mode** (`model.train()`),\n",
    "- and it is **disabled in evaluation mode** (`model.eval()`).\n",
    "\n",
    "So at test / inference time, the model behaves like a **deterministic function**: the same input always gives\n",
    "the same output, and there is no randomness from Dropout anymore. The purpose of normal Dropout is therefore\n",
    "*only* to improve generalisation during training, not to provide uncertainty information.\n",
    "\n",
    "### 1.2 Dropout Transformation (probly)\n",
    "\n",
    "The **Dropout transformation** in `probly` takes this Dropout idea and uses it in a slightly different role.\n",
    "Instead of treating Dropout purely as a regularisation trick during training, we use it to make the model\n",
    "**uncertainty‑aware** at prediction time.\n",
    "\n",
    "Roughly speaking, the transformation does the following:\n",
    "\n",
    "- It walks through your PyTorch model and finds the relevant linear layers.\n",
    "- It programmatically inserts Dropout layers around those linear layers.\n",
    "- Crucially, these Dropout layers stay **active during inference**, so each forward pass is a bit different.\n",
    "\n",
    "If we now feed the **same input** through the transformed model multiple times, we do **not** get exactly the\n",
    "same output each time. Instead we get a *cloud* of slightly different predictions. From this cloud we can:\n",
    "\n",
    "- compute a mean prediction (what the model “on average” thinks), and\n",
    "- look at how much the predictions vary (this variation is a proxy for **uncertainty**).\n",
    "\n",
    "So the Dropout transformation reuses the usual Dropout mechanism, but with a **different goal**:\n",
    "\n",
    "- normal Dropout: better training, less overfitting, Dropout OFF in eval mode;\n",
    "- Dropout transformation: keep Dropout ON in eval mode to get a distribution of outputs and estimate how\n",
    "  confident the model is.\n",
    "\n",
    "### 1.3 Short side‑by‑side comparison\n",
    "\n",
    "| Aspect                        | Normal Dropout (PyTorch)                               | Dropout Transformation (probly)                          |\n",
    "|------------------------------|--------------------------------------------------------|----------------------------------------------------------|\n",
    "| Where it appears in code     | You explicitly add `nn.Dropout` layers                 | Transformation walks the model and inserts Dropout       |\n",
    "| When Dropout is active       | Only in `model.train()`                                | Also (and intentionally) in `model.eval()`               |\n",
    "| Main purpose                 | Reduce overfitting / improve generalisation            | Make predictions uncertainty‑aware                       |\n",
    "| Output behaviour in eval     | Deterministic (same input → same output)               | Stochastic (same input → slightly different outputs)     |\n",
    "| How we use the randomness    | We ignore it at inference                              | We *use* it to measure spread / uncertainty              |\n",
    "\n",
    "The rest of this notebook now assumes this picture: **“normal” Dropout is a training regulariser, the\n",
    "Dropout transformation turns the same mechanism into a tool for estimating uncertainty.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac982de7",
   "metadata": {},
   "source": [
    "## 2. Quickstart (PyTorch)\n",
    "\n",
    "Below: build a small MLP, apply `dropout(model, p)`, and inspect the modified architecture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50def69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're running inside the repo's environment, these imports should work directly.\n",
    "from probly.transformation import dropout\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def build_mlp(in_dim=10, hidden=32, out_dim=1):\n",
    "    # A sequential model that ends on a Linear\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_dim, hidden),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden, hidden),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden, out_dim),\n",
    "    )\n",
    "\n",
    "p = 0.2  # dropout probability\n",
    "\n",
    "model = build_mlp()\n",
    "print(\"Original model:\\n\", model)\n",
    "\n",
    "model_do = dropout(model, p)\n",
    "print(\"\\nWith Dropout transformation (p=%.2f):\\n\" % p, model_do)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e37850",
   "metadata": {},
   "source": [
    "### Notes on the structure\n",
    "- Expect a Dropout layer **before** each intermediate `nn.Linear`.\n",
    "- If the last layer is a linear output head, the transform usually **does not** add a Dropout layer in front of it, preserving your final mapping.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a5c9b8",
   "metadata": {},
   "source": [
    "## 3. Uncertainty via Monte Carlo (MC) Dropout\n",
    "\n",
    "To obtain predictive *uncertainty*, we run multiple stochastic forward passes with Dropout **active** and compute the mean and variance of predictions.\n",
    "\n",
    "> **Important:** In PyTorch, Dropout is active in `model.train()` mode. For MC Dropout at inference, we intentionally call `train()` while disabling gradients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395d616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import math\n",
    "\n",
    "# Toy regression data\n",
    "torch.manual_seed(0)\n",
    "n = 128\n",
    "X = torch.randn(n, 10)\n",
    "true_w = torch.randn(10, 1)\n",
    "y = X @ true_w + 0.1 * torch.randn(n, 1)\n",
    "\n",
    "# (Re)build and transform the model\n",
    "model = build_mlp(in_dim=10, hidden=64, out_dim=1)\n",
    "model_do = dropout(model, p=0.2)\n",
    "\n",
    "# Simple training loop (few steps just for illustration)\n",
    "opt = torch.optim.Adam(model_do.parameters(), lr=1e-2)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "model_do.train()\n",
    "for step in range(200):\n",
    "    opt.zero_grad()\n",
    "    pred = model_do(X)\n",
    "    loss = loss_fn(pred, y)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "# MC dropout prediction function\n",
    "@torch.no_grad()\n",
    "def mc_predict(model_with_dropout, inputs, T=50):\n",
    "    model_with_dropout.train()  # activate dropout\n",
    "    preds = []\n",
    "    for _ in range(T):\n",
    "        preds.append(model_with_dropout(inputs).detach())\n",
    "    stacked = torch.stack(preds, dim=0)  # [T, N, out_dim]\n",
    "    mean = stacked.mean(dim=0)\n",
    "    var = stacked.var(dim=0, unbiased=False)\n",
    "    return mean, var\n",
    "\n",
    "mean_pred, var_pred = mc_predict(model_do, X[:5], T=100)\n",
    "print(\"Predictive mean (first 5):\\n\", mean_pred.squeeze())\n",
    "print(\"\\nPredictive variance (first 5):\\n\", var_pred.squeeze())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fea5a0",
   "metadata": {},
   "source": [
    "## 4. Good practices\n",
    "- Tune `p` (e.g., 0.1–0.5) based on validation performance.\n",
    "- Use a reasonable number of MC samples `T` (e.g., 20–200). Larger `T` → smoother uncertainty estimates, but slower.\n",
    "- Keep your **final layer behavior** in mind when interpreting where Dropout is inserted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7720ab12",
   "metadata": {},
   "source": [
    "## 5. Common errors\n",
    "- `ValueError: p must be between 0 and 1` — ensure `0 ≤ p ≤ 1`.\n",
    "- Seeing no Dropout layers? Confirm your model actually contains `nn.Linear` modules where you expect them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cad33a",
   "metadata": {},
   "source": [
    "## 6. Next steps\n",
    "- Try other architectures (e.g., with Conv blocks feeding into Linear heads).\n",
    "- Compare models **with vs. without** the transformation using the same training loop.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "divider_part_b",
   "source": [
    "---\n",
    "\n",
    "# Part B — Applied MC-Dropout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# probly Tutorial — Dropout Transformation (Part B)\n",
    "\n",
    "*Date:* 2025-11-03  \n",
    "**Audience:** New probly users · **Framework:** PyTorch · **Author:** Nidhi Jain and Julia Goihman  \n",
    "\n",
    "In **Part A**, we learned what the **Dropout transformation** in `probly` does and how it modifies a model’s structure.  \n",
    "In this **Part B**, we will *apply* that transformation to make a model uncertainty-aware, run several stochastic predictions, and visualize the variability in outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67b4a59",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# Part B\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## 1. Setup and base model\n",
    "\n",
    "We start from the same idea as before — a small fully-connected network — but this time we will focus on the *inference behaviour* under MC-Dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from probly.transformation import dropout\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "class TinyNet(nn.Module):\n",
    "    def __init__(self, p: float = 0.3):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(16, 32)\n",
    "        self.do1 = nn.Dropout(p)\n",
    "        self.fc2 = nn.Linear(32, 8)\n",
    "        self.do2 = nn.Dropout(p)\n",
    "        self.out = nn.Linear(8, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.do1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.do2(x)\n",
    "        return self.out(x)\n",
    "\n",
    "# dummy input\n",
    "x = torch.randn(1, 16)\n",
    "base_model = TinyNet(p=0.3).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apply_dropout",
   "metadata": {},
   "source": [
    "## 2. Apply the Dropout transformation\n",
    "\n",
    "We now transform the base model with `dropout()` so that Dropout stays *active* during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apply_dropout_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model = dropout(base_model, enable_at_eval=True)\n",
    "mc_model.eval()  # MC-Dropout active even in eval mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mc_passes",
   "metadata": {},
   "source": [
    "## 3. Monte-Carlo inference: repeated forward passes\n",
    "\n",
    "We feed the same input through the model multiple times and collect the stochastic outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mc_passes_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_passes = 100\n",
    "logits_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in range(num_passes):\n",
    "        logits_list.append(mc_model(x))\n",
    "\n",
    "logits = torch.cat(logits_list, dim=0)   # [num_passes, 3]\n",
    "probs  = torch.softmax(logits, dim=-1)   # convert to probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantify",
   "metadata": {},
   "source": [
    "## 4. Quantify uncertainty\n",
    "\n",
    "Compute the mean and standard deviation across all passes — these capture the central tendency and spread (uncertainty)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantify_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_probs = probs.mean(dim=0)\n",
    "std_probs  = probs.std(dim=0, unbiased=False)\n",
    "\n",
    "pred_class = mean_probs.argmax().item()\n",
    "predictive_entropy = -(mean_probs * (mean_probs.clamp_min(1e-12).log())).sum().item()\n",
    "\n",
    "print(\"Mean probabilities:\", mean_probs)\n",
    "print(\"Std probabilities:\", std_probs)\n",
    "print(\"Predicted class:\", pred_class)\n",
    "print(\"Predictive entropy:\", predictive_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization",
   "metadata": {},
   "source": [
    "## 5. Visualization – Inspecting uncertainty distributions\n",
    "\n",
    "We visualize how much the predicted probabilities fluctuate across Monte-Carlo runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "histogram",
   "metadata": {},
   "outputs": [],
   "source": [
    "winning_class = int(mean_probs.argmax().item())\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(probs[:, winning_class].numpy(), bins=20, color=\"skyblue\", edgecolor=\"black\")\n",
    "plt.title(f\"Distribution of predicted probability – class {winning_class}\")\n",
    "plt.xlabel(\"Predicted probability\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "histogram_note",
   "metadata": {},
   "source": [
    "> **Interpretation:**  \n",
    "> – Narrow peak near 1.0 → model confident  \n",
    "> – Wide or multimodal distribution → model uncertain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "barplot",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = mean_probs.shape[0]\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(np.arange(C), mean_probs.numpy(), yerr=std_probs.numpy(), capsize=5, color=\"lightcoral\")\n",
    "plt.xticks(np.arange(C), [f\"Class {i}\" for i in range(C)])\n",
    "plt.ylabel(\"Predicted probability\")\n",
    "plt.title(\"Mean ± Std of predicted probabilities per class\")\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "barplot_note",
   "metadata": {},
   "source": [
    "> **Interpretation:**  \n",
    "> – Taller bars → more probable classes  \n",
    "> – Longer error bars → higher uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional",
   "metadata": {},
   "source": [
    "## 6. Optional: turn MC-Dropout off (deterministic check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_mc = dropout(base_model, enable_at_eval=False)\n",
    "no_mc.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    y1, y2 = no_mc(x), no_mc(x)\n",
    "print(\"Deterministic without MC-Dropout:\", torch.allclose(y1, y2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "In **Part B**, we applied the `dropout()` transformation from `probly` to make a PyTorch model uncertainty-aware.  \n",
    "By running multiple stochastic forward passes on the same input, we observed small variations in the output.  \n",
    "This variability represents **model uncertainty**, because dropout remains active during inference.  \n",
    "We then computed the **mean**, **standard deviation**, and **predictive entropy** of the outputs, and visualized them using histograms and error-bar plots to understand how confident the model was in its predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
