{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8e47f87",
   "metadata": {},
   "source": [
    "# Multi-Loss Sub-Ensemble Example\n",
    "\n",
    "In this notebook we explore **Sub-Ensemble** methods for uncertainty estimation, focusing on\n",
    "a **Multi-Loss Sub-Ensemble** architecture inspired by:\n",
    "\n",
    "> \"Multi-Loss Sub-Ensembles for Accurate Classification with Uncertainty Estimation\"\n",
    "> (Achrack et al., 2020, arXiv:2010.01917)\n",
    "\n",
    "Instead of training many independent models as a full ensemble, we:\n",
    "\n",
    "- use a **shared backbone** (trunk) to extract features, and\n",
    "- attach several **classifier heads** (sub-ensembles) on top of the trunk.\n",
    "\n",
    "Each head is trained with a **different loss function**, which introduces diversity between\n",
    "the heads while keeping training in a single phase and with a single backbone.\n",
    "\n",
    "The goals of this notebook are:\n",
    "\n",
    "- to explain the idea of Sub-Ensembles and how Multi-Loss Sub-Ensembles extend them,\n",
    "- to implement a simple shared-trunk + multi-head architecture on CIFAR-10 in PyTorch,\n",
    "- to train different heads with different losses,\n",
    "- and to show how to obtain **accuracy** and **uncertainty** estimates from the disagreement\n",
    "  between heads.\n",
    "\n",
    "This notebook is structured as follows:\n",
    "\n",
    "1. Imports & Setup  \n",
    "2. Full Ensembles vs. Sub-Ensembles  \n",
    "3. Multi-Loss Sub-Ensembles  \n",
    "4. Data Preparation  \n",
    "5. Model Definition (shared trunk + multiple heads)  \n",
    "6. Multi-Loss Sub-Ensemble Training Function  \n",
    "7. Short-run Experiment on CIFAR-10  \n",
    "8. Evaluation: Predictions & Uncertainty  \n",
    "9. Conclusion and connection to `probly`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41308c47",
   "metadata": {},
   "source": [
    "## 1. Imports & Setup\n",
    "\n",
    "We first import the required libraries:\n",
    "\n",
    "- **torch, torchvision**: core tools for neural networks and datasets,\n",
    "- **CIFAR-10**: small image classification dataset,\n",
    "- standard utilities for data loading and device selection.\n",
    "\n",
    "Later, the same ideas can be integrated into the `probly` package and wrapped by a\n",
    "SubEnsemble utility function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec6b4b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b641975",
   "metadata": {},
   "source": [
    "## 2. Full Ensembles vs. Sub-Ensembles\n",
    "\n",
    "### 2.1 Full ensembles\n",
    "\n",
    "A **full ensemble** consists of several independent models:\n",
    "\n",
    "- each model has its own parameters and random initialisation,\n",
    "- all models are trained separately on the same (or slightly resampled) dataset,\n",
    "- at test time, their predictions are averaged (or combined in some other way).\n",
    "\n",
    "Formally, for an input $x$ and $M$ models $f_m$, we obtain predictions\n",
    "$\\hat{y}_m = f_m(x)$ and aggregate them as\n",
    "\n",
    "$$\n",
    "\\hat{y}_{\\text{ens}}(x) = \\frac{1}{M} \\sum_{m=1}^M \\hat{y}_m.\n",
    "$$\n",
    "\n",
    "Full ensembles are strong baselines for both **accuracy** and **uncertainty**, but they are:\n",
    "\n",
    "- computationally expensive (M separate models),\n",
    "- memory-intensive (M copies of all weights),\n",
    "- and sometimes hard to deploy in practice.\n",
    "\n",
    "### 2.2 Sub-Ensembles\n",
    "\n",
    "**Sub-Ensembles** aim to reduce this cost by sharing a large part of the model:\n",
    "\n",
    "- a single **trunk** processes the input and produces a feature representation,\n",
    "- multiple **heads** (sub-ensembles) take the same features and output predictions,\n",
    "- at test time, the heads are treated as ensemble members and their outputs are aggregated.\n",
    "\n",
    "This keeps many of the benefits of ensembles:\n",
    "\n",
    "- diversity between heads,\n",
    "- the ability to measure disagreement,\n",
    "- and simple averaging for predictions,\n",
    "\n",
    "while requiring only **one backbone** to be stored and operated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c4a86d",
   "metadata": {},
   "source": [
    "## 3. Multi-Loss Sub-Ensembles\n",
    "\n",
    "A **Multi-Loss Sub-Ensemble** keeps the shared trunk + multi-head structure, but introduces\n",
    "an additional source of diversity:\n",
    "\n",
    "> each head is trained with a **different loss function**.\n",
    "\n",
    "Intuitively:\n",
    "\n",
    "- a standard Sub-Ensemble uses the same training objective for all heads,\n",
    "- a Multi-Loss Sub-Ensemble lets each head see the same data through a different loss.\n",
    "\n",
    "In this notebook we combine:\n",
    "\n",
    "- a head trained with standard cross-entropy,\n",
    "- a head trained with label-smoothed cross-entropy,\n",
    "- a head trained with a simple margin-based loss that enforces a gap between the correct\n",
    "  class and the most likely wrong class.\n",
    "\n",
    "Even though all heads share the same backbone, the different losses encourage:\n",
    "\n",
    "- slightly different decision boundaries,\n",
    "- different confidence behaviours,\n",
    "- and therefore more informative disagreement patterns between heads.\n",
    "\n",
    "We will now implement this setting with a small CNN trunk and three heads.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0e388d",
   "metadata": {},
   "source": [
    "## 4. Data Preparation\n",
    "\n",
    "We use CIFAR-10 as a small image classification benchmark:\n",
    "\n",
    "- 50,000 training images and 10,000 test images,\n",
    "- 10 classes,\n",
    "- RGB images of size 32x32.\n",
    "\n",
    "We apply:\n",
    "\n",
    "- conversion to tensors,\n",
    "- simple normalisation of pixel values,\n",
    "- `DataLoader` wrappers for batching and shuffling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb71521e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 50000,  Val samples: 10000\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ],\n",
    ")\n",
    "\n",
    "train_data = CIFAR10(root=\"./data\", train=True, transform=transform, download=True)\n",
    "val_data = CIFAR10(root=\"./data\", train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_data, batch_size=256, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Train samples: {len(train_data)},  Val samples: {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c091f120",
   "metadata": {},
   "source": [
    "## 5. Model Definition: shared trunk + multiple heads\n",
    "\n",
    "We now define a small CNN with:\n",
    "\n",
    "- one **shared trunk** that extracts features from the input image, and\n",
    "- several **classifier heads** (sub-ensembles), each producing logits for the 10 classes.\n",
    "\n",
    "During training, each head will be paired with a different loss function.\n",
    "At inference time, all heads are treated as ensemble members and their\n",
    "predictions are aggregated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6de693df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubEnsembleNet(\n",
      "  (trunk): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (heads): ModuleList(\n",
      "    (0-2): 3 x Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class SubEnsembleNet(nn.Module):\n",
    "    def __init__(self, num_classes: int = 10, num_heads: int = 3) -> None:\n",
    "        \"\"\"Initialize the shared-trunk multi-head classifier.\"\"\"\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        # shared trunk\n",
    "        self.trunk = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # 16x16\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # 8x8\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        trunk_out_dim = 64 * 8 * 8\n",
    "\n",
    "        # multiple classifier heads\n",
    "        self.heads = nn.ModuleList(\n",
    "            [nn.Linear(trunk_out_dim, num_classes) for _ in range(num_heads)],\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> list[torch.Tensor]:\n",
    "        \"\"\"Compute logits for each head.\"\"\"\n",
    "        feat = self.trunk(x)\n",
    "        logits_per_head = [head(feat) for head in self.heads]\n",
    "        return logits_per_head\n",
    "\n",
    "\n",
    "num_heads = 3\n",
    "model = SubEnsembleNet(num_classes=10, num_heads=num_heads).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d784e05",
   "metadata": {},
   "source": [
    "## 6. Multi-Loss Sub-Ensemble Training Function\n",
    "\n",
    "We now define:\n",
    "\n",
    "1. a small set of loss functions:\n",
    "   - standard cross-entropy,\n",
    "   - label-smoothed cross-entropy,\n",
    "   - a margin-based loss that enforces a gap between the correct and the most likely\n",
    "     incorrect logit;\n",
    "\n",
    "2. a unified training routine:\n",
    "\n",
    "   `train_multi_loss_sub_ensemble(model, dataloader, losses, ...)`\n",
    "\n",
    "The training function:\n",
    "\n",
    "- moves the model to the chosen device,\n",
    "- iterates over epochs and batches,\n",
    "- computes logits for each head,\n",
    "- applies a different loss to each head,\n",
    "- sums the per-head losses into a single scalar,\n",
    "- performs backpropagation and optimisation.\n",
    "\n",
    "This mimics how a future SubEnsemble training utility in `probly` could look like.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6f08d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    \"\"\"Small implementation of label-smoothed cross-entropy.\"\"\"\n",
    "\n",
    "    def __init__(self, smoothing: float = 0.1) -> None:\n",
    "        \"\"\"Initialize the loss with a smoothing factor.\"\"\"\n",
    "        super().__init__()\n",
    "        self.smoothing = smoothing\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        logits: torch.Tensor,\n",
    "        target: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Compute the smoothed cross-entropy loss.\"\"\"\n",
    "        num_classes = logits.size(-1)\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(logits)\n",
    "            true_dist.fill_(self.smoothing / (num_classes - 1))\n",
    "            true_dist.scatter_(1, target.unsqueeze(1), 1.0 - self.smoothing)\n",
    "\n",
    "        loss = torch.sum(-true_dist * log_probs, dim=-1)\n",
    "        return loss.mean()\n",
    "\n",
    "\n",
    "class MarginLoss(nn.Module):\n",
    "    \"\"\"Encourage margin between correct logit and max wrong logit.\"\"\"\n",
    "\n",
    "    def __init__(self, margin: float = 0.5) -> None:\n",
    "        \"\"\"Initialize the margin loss with a target margin.\"\"\"\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        logits: torch.Tensor,\n",
    "        target: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Compute the margin-based loss.\"\"\"\n",
    "        num_classes = logits.size(-1)\n",
    "        one_hot = F.one_hot(target, num_classes=num_classes).bool()\n",
    "\n",
    "        correct_logit = logits[one_hot].view(-1)\n",
    "        wrong_logits = logits.masked_fill(one_hot, float(\"-inf\"))\n",
    "        max_wrong_logit, _ = wrong_logits.max(dim=-1)\n",
    "\n",
    "        margin_term = correct_logit - max_wrong_logit\n",
    "        loss = F.relu(self.margin - margin_term)\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21dacc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multi_loss_sub_ensemble(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    losses: list[nn.Module],\n",
    "    epochs: int = 5,\n",
    "    lr: float = 1e-3,\n",
    "    device: str = \"cuda\",\n",
    ") -> None:\n",
    "    \"\"\"Demonstration of a multi-loss sub-ensemble training function.\"\"\"\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    if len(losses) != model.num_heads:\n",
    "        msg = f\"Need one loss per head, got {len(losses)} losses for {model.num_heads} heads.\"\n",
    "        raise ValueError(msg)\n",
    "    losses = [ls.to(device) for ls in losses]\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        num_batches = 0\n",
    "\n",
    "        for batch_inputs, batch_targets in dataloader:\n",
    "            inputs = batch_inputs.to(device)\n",
    "            targets = batch_targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logits_per_head = model(inputs)\n",
    "\n",
    "            batch_loss = 0.0\n",
    "            for head_logits, loss_fn in zip(logits_per_head, losses, strict=False):\n",
    "                batch_loss = batch_loss + loss_fn(head_logits, targets)\n",
    "\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += batch_loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "        avg_loss = total_loss / max(1, num_batches)\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}] - Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76f5e76",
   "metadata": {},
   "source": [
    "## 7. Short-run experiment on CIFAR-10\n",
    "\n",
    "To keep the runtime manageable, we perform a **short-run** experiment on CIFAR-10:\n",
    "\n",
    "- Dataset: CIFAR-10 (50k train, 10k test)\n",
    "- Model: small CNN trunk with 3 classifier heads\n",
    "- Heads / losses:\n",
    "  - Head 1: standard cross-entropy\n",
    "  - Head 2: label-smoothed cross-entropy\n",
    "  - Head 3: margin-based loss\n",
    "- Training: a few epochs with Adam\n",
    "- Evaluation: accuracy and simple uncertainty metrics on the validation set\n",
    "\n",
    "This is not meant to be a state-of-the-art benchmark.  \n",
    "The goal is to clearly illustrate how a Multi-Loss Sub-Ensemble can be trained and how\n",
    "head disagreement can be turned into uncertainty estimates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "093413ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2] - Loss: 3.6320\n",
      "Epoch [2/2] - Loss: 2.8901\n"
     ]
    }
   ],
   "source": [
    "num_heads = 3\n",
    "base_model = SubEnsembleNet(num_classes=10, num_heads=num_heads)\n",
    "\n",
    "loss_list: list[nn.Module] = [\n",
    "    nn.CrossEntropyLoss(),\n",
    "    LabelSmoothingCrossEntropy(smoothing=0.1),\n",
    "    MarginLoss(margin=0.5),\n",
    "]\n",
    "\n",
    "train_multi_loss_sub_ensemble(\n",
    "    model=base_model,\n",
    "    dataloader=train_loader,\n",
    "    losses=loss_list,\n",
    "    epochs=2,  # keep small for a quick demo\n",
    "    lr=1e-3,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4817573",
   "metadata": {},
   "source": [
    "## 8. Evaluation: accuracy and uncertainty\n",
    "\n",
    "After training, we treat each head as an ensemble member:\n",
    "\n",
    "1. For each input, we collect the softmax probabilities from all heads.\n",
    "2. We compute the **mean prediction** by averaging probabilities over heads.\n",
    "3. From this, we derive:\n",
    "\n",
    "   - the **ensemble accuracy** (argmax of the mean prediction),\n",
    "   - the **predictive entropy** of the mean prediction,\n",
    "   - the **variance** of the predicted probability of the chosen class across heads.\n",
    "\n",
    "The entropy and variance are simple but useful uncertainty indicators:\n",
    "\n",
    "- high entropy / variance → heads disagree or are unsure,  \n",
    "- low entropy / variance → heads agree and are confident.\n",
    "\n",
    "In practice, misclassified samples tend to have higher uncertainty scores than correctly\n",
    "classified ones, which can be exploited for tasks such as rejection, out-of-distribution\n",
    "detection, or risk-aware decision making.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6888ef8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_with_uncertainty(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    device: str = \"cuda\",\n",
    ") -> dict[str, torch.Tensor]:\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    all_mean_probs = []\n",
    "    all_targets = []\n",
    "    all_entropies = []\n",
    "    all_var_maxclass = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_inputs, batch_targets in dataloader:\n",
    "            inputs = batch_inputs.to(device)\n",
    "            targets = batch_targets.to(device)\n",
    "\n",
    "            logits_per_head = model(inputs)\n",
    "            probs_per_head = [F.softmax(logits, dim=-1) for logits in logits_per_head]\n",
    "\n",
    "            # stack along head axis: (heads, batch, classes)\n",
    "            probs_stack = torch.stack(probs_per_head, dim=0)\n",
    "\n",
    "            mean_probs = probs_stack.mean(dim=0)  # (batch, classes)\n",
    "            all_mean_probs.append(mean_probs.cpu())\n",
    "            all_targets.append(targets.cpu())\n",
    "\n",
    "            # predictive entropy of mean prediction\n",
    "            entropy = -torch.sum(mean_probs * torch.log(mean_probs + 1e-8), dim=-1)\n",
    "\n",
    "            # variance of probability of the predicted class across heads\n",
    "            preds = mean_probs.argmax(dim=-1)  # (batch,)\n",
    "            head_probs_max = []\n",
    "            for probs in probs_per_head:\n",
    "                head_probs_max.append(\n",
    "                    probs[torch.arange(probs.size(0), device=probs.device), preds],\n",
    "                )\n",
    "            head_probs_max = torch.stack(head_probs_max, dim=0)  # (heads, batch)\n",
    "            var_max = head_probs_max.var(dim=0)\n",
    "\n",
    "            all_entropies.append(entropy.cpu())\n",
    "            all_var_maxclass.append(var_max.cpu())\n",
    "\n",
    "    mean_probs = torch.cat(all_mean_probs, dim=0)\n",
    "    targets = torch.cat(all_targets, dim=0)\n",
    "    entropies = torch.cat(all_entropies, dim=0)\n",
    "    var_maxclass = torch.cat(all_var_maxclass, dim=0)\n",
    "\n",
    "    preds = mean_probs.argmax(dim=-1)\n",
    "    acc = (preds == targets).float().mean().item()\n",
    "\n",
    "    print(f\"Validation accuracy (ensemble): {acc:.4f}\")\n",
    "    print(f\"Entropy: mean={entropies.mean():.4f}, std={entropies.std():.4f}\")\n",
    "    print(f\"Var(max-class prob): mean={var_maxclass.mean():.4f}, std={var_maxclass.std():.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"mean_probs\": mean_probs,\n",
    "        \"targets\": targets,\n",
    "        \"entropy\": entropies,\n",
    "        \"var_maxclass\": var_maxclass,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cbee59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy (ensemble): 0.6522\n",
      "Entropy: mean=1.6486, std=0.3376\n",
      "Var(max-class prob): mean=0.0445, std=0.0324\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluate_with_uncertainty(base_model, val_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3fa47083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct samples: 6522\n",
      "Wrong samples   : 3478\n",
      "Entropy  - correct: 1.5505, wrong: 1.8325\n",
      "Var(max) - correct: 0.0544, wrong: 0.0260\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "probs = metrics[\"mean_probs\"]  # (N, num_classes)\n",
    "targets = metrics[\"targets\"]  # (N,)\n",
    "entropy = metrics[\"entropy\"]  # (N,)\n",
    "var_max = metrics[\"var_maxclass\"]  # (N,)\n",
    "\n",
    "# boolean mask for correct / wrong predictions\n",
    "preds = probs.argmax(dim=-1)\n",
    "correct_mask = preds == targets\n",
    "wrong_mask = ~correct_mask\n",
    "\n",
    "# compute mean uncertainty for each group\n",
    "mean_ent_correct = entropy[correct_mask].mean().item()\n",
    "mean_ent_wrong = entropy[wrong_mask].mean().item()\n",
    "\n",
    "mean_var_correct = var_max[correct_mask].mean().item()\n",
    "mean_var_wrong = var_max[wrong_mask].mean().item()\n",
    "\n",
    "print(\"Correct samples:\", int(correct_mask.sum()))\n",
    "print(\"Wrong samples   :\", int(wrong_mask.sum()))\n",
    "print(f\"Entropy  - correct: {mean_ent_correct:.4f}, wrong: {mean_ent_wrong:.4f}\")\n",
    "print(f\"Var(max) - correct: {mean_var_correct:.4f}, wrong: {mean_var_wrong:.4f}\")\n",
    "\n",
    "# --- bar plots ---\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 3))\n",
    "\n",
    "# entropy\n",
    "axes[0].bar([\"correct\", \"wrong\"], [mean_ent_correct, mean_ent_wrong])\n",
    "axes[0].set_title(\"Mean predictive entropy\")\n",
    "axes[0].set_ylabel(\"entropy\")\n",
    "\n",
    "# variance of max-class prob\n",
    "axes[1].bar([\"correct\", \"wrong\"], [mean_var_correct, mean_var_wrong])\n",
    "axes[1].set_title(\"Mean var of max-class prob\")\n",
    "axes[1].set_ylabel(\"variance\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41de76b",
   "metadata": {},
   "source": [
    "We see that both entropy and the variance of the max-class probability are higher on misclassified samples than on correctly classified ones, which indicates that the Multi-Loss Sub-Ensemble provides meaningful uncertainty estimates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6fb5f0",
   "metadata": {},
   "source": [
    "## 9. Conclusion and connection to `probly`\n",
    "\n",
    "In this notebook we:\n",
    "\n",
    "- reviewed the idea of full ensembles and their computational cost,\n",
    "- introduced Sub-Ensembles with a shared backbone and multiple heads,\n",
    "- extended this to Multi-Loss Sub-Ensembles, where each head uses a different loss,\n",
    "- implemented a simple CNN-based Multi-Loss Sub-Ensemble on CIFAR-10,\n",
    "- and demonstrated how to extract accuracy and basic uncertainty metrics from the ensemble.\n",
    "\n",
    "From the perspective of `probly`, Multi-Loss Sub-Ensembles are a natural example of\n",
    "an **extended ensemble structure**:\n",
    "\n",
    "- the ensemble axis is realised by multiple heads,\n",
    "- parameters are partially shared (backbone) and partially head-specific,\n",
    "- each head can be associated with its own loss and possibly its own training settings.\n",
    "\n",
    "Future work in `probly` could expose this pattern via a dedicated SubEnsemble\n",
    "transformation, similar to existing ensemble utilities, so that:\n",
    "\n",
    "- users can quickly wrap an existing backbone into a Multi-Loss Sub-Ensemble,\n",
    "- and obtain uncertainty estimates without writing the full multi-head training loop\n",
    "  themselves.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "probly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
