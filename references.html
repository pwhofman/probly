<!doctype html>
<html class="no-js" lang="en" data-content_root="./">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="genindex.html" /><link rel="search" title="Search" href="search.html" /><link rel="next" title="FAQ and Troubleshooting" href="faq.html" /><link rel="prev" title="Contributing to probly üèîÔ∏è" href="contributing.html" />

    <!-- Generated with Sphinx 8.2.3 and Furo 2024.08.06 -->
        <title>References and Further Reading - probly 0.3.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo.css?v=354aac6f" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo-extensions.css?v=302659d7" />
    <link rel="stylesheet" type="text/css" href="_static/css/custom.css?v=201d0c9a" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #272822;
  --color-code-foreground: #f8f8f2;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #272822;
  --color-code-foreground: #f8f8f2;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="index.html"><div class="brand">probly 0.3.1 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><div class="sidebar-scroll"><a class="sidebar-brand" href="index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo only-light" src="_static/logo/logo_light.png" alt="Light Logo"/>
    <img class="sidebar-logo only-dark" src="_static/logo/logo_dark.png" alt="Dark Logo"/>
  </div>
  
  
</a><form class="sidebar-search-container" method="get" action="search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Content</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">The <code class="docutils literal notranslate"><span class="pre">probly</span></code> Python Package</a></li>
<li class="toctree-l1"><a class="reference internal" href="core_concepts.html">Core Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="main_components.html">Main Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="advanced_topics.html">Advanced Topics</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples_and_tutorials.html">Examples and Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="methods.html">Implemented methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing to probly üèîÔ∏è</a></li>
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">References and Further Reading</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ and Troubleshooting</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Notebooks</span></p>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="notebooks/examples/index.html">Notebook Examples</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Notebook Examples</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="notebooks/examples/utilities_and_layers/index.html">Utilities and Layers</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of Utilities and Layers</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="notebooks/examples/utilities_and_layers/custom_loss_functions.html">Custom Loss Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="notebooks/examples/utilities_and_layers/metrics.html">Evaluation Metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="notebooks/examples/utilities_and_layers/probabilistic_layers.html">Key Probabilistic Layers in <code class="docutils literal notranslate"><span class="pre">probly</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="notebooks/examples/utilities_and_layers/utility_functions.html">Utility Functions</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="notebooks/examples/evaluation_and_quantification/index.html">Evaluation and Quantification</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of Evaluation and Quantification</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="notebooks/examples/evaluation_and_quantification/calibration_metrics.html">Calibration Metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="notebooks/examples/evaluation_and_quantification/interpretation_techniques.html">Interpretation techniques</a></li>
<li class="toctree-l3"><a class="reference internal" href="notebooks/examples/evaluation_and_quantification/visualization_tools.html">Visualisation Tools</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/examples/bayesian_transformation.html">Bayesian Transformation</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/examples/dropconnect_transformation.html">Dropconnect Transformation</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/examples/dropout_transformation.html">Dropout Transformation</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/examples/ensemble_transformation.html">Ensemble Transformation</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/examples/evidential_classification_transformation.html">Evidential Classification Transformation</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/examples/evidential_regression_transformation.html">Evidential Regression Transformation</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/examples/fashionmnist_ood_ensemble.html">Out-of-Distribution Detection with an Ensemble</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/examples/label_relaxation_calibration.html">Calibration with Label Relaxation</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/examples/lazy_dispatch_test.html">Lazy Dispatch Test</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/examples/multilib_demo.html">Multilib Demo</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/examples/pytraverse_tutorial.html">A Brief Introduction to PyTraverse</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/examples/sklearn_selective_prediction.html">Using probly with scikit-learn</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/examples/temperature_scaling_calibration.html">Calibration using Temperature Scaling</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/examples/train_bnn_classification.html">Bayesian Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/examples/train_evidential_classification.html">Evidential Model for Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/examples/train_evidential_regression.html">Evidential Regression Model</a></li>
</ul>
</li>
</ul>

</div>
</div><div style="text-align: center; margin-top: 1rem; margin-bottom: 1rem;">
  <a href="https://github.com/pwhofman/probly" target="_blank" rel="noopener noreferrer" title="GitHub Repository">
    <img src="_static/github-mark.svg" alt="GitHub Logo" width="28" height="28" style="display: inline-block;">
  </a>
</div>
      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          

<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="references-and-further-reading">
<span id="references"></span><h1>References and Further Reading<a class="headerlink" href="#references-and-further-reading" title="Link to this heading">¬∂</a></h1>
<p>This section provides the theoretical background for the models implemented in <code class="docutils literal notranslate"><span class="pre">probly</span></code> as well as references to relevant literature and acknowledgments.</p>
<section id="related-research-papers">
<h2>Related Research Papers<a class="headerlink" href="#related-research-papers" title="Link to this heading">¬∂</a></h2>
<p>The core functionality of this package is built upon the following foundational research papers. We recommend reading the papers to gain a deeper understanding of the algorithms and methodologies used:</p>
<div class="docutils container" id="id1">
<div role="list" class="citation-list">
<div class="citation" id="id69" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Abd21<span class="fn-bracket">]</span></span>
<p>Moloud et¬†al. Abdar. A review of uncertainty quantification in deep learning. <em>Information Fusion</em>, 2021.</p>
</div>
<div class="citation" id="id11" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>AbellanKM06<span class="fn-bracket">]</span></span>
<p>Joaqu\'ƒ±n Abell√°n, George¬†J. Klir, and Seraf\'ƒ±n Moral. Disaggregated total uncertainty measure for credal sets. <em>Int. J. Gen. Syst.</em>, 35(1):29‚Äì44, 2006. URL: <a class="reference external" href="https://doi.org/10.1080/03081070500473490">https://doi.org/10.1080/03081070500473490</a>, <a class="reference external" href="https://doi.org/10.1080/03081070500473490">doi:10.1080/03081070500473490</a>.</p>
</div>
<div class="citation" id="id12" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>AbellanM00<span class="fn-bracket">]</span></span>
<p>Joaqu\'ƒ±n Abell√°n and Seraf\'ƒ±n Moral. A non-specificity measure for convex sets of probability distributions. <em>Int. J. Uncertain. Fuzziness Knowl. Based Syst.</em>, 8(3):357‚Äì368, 2000. URL: <a class="reference external" href="https://doi.org/10.1142/S0218488500000253">https://doi.org/10.1142/S0218488500000253</a>, <a class="reference external" href="https://doi.org/10.1142/S0218488500000253">doi:10.1142/S0218488500000253</a>.</p>
</div>
<div class="citation" id="id6" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>ASSR20<span class="fn-bracket">]</span></span>
<p>Alexander Amini, Wilko Schwarting, Ava Soleimany, and Daniela Rus. Deep evidential regression. In Hugo Larochelle, Marc'Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin, editors, <em>Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual</em>. 2020. URL: <a class="reference external" href="https://proceedings.neurips.cc/paper/2020/hash/aab085461de182608ee9f607f3f7d18f-Abstract.html">https://proceedings.neurips.cc/paper/2020/hash/aab085461de182608ee9f607f3f7d18f-Abstract.html</a>.</p>
</div>
<div class="citation" id="id16" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>AB21<span class="fn-bracket">]</span></span>
<p>Anastasios¬†N. Angelopoulos and Stephen Bates. A gentle introduction to conformal prediction and distribution-free uncertainty quantification. <em>CoRR</em>, 2021. URL: <a class="reference external" href="https://arxiv.org/abs/2107.07511">https://arxiv.org/abs/2107.07511</a>, <a class="reference external" href="https://arxiv.org/abs/2107.07511">arXiv:2107.07511</a>.</p>
</div>
<div class="citation" id="id63" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>ACB17<span class="fn-bracket">]</span></span>
<p>Martin Arjovsky, Soumith Chintala, and L√©on Bottou. Wasserstein generative adversarial networks. <em>ICML</em>, 2017.</p>
</div>
<div class="citation" id="id65" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>ACdCT14<span class="fn-bracket">]</span></span>
<p>Thomas Augustin, Frank Coolen, Gert de¬†Cooman, and Matthias Troffaes. <em>Introduction to Imprecise Probabilities</em>. Wiley, 2014.</p>
</div>
<div class="citation" id="id18" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>BHenaffK+20<span class="fn-bracket">]</span></span>
<p>Lucas Beyer, Olivier¬†J. H√©naff, Alexander Kolesnikov, Xiaohua Zhai, and A√§ron van¬†den Oord. Are we done with imagenet? <em>CoRR</em>, 2020. URL: <a class="reference external" href="https://arxiv.org/abs/2006.07159">https://arxiv.org/abs/2006.07159</a>, <a class="reference external" href="https://arxiv.org/abs/2006.07159">arXiv:2006.07159</a>.</p>
</div>
<div class="citation" id="id21" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Bis06a<span class="fn-bracket">]</span></span>
<p>Christopher¬†M. Bishop. <em>Pattern Recognition and Machine Learning</em>. Information Science and Statistics. Springer, New York, NY, USA, 2006. ISBN 978-0-387-31073-2. URL: <a class="reference external" href="https://link.springer.com/book/10.1007/978-0-387-45528-0">https://link.springer.com/book/10.1007/978-0-387-45528-0</a>, <a class="reference external" href="https://doi.org/10.1007/978-0-387-45528-0">doi:10.1007/978-0-387-45528-0</a>.</p>
</div>
<div class="citation" id="id47" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Bis06b<span class="fn-bracket">]</span></span>
<p>Christopher¬†M. Bishop. <em>Pattern Recognition and Machine Learning</em>. Springer, 2006.</p>
</div>
<div class="citation" id="id2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>BCKW15<span class="fn-bracket">]</span></span>
<p>Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra. Weight uncertainty in neural network. In Francis¬†R. Bach and David¬†M. Blei, editors, <em>Proceedings of the 32nd International Conference on Machine Learning, ICML 2015, Lille, France, 6-11 July 2015</em>, volume¬†37 of JMLR Workshop and Conference Proceedings, 1613‚Äì1622. JMLR.org, 2015. URL: <a class="reference external" href="http://proceedings.mlr.press/v37/blundell15.html">http://proceedings.mlr.press/v37/blundell15.html</a>.</p>
</div>
<div class="citation" id="id22" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>CGH+17<span class="fn-bracket">]</span></span>
<p>Bob Carpenter, Andrew Gelman, Matthew¬†D. Hoffman, Daniel Lee, Ben Goodrich, Michael Betancourt, Marcus Brubaker, Jiqiang Guo, Peter Li, and Allen Riddell. Stan: A probabilistic programming language. <em>Journal of Statistical Software</em>, 76(1):1‚Äì32, 2017. URL: <a class="reference external" href="https://www.jstatsoft.org/article/view/v076i01">https://www.jstatsoft.org/article/view/v076i01</a>, <a class="reference external" href="https://doi.org/10.18637/jss.v076.i01">doi:10.18637/jss.v076.i01</a>.</p>
</div>
<div class="citation" id="id77" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>CBZugner+22<span class="fn-bracket">]</span></span>
<p>Bertrand Charpentier, Oliver Borchert, Daniel Z√ºgner, Simon Geisler, and Stephan G√ºnnemann. Natural posterior network: deep bayesian predictive uncertainty for exponential family distributions. In <em>International Conference on Learning Representations</em>. 2022.</p>
</div>
<div class="citation" id="id75" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>CZugnerGunnemann20<span class="fn-bracket">]</span></span>
<p>Bertrand Charpentier, Daniel Z√ºgner, and Stephan G√ºnnemann. Posterior network: uncertainty estimation without ood samples via density-based pseudo-counts. In <em>Advances in Neural Information Processing Systems</em>, volume¬†33, 1356‚Äì1367. Curran Associates, Inc., 2020.</p>
</div>
<div class="citation" id="id55" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>C+20<span class="fn-bracket">]</span></span>
<p>John¬†P. Cunningham and others. Ensemble subsampling for efficient uncertainty estimation. In <em>ICLR Workshop on Uncertainty and Robustness in Deep Learning</em>. 2020.</p>
</div>
<div class="citation" id="id20" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Cuz22<span class="fn-bracket">]</span></span>
<p>Fabio Cuzzolin. The intersection probability: betting with probability intervals. <em>CoRR</em>, 2022. URL: <a class="reference external" href="https://arxiv.org/abs/2201.01729">https://arxiv.org/abs/2201.01729</a>, <a class="reference external" href="https://arxiv.org/abs/2201.01729">arXiv:2201.01729</a>.</p>
</div>
<div class="citation" id="id8" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>DHernandezLobatoDoshiVelezU18<span class="fn-bracket">]</span></span>
<p>Stefan Depeweg, Jos√©¬†Miguel Hern√°ndez-Lobato, Finale Doshi-Velez, and Steffen Udluft. Decomposition of uncertainty in bayesian deep learning for efficient and risk-sensitive learning. In Jennifer¬†G. Dy and Andreas Krause, editors, <em>Proceedings of the 35th International Conference on Machine Learning, ICML 2018, Stockholmsm√§ssan, Stockholm, Sweden, July 10-15, 2018</em>, volume¬†80 of Proceedings of Machine Learning Research, 1192‚Äì1201. PMLR, 2018. URL: <a class="reference external" href="http://proceedings.mlr.press/v80/depeweg18a.html">http://proceedings.mlr.press/v80/depeweg18a.html</a>.</p>
</div>
<div class="citation" id="id64" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>DKD09<span class="fn-bracket">]</span></span>
<p>Armen Der¬†Kiureghian and Ove Ditlevsen. Aleatory or epistemic? does it matter? <em>Structural Safety</em>, 2009.</p>
</div>
<div class="citation" id="id52" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Die00<span class="fn-bracket">]</span></span>
<p>Thomas¬†G. Dietterich. Ensemble methods in machine learning. In <em>International Workshop on Multiple Classifier Systems</em>, 1‚Äì15. Springer, 2000.</p>
</div>
<div class="citation" id="id53" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>FHL19<span class="fn-bracket">]</span></span>
<p>Stanislav Fort, Huiyi Hu, and Balaji Lakshminarayanan. Deep ensembles: a loss landscape perspective. <em>arXiv preprint arXiv:1912.02757</em>, 2019.</p>
</div>
<div class="citation" id="id60" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>GG16a<span class="fn-bracket">]</span></span>
<p>Yarin Gal and Zoubin Ghahramani. Dropout as a bayesian approximation: representing model uncertainty in deep learning. <em>ICML</em>, 2016.</p>
</div>
<div class="citation" id="id3" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>GG16b<span class="fn-bracket">]</span></span>
<p>Yarin Gal and Zoubin Ghahramani. Dropout as a bayesian approximation: representing model uncertainty in deep learning. In Maria-Florina Balcan and Kilian¬†Q. Weinberger, editors, <em>Proceedings of the 33nd International Conference on Machine Learning, ICML 2016, New York City, NY, USA, June 19-24, 2016</em>, volume¬†48 of JMLR Workshop and Conference Proceedings, 1050‚Äì1059. JMLR.org, 2016. URL: <a class="reference external" href="http://proceedings.mlr.press/v48/gal16.html">http://proceedings.mlr.press/v48/gal16.html</a>.</p>
</div>
<div class="citation" id="id48" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>GG16c<span class="fn-bracket">]</span></span>
<p>Yarin Gal and Zoubin Ghahramani. Dropout as a bayesian approximation: representing model uncertainty in deep learning. In <em>Proceedings of the 33rd International Conference on Machine Learning (ICML)</em>, 1050‚Äì1059. 2016.</p>
</div>
<div class="citation" id="id67" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>GEY17<span class="fn-bracket">]</span></span>
<p>Yotam Geifman and Ran El-Yaniv. Selective classification for deep neural networks. In <em>NeurIPS</em>. 2017.</p>
</div>
<div class="citation" id="id24" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>GH07<span class="fn-bracket">]</span></span>
<p>Andrew Gelman and Jennifer Hill. <em>Data Analysis Using Regression and Multilevel/Hierarchical Models</em>. Analytical Methods for Social Research. Cambridge University Press, New York, NY, 2007. ISBN 978-0-521-86706-1. URL: <a class="reference external" href="https://doi.org/10.1017/CBO9780511790942">https://doi.org/10.1017/CBO9780511790942</a>, <a class="reference external" href="https://doi.org/10.1017/CBO9780511790942">doi:10.1017/CBO9780511790942</a>.</p>
</div>
<div class="citation" id="id62" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>GR07<span class="fn-bracket">]</span></span>
<p>Tilmann Gneiting and Adrian¬†E. Raftery. Strictly proper scoring rules, prediction, and estimation. <em>JASA</em>, 2007.</p>
</div>
<div class="citation" id="id46" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>GBC16<span class="fn-bracket">]</span></span>
<p>Ian Goodfellow, Yoshua Bengio, and Aaron Courville. <em>Deep Learning</em>. MIT Press, 2016.</p>
</div>
<div class="citation" id="id25" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>GW08<span class="fn-bracket">]</span></span>
<p>Andreas Griewank and Andrea Walther. <em>Evaluating Derivatives: Principles and Techniques of Algorithmic Differentiation</em>. Volume 105 of Other Titles in Applied Mathematics. Society for Industrial and Applied Mathematics, Philadelphia, PA, 2 edition, 2008. ISBN 978-0-89871-659-7. URL: <a class="reference external" href="https://doi.org/10.1137/1.9780898717761">https://doi.org/10.1137/1.9780898717761</a>, <a class="reference external" href="https://doi.org/10.1137/1.9780898717761">doi:10.1137/1.9780898717761</a>.</p>
</div>
<div class="citation" id="id68" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>GPSW17a<span class="fn-bracket">]</span></span>
<p>Chuan Guo, Geoff Pleiss, Yu¬†Sun, and Kilian Weinberger. On calibration of modern neural networks. <em>ICML</em>, 2017.</p>
</div>
<div class="citation" id="id14" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>GPSW17b<span class="fn-bracket">]</span></span>
<p>Chuan Guo, Geoff Pleiss, Yu¬†Sun, and Kilian¬†Q. Weinberger. On calibration of modern neural networks. In Doina Precup and Yee¬†Whye Teh, editors, <em>Proceedings of the 34th International Conference on Machine Learning, ICML 2017, Sydney, NSW, Australia, 6-11 August 2017</em>, volume¬†70 of Proceedings of Machine Learning Research, 1321‚Äì1330. PMLR, 2017. URL: <a class="reference external" href="http://proceedings.mlr.press/v70/guo17a.html">http://proceedings.mlr.press/v70/guo17a.html</a>.</p>
</div>
<div class="citation" id="id54" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>H+21<span class="fn-bracket">]</span></span>
<p>Marton Havasi and others. Training independent subnetworks for robust prediction. <em>Proceedings of the National Academy of Sciences</em>, 2021.</p>
</div>
<div class="citation" id="id66" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>HG17<span class="fn-bracket">]</span></span>
<p>Dan Hendrycks and Kevin Gimpel. A baseline for detecting misclassified and out-of-distribution examples in neural networks. <em>ICLR</em>, 2017.</p>
</div>
<div class="citation" id="id26" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>HA18<span class="fn-bracket">]</span></span>
<p>Robin¬†J. Hyndman and George Athanasopoulos. <em>Forecasting: Principles and Practice</em>. OTexts, Australia, 2nd edition, 2018. URL: <a class="reference external" href="https://otexts.com/fpp2/">https://otexts.com/fpp2/</a>.</p>
</div>
<div class="citation" id="id41" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>HW21<span class="fn-bracket">]</span></span>
<p>Eyke H√ºllermeier and Willem Waegeman. Aleatoric and epistemic uncertainty in machine learning: an introduction to concepts and methods. <em>Machine Learning</em>, 2021. arXiv:1910.09457.</p>
</div>
<div class="citation" id="id57" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>JJNH91<span class="fn-bracket">]</span></span>
<p>Robert¬†A. Jacobs, Michael¬†I. Jordan, Steven¬†J. Nowlan, and Geoffrey¬†E. Hinton. Adaptive mixtures of local experts. <em>Neural Computation</em>, 3(1):79‚Äì87, 1991.</p>
</div>
<div class="citation" id="id49" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>KG17<span class="fn-bracket">]</span></span>
<p>Alex Kendall and Yarin Gal. What uncertainties do we need in bayesian deep learning for computer vision? <em>Advances in Neural Information Processing Systems</em>, 2017.</p>
</div>
<div class="citation" id="id27" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>KW14<span class="fn-bracket">]</span></span>
<p>Diederik¬†P. Kingma and Max Welling. Auto-encoding variational bayes. In <em>Proceedings of the 2nd International Conference on Learning Representations (ICLR 2014)</em>. 2014. arXiv:1312.6114. URL: <a class="reference external" href="https://arxiv.org/abs/1312.6114">https://arxiv.org/abs/1312.6114</a>.</p>
</div>
<div class="citation" id="id61" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>LPB17a<span class="fn-bracket">]</span></span>
<p>Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and scalable predictive uncertainty estimation using deep ensembles. <em>NeurIPS</em>, 2017.</p>
</div>
<div class="citation" id="id4" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>LPB17b<span class="fn-bracket">]</span></span>
<p>Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and scalable predictive uncertainty estimation using deep ensembles. In Isabelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna¬†M. Wallach, Rob Fergus, S.¬†V.¬†N. Vishwanathan, and Roman Garnett, editors, <em>Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA</em>, 6402‚Äì6413. 2017. URL: <a class="reference external" href="https://proceedings.neurips.cc/paper/2017/hash/9ef2ed4b7fd2c810847ffa5fa85bce38-Abstract.html">https://proceedings.neurips.cc/paper/2017/hash/9ef2ed4b7fd2c810847ffa5fa85bce38-Abstract.html</a>.</p>
</div>
<div class="citation" id="id51" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>LPB17c<span class="fn-bracket">]</span></span>
<p>Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and scalable predictive uncertainty estimation using deep ensembles. In <em>Advances in Neural Information Processing Systems</em>, 6402‚Äì6413. 2017.</p>
</div>
<div class="citation" id="id45" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>LBBH98<span class="fn-bracket">]</span></span>
<p>Yann LeCun, L√©on Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document recognition. <em>Proceedings of the IEEE</em>, 86(11):2278‚Äì2324, 1998.</p>
</div>
<div class="citation" id="id10" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>LHullermeier21<span class="fn-bracket">]</span></span>
<p>Julian Lienen and Eyke H√ºllermeier. From label smoothing to label relaxation. In <em>Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event, February 2-9, 2021</em>, 8583‚Äì8591. AAAI Press, 2021. URL: <a class="reference external" href="https://doi.org/10.1609/aaai.v35i10.17041">https://doi.org/10.1609/aaai.v35i10.17041</a>, <a class="reference external" href="https://doi.org/10.1609/AAAI.V35I10.17041">doi:10.1609/AAAI.V35I10.17041</a>.</p>
</div>
<div class="citation" id="id13" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>LGG+17<span class="fn-bracket">]</span></span>
<p>Tsung-Yi Lin, Priya Goyal, Ross¬†B. Girshick, Kaiming He, and Piotr Doll√°r. Focal loss for dense object detection. In <em>IEEE International Conference on Computer Vision, ICCV 2017, Venice, Italy, October 22-29, 2017</em>, 2999‚Äì3007. IEEE Computer Society, 2017. URL: <a class="reference external" href="https://doi.org/10.1109/ICCV.2017.324">https://doi.org/10.1109/ICCV.2017.324</a>, <a class="reference external" href="https://doi.org/10.1109/ICCV.2017.324">doi:10.1109/ICCV.2017.324</a>.</p>
</div>
<div class="citation" id="id76" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>MCPG20<span class="fn-bracket">]</span></span>
<p>Andrey Malinin, Sergey Chervontsev, Ivan Provilkov, and Mark Gales. Regression prior networks. <em>arXiv preprint arXiv:2006.11590</em>, 2020.</p>
</div>
<div class="citation" id="id73" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>MG18<span class="fn-bracket">]</span></span>
<p>Andrey Malinin and Mark Gales. Predictive uncertainty estimation via prior networks. In <em>Advances in Neural Information Processing Systems</em>, volume¬†31. Curran Associates, Inc., 2018.</p>
</div>
<div class="citation" id="id42" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Mar24<span class="fn-bracket">]</span></span>
<p>Charlie Marsh. Astral docs. <a class="reference external" href="https://docs.astral.sh/uv/">https://docs.astral.sh/uv/</a>, 2024. Accessed: 2024-01-15.</p>
</div>
<div class="citation" id="id15" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>MNM+19<span class="fn-bracket">]</span></span>
<p>Aryan Mobiny, Hien¬†Van Nguyen, Supratik Moulik, Naveen Garg, and Carol¬†C. Wu. Dropconnect is effective in modeling uncertainty of bayesian deep networks. <em>CoRR</em>, 2019. URL: <a class="reference external" href="http://arxiv.org/abs/1906.04569">http://arxiv.org/abs/1906.04569</a>, <a class="reference external" href="https://arxiv.org/abs/1906.04569">arXiv:1906.04569</a>.</p>
</div>
<div class="citation" id="id43" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>na26<span class="fn-bracket">]</span></span>
<p>n/a. Google python style guide. <a class="reference external" href="https://google.github.io/styleguide/pyguide.html#docstrings">https://google.github.io/styleguide/pyguide.html#docstrings</a>, 2026. Accessed: 2025-01-15.</p>
</div>
<div class="citation" id="id7" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>NZD25<span class="fn-bracket">]</span></span>
<p>Vu-Linh Nguyen, Haifei Zhang, and S√©bastien Destercke. Credal ensembling in multi-class classification. <em>Mach. Learn.</em>, 114(1):19, 2025. URL: <a class="reference external" href="https://doi.org/10.1007/s10994-024-06703-y">https://doi.org/10.1007/s10994-024-06703-y</a>, <a class="reference external" href="https://doi.org/10.1007/S10994-024-06703-Y">doi:10.1007/S10994-024-06703-Y</a>.</p>
</div>
<div class="citation" id="id56" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>OM99<span class="fn-bracket">]</span></span>
<p>David Opitz and Richard Maclin. Popular ensemble methods: an empirical study. <em>Journal of Artificial Intelligence Research</em>, 11:169‚Äì198, 1999.</p>
</div>
<div class="citation" id="id50" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>O+19<span class="fn-bracket">]</span></span>
<p>Yaniv Ovadia and others. Can you trust your model's uncertainty? evaluating predictive uncertainty under dataset shift. <em>Advances in Neural Information Processing Systems</em>, 2019.</p>
</div>
<div class="citation" id="id28" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>PNR+21<span class="fn-bracket">]</span></span>
<p>George Papamakarios, Eric Nalisnick, Danilo¬†Jimenez Rezende, Shakir Mohamed, and Balaji Lakshminarayanan. Normalizing flows for probabilistic modeling and inference. <em>Journal of Machine Learning Research</em>, 22(57):1‚Äì64, 2021. URL: <a class="reference external" href="https://www.jmlr.org/papers/volume22/19-1028/19-1028.pdf">https://www.jmlr.org/papers/volume22/19-1028/19-1028.pdf</a>.</p>
</div>
<div class="citation" id="id29" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Pat25<span class="fn-bracket">]</span></span>
<p>Suvendu¬†K. Pati. Best practices for organizing and coding data science projects ‚Äî part 1. 2025. The Deep Hub (Medium), posted March 27, 2025. URL: <a class="reference external" href="https://medium.com/thedeephub/best-practices-for-organizing-and-coding-data-science-projects-part-1-72539e14a7a0">https://medium.com/thedeephub/best-practices-for-organizing-and-coding-data-science-projects-part-1-72539e14a7a0</a>.</p>
</div>
<div class="citation" id="id17" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>PBGR19<span class="fn-bracket">]</span></span>
<p>Joshua¬†C. Peterson, Ruairidh¬†M. Battleday, Thomas¬†L. Griffiths, and Olga Russakovsky. Human uncertainty makes classification more robust. In <em>2019 IEEE/CVF International Conference on Computer Vision, ICCV 2019, Seoul, Korea (South), October 27 - November 2, 2019</em>, 9616‚Äì9625. IEEE, 2019. URL: <a class="reference external" href="https://doi.org/10.1109/ICCV.2019.00971">https://doi.org/10.1109/ICCV.2019.00971</a>, <a class="reference external" href="https://doi.org/10.1109/ICCV.2019.00971">doi:10.1109/ICCV.2019.00971</a>.</p>
</div>
<div class="citation" id="id31" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>RM15<span class="fn-bracket">]</span></span>
<p>Danilo¬†J. Rezende and Shakir Mohamed. Variational inference with normalizing flows. In <em>Proceedings of the 32nd International Conference on Machine Learning</em>, volume¬†37 of Proceedings of Machine Learning Research, 1530‚Äì1538. PMLR, 2015. URL: <a class="reference external" href="https://proceedings.mlr.press/v37/rezende15.html">https://proceedings.mlr.press/v37/rezende15.html</a>.</p>
</div>
<div class="citation" id="id9" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>SBCHullermeier24<span class="fn-bracket">]</span></span>
<p>Yusuf Sale, Viktor Bengs, Michele Caprio, and Eyke H√ºllermeier. Second-order uncertainty quantification: A distance-based approach. In <em>Forty-first International Conference on Machine Learning, ICML 2024, Vienna, Austria, July 21-27, 2024</em>. OpenReview.net, 2024. URL: <a class="reference external" href="https://openreview.net/forum?id=VJjjNrUi8j">https://openreview.net/forum?id=VJjjNrUi8j</a>.</p>
</div>
<div class="citation" id="id19" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>SGZ+22<span class="fn-bracket">]</span></span>
<p>Lars Schmarje, Vasco Grossmann, Claudius Zelenka, Sabine Dippel, Rainer Kiko, Mariusz Oszust, Matti Pastell, Jenny Stracke, Anna Valros, Nina Volkmann, and Reinhard Koch. Is one annotation enough? - A data-centric image classification benchmark for noisy and ambiguous label estimation. In Sanmi Koyejo, S.¬†Mohamed, A.¬†Agarwal, Danielle Belgrave, K.¬†Cho, and A.¬†Oh, editors, <em>Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022</em>. 2022. URL: <a class="reference external" href="http://papers.nips.cc/paper_files/paper/2022/hash/d6c03035b8bc551f474f040fe8607cab-Abstract-Datasets_and_Benchmarks.html">http://papers.nips.cc/paper_files/paper/2022/hash/d6c03035b8bc551f474f040fe8607cab-Abstract-Datasets_and_Benchmarks.html</a>.</p>
</div>
<div class="citation" id="id72" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>SKK19<span class="fn-bracket">]</span></span>
<p>Murat Sensoy, Lance Kaplan, and Melih Kandemir. Evidential deep learning to quantify classification uncertainty. <em>arXiv preprint arXiv:1910.09457</em>, 2019.</p>
</div>
<div class="citation" id="id5" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>SKK18<span class="fn-bracket">]</span></span>
<p>Murat Sensoy, Lance¬†M. Kaplan, and Melih Kandemir. Evidential deep learning to quantify classification uncertainty. In Samy Bengio, Hanna¬†M. Wallach, Hugo Larochelle, Kristen Grauman, Nicol√≤ Cesa-Bianchi, and Roman Garnett, editors, <em>Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montr√©al, Canada</em>, 3183‚Äì3193. 2018. URL: <a class="reference external" href="https://proceedings.neurips.cc/paper/2018/hash/a981f2b708044d6fb4a71a1463242520-Abstract.html">https://proceedings.neurips.cc/paper/2018/hash/a981f2b708044d6fb4a71a1463242520-Abstract.html</a>.</p>
</div>
<div class="citation" id="id59" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Sha48<span class="fn-bracket">]</span></span>
<p>Claude Shannon. A mathematical theory of communication. <em>Bell System Technical Journal</em>, 1948.</p>
</div>
<div class="citation" id="id58" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>SMM+17<span class="fn-bracket">]</span></span>
<p>Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, and others. Outrageously large neural networks: the sparsely-gated mixture-of-experts layer. In <em>International Conference on Learning Representations</em>. 2017.</p>
</div>
<div class="citation" id="id70" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Tra19<span class="fn-bracket">]</span></span>
<p>Dustin et¬†al. Tran. Bayesian layers: a module for neural network uncertainty. In <em>NeurIPS</em>. 2019.</p>
</div>
<div class="citation" id="id74" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Tsi19<span class="fn-bracket">]</span></span>
<p>Theodoros Tsiligkaridis. Information robust dirichlet networks for predictive uncertainty estimation. <em>arXiv preprint arXiv:1910.04819</em>, 2019.</p>
</div>
<div class="citation" id="id37" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>THH+24<span class="fn-bracket">]</span></span>
<p>Xiaoguang Tu, Zhi He, Yi¬†Huang, Zhi-Hao Zhang, Ming Yang, and Jian Zhao. An overview of large AI models and their applications. <em>Visual Intelligence</em>, 2(1):34, 2024. URL: <a class="reference external" href="https://doi.org/10.1007/s44267-024-00065-8">https://doi.org/10.1007/s44267-024-00065-8</a>, <a class="reference external" href="https://doi.org/10.1007/s44267-024-00065-8">doi:10.1007/s44267-024-00065-8</a>.</p>
</div>
<div class="citation" id="id38" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Tya25<span class="fn-bracket">]</span></span>
<p>Ankush¬†Jitendrakumar Tyagi. Scaling deep learning models: challenges and solutions for large-scale deployments. <em>World Journal of Advanced Engineering Technology and Sciences</em>, 16(2):10‚Äì20, 2025. URL: <a class="reference external" href="https://doi.org/10.30574/wjaets.2025.16.2.1252">https://doi.org/10.30574/wjaets.2025.16.2.1252</a>, <a class="reference external" href="https://doi.org/10.30574/wjaets.2025.16.2.1252">doi:10.30574/wjaets.2025.16.2.1252</a>.</p>
</div>
<div class="citation" id="id39" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>vit20<span class="fn-bracket">]</span></span>
<p>vitkl. Softplus transform as a more numerically stable way to enforce positive constraint. GitHub issue #855 on the \emph NumPyro repository, December 2020. Issue opened December 31, 2020. URL: <a class="reference external" href="https://github.com/pyro-ppl/numpyro/issues/855">https://github.com/pyro-ppl/numpyro/issues/855</a>.</p>
</div>
<div class="citation" id="id71" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Yan21<span class="fn-bracket">]</span></span>
<p>Yiyou et¬†al. Yang. Generalized ood detection via bayesian uncertainty estimation. <em>CVPR</em>, 2021.</p>
</div>
<div class="citation" id="id40" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Zind.<span class="fn-bracket">]</span></span>
<p>Martin Zinkevich. Rules of machine learning: best practices for ML engineering. Google Developers, n.d. Google Developers guide, accessed 19 November 2025. URL: <a class="reference external" href="https://developers.google.com/machine-learning/guides/rules-of-ml">https://developers.google.com/machine-learning/guides/rules-of-ml</a>.</p>
</div>
<div class="citation" id="id23" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>ContributorsttPProject19<span class="fn-bracket">]</span></span>
<p>Contributors to the Pyro Project. NumPyro transforms module. Documentation, 2019. NumPyro documentation, transforms module, version 0.4.1. URL: <a class="reference external" href="https://num.pyro.ai/en/0.4.1/_modules/numpyro/distributions/transforms.html">https://num.pyro.ai/en/0.4.1/_modules/numpyro/distributions/transforms.html</a>.</p>
</div>
<div class="citation" id="id44" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>PythonSFoundation18<span class="fn-bracket">]</span></span>
<p>Python Software Foundation. Python Software Foundation Code of Conduct ‚Äì Python Software Foundation Policies. <a class="reference external" href="https://policies.python.org/python.org/code-of-conduct/">https://policies.python.org/python.org/code-of-conduct/</a>, 2018. Accessed: 2025-12-07.</p>
</div>
<div class="citation" id="id30" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>PythonSFoundationd.<span class="fn-bracket">]</span></span>
<p>Python Software Foundation. The python profilers. n.d. In Python Documentation. URL: <a class="reference external" href="https://docs.python.org/3/library/profile.html">https://docs.python.org/3/library/profile.html</a>.</p>
</div>
<div class="citation" id="id33" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>StanDTeam25<span class="fn-bracket">]</span></span>
<p>Stan Development Team. Constraint transforms. 2025. In Stan Reference Manual, Version 2.37. URL: <a class="reference external" href="https://mc-stan.org/docs/reference-manual/transforms.html">https://mc-stan.org/docs/reference-manual/transforms.html</a>.</p>
</div>
<div class="citation" id="id32" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>StanDTeamd.<span class="fn-bracket">]</span></span>
<p>Stan Development Team. 10.2 lower bounded scalar. n.d. In Stan Reference Manual, Version 2.22. URL: <a class="reference external" href="https://mc-stan.org/docs/2_22/reference-manual/lower-bound-transform-section.html">https://mc-stan.org/docs/2_22/reference-manual/lower-bound-transform-section.html</a>.</p>
</div>
<div class="citation" id="id35" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>TensorFlowProbability23<span class="fn-bracket">]</span></span>
<p>TensorFlow Probability. Tfp.bijectors.bijector; tfp.bijectors.softplus. 2023. In TensorFlow Probability API documentation. URL: <a class="reference external" href="https://www.tensorflow.org/probability/api_docs/python/tfp/bijectors/Bijector">https://www.tensorflow.org/probability/api_docs/python/tfp/bijectors/Bijector</a>.</p>
</div>
<div class="citation" id="id34" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>TensorFlowProbabilityd.<span class="fn-bracket">]</span></span>
<p>TensorFlow Probability. Module: tfp.bijectors. n.d. In TensorFlow Probability API documentation. URL: <a class="reference external" href="https://www.tensorflow.org/probability/api_docs/python/tfp/bijectors">https://www.tensorflow.org/probability/api_docs/python/tfp/bijectors</a>.</p>
</div>
<div class="citation" id="id36" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>TheJAuthors24<span class="fn-bracket">]</span></span>
<p>The JAX Authors. Pseudorandom numbers. 2024. In JAX documentation. URL: <a class="reference external" href="https://docs.jax.dev/en/latest/random-numbers.html">https://docs.jax.dev/en/latest/random-numbers.html</a>.</p>
</div>
</div>
</div>
</section>
<section id="similar-tools-ecosystem">
<h2>Similar Tools &amp; Ecosystem<a class="headerlink" href="#similar-tools-ecosystem" title="Link to this heading">¬∂</a></h2>
<p>We believe in using the right tool for the right job. While <code class="docutils literal notranslate"><span class="pre">probly</span></code> offers a unique set of features, there are several other tools in the ecosystem that may complement or enhance your workflow:</p>
<ul class="simple">
<li><dl class="simple">
<dt><strong>TensorFlow Probability (TFP):</strong></dt><dd><p>A library for probabilistic reasoning and statistical analysis in TensorFlow. It provides a wide range of probabilistic models and inference algorithms.
<a class="reference external" href="https://www.tensorflow.org/probability">Visit TensorFlow Probability</a></p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>Pyro:</strong></dt><dd><p>A flexible, scalable deep probabilistic programming library built on PyTorch. It is designed for Bayesian modeling and inference.
<a class="reference external" href="https://pyro.ai/">Visit Pyro</a></p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>GPyTorch:</strong></dt><dd><p>A Gaussian process library built on PyTorch, designed for creating and training Gaussian process models.
<a class="reference external" href="https://gpytorch.ai/">Visit GPyTorch</a></p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>Laplace:</strong></dt><dd><p>A library for Laplace approximations in PyTorch, useful for Bayesian deep learning.
<a class="reference external" href="httsps://github.com/AlexImmer/Laplace">Visit Laplace</a></p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>Fortuna:</strong></dt><dd><p>An uncertainty quantification library by AWS, focusing on calibration and probabilistic modeling.
<a class="reference external" href="https://github.com/awslabs/fortuna">Visit Fortuna</a></p>
</dd>
</dl>
</li>
</ul>
</section>
<section id="credits-acknowledgments">
<h2>Credits &amp; Acknowledgments<a class="headerlink" href="#credits-acknowledgments" title="Link to this heading">¬∂</a></h2>
<p>We would like to acknowledge the contributions of the open-source community and the authors of the research papers that have inspired and informed the development of this package. Special thanks to:
* The developers of <strong>PyTorch</strong>, <strong>JAX</strong>, and <strong>FLAX</strong> for providing the backends that make this work possible.
* The authors of the foundational research papers listed above for their pioneering work in probabilistic modeling and inference.</p>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="faq.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">FAQ and Troubleshooting</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="contributing.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Contributing to probly üèîÔ∏è</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2025, probly team
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">References and Further Reading</a><ul>
<li><a class="reference internal" href="#related-research-papers">Related Research Papers</a></li>
<li><a class="reference internal" href="#similar-tools-ecosystem">Similar Tools &amp; Ecosystem</a></li>
<li><a class="reference internal" href="#credits-acknowledgments">Credits &amp; Acknowledgments</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="_static/documentation_options.js?v=4621528c"></script>
    <script src="_static/doctools.js?v=9bcbadda"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/scripts/furo.js?v=5fa4622c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=ccdb6887"></script>
    </body>
</html>