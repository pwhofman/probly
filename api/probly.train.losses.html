<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="probly.transformation" href="probly.transformation.html" /><link rel="prev" title="probly.train.bayesian" href="probly.train.bayesian.html" />

    <!-- Generated with Sphinx 8.2.3 and Furo 2024.08.06 -->
        <title>probly.train.losses - probly 0.3.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=354aac6f" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=302659d7" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #272822;
  --color-code-foreground: #f8f8f2;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #272822;
  --color-code-foreground: #f8f8f2;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">probly 0.3.1 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><div class="sidebar-scroll"><a class="sidebar-brand" href="../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo only-light" src="../_static/logo/logo_light.png" alt="Light Logo"/>
    <img class="sidebar-logo only-dark" src="../_static/logo/logo_dark.png" alt="Dark Logo"/>
  </div>
  
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Content</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../methods.html">Implemented methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html">References</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../examples/fashionmnist_ood_ensemble.html">Out-of-Distribution Detection with an Ensemble</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/label_relaxation_calibration.html">Calibration with Label Relaxation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/sklearn_selective_prediction.html">Using probly with scikit-learn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/temperature_scaling_calibration.html">Calibration using Temperature Scaling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/train_bnn_classification.html">Bayesian Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/train_evidential_classification.html">Evidential Model for Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/train_evidential_regression.html">Evidential Regression Model</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul class="current">
<li class="toctree-l1 current has-children"><a class="reference internal" href="../api.html">API Reference</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of API Reference</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2 has-children"><a class="reference internal" href="probly.datasets.html">probly.datasets</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of probly.datasets</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="probly.datasets.torch.html">probly.datasets.torch</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="probly.evaluation.html">probly.evaluation</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of probly.evaluation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="probly.evaluation.metrics.html">probly.evaluation.metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="probly.evaluation.tasks.html">probly.evaluation.tasks</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="probly.layers.html">probly.layers</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of probly.layers</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="probly.layers.torch.html">probly.layers.torch</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="probly.plot.html">probly.plot</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of probly.plot</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="probly.plot.credal.html">probly.plot.credal</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="probly.predictor.html">probly.predictor</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="probly.quantification.html">probly.quantification</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of probly.quantification</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="probly.quantification.classification.html">probly.quantification.classification</a></li>
<li class="toctree-l3"><a class="reference internal" href="probly.quantification.regression.html">probly.quantification.regression</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="probly.representation.html">probly.representation</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of probly.representation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="probly.representation.representer.html">probly.representation.representer</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="probly.representation.sampling.html">probly.representation.sampling</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of probly.representation.sampling</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="probly.representation.sampling.flax_sampler.html">probly.representation.sampling.flax_sampler</a></li>
<li class="toctree-l4"><a class="reference internal" href="probly.representation.sampling.jax_sample.html">probly.representation.sampling.jax_sample</a></li>
<li class="toctree-l4"><a class="reference internal" href="probly.representation.sampling.sample.html">probly.representation.sampling.sample</a></li>
<li class="toctree-l4"><a class="reference internal" href="probly.representation.sampling.sampler.html">probly.representation.sampling.sampler</a></li>
<li class="toctree-l4"><a class="reference internal" href="probly.representation.sampling.torch_sample.html">probly.representation.sampling.torch_sample</a></li>
<li class="toctree-l4"><a class="reference internal" href="probly.representation.sampling.torch_sampler.html">probly.representation.sampling.torch_sampler</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 current has-children"><a class="reference internal" href="probly.train.html">probly.train</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle navigation of probly.train</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="probly.train.bayesian.html">probly.train.bayesian</a></li>
<li class="toctree-l3 current current-page"><a class="current reference internal" href="#">probly.train.losses</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="probly.transformation.html">probly.transformation</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle navigation of probly.transformation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="probly.transformation.bayesian.html">probly.transformation.bayesian</a></li>
<li class="toctree-l3"><a class="reference internal" href="probly.transformation.dropconnect.html">probly.transformation.dropconnect</a></li>
<li class="toctree-l3"><a class="reference internal" href="probly.transformation.dropout.html">probly.transformation.dropout</a></li>
<li class="toctree-l3"><a class="reference internal" href="probly.transformation.ensemble.html">probly.transformation.ensemble</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="probly.transformation.evidential.html">probly.transformation.evidential</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle navigation of probly.transformation.evidential</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4 has-children"><a class="reference internal" href="probly.transformation.evidential.classification.html">probly.transformation.evidential.classification</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle navigation of probly.transformation.evidential.classification</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l5"><a class="reference internal" href="probly.transformation.evidential.classification.common.html">probly.transformation.evidential.classification.common</a></li>
<li class="toctree-l5"><a class="reference internal" href="probly.transformation.evidential.classification.torch.html">probly.transformation.evidential.classification.torch</a></li>
</ul>
</li>
<li class="toctree-l4 has-children"><a class="reference internal" href="probly.transformation.evidential.regression.html">probly.transformation.evidential.regression</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle navigation of probly.transformation.evidential.regression</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l5"><a class="reference internal" href="probly.transformation.evidential.regression.common.html">probly.transformation.evidential.regression.common</a></li>
<li class="toctree-l5"><a class="reference internal" href="probly.transformation.evidential.regression.torch.html">probly.transformation.evidential.regression.torch</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="probly.traverse_nn.html">probly.traverse_nn</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><div class="visually-hidden">Toggle navigation of probly.traverse_nn</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="probly.traverse_nn.common.html">probly.traverse_nn.common</a></li>
<li class="toctree-l3"><a class="reference internal" href="probly.traverse_nn.flax.html">probly.traverse_nn.flax</a></li>
<li class="toctree-l3"><a class="reference internal" href="probly.traverse_nn.torch.html">probly.traverse_nn.torch</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="probly.utils.html">probly.utils</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><div class="visually-hidden">Toggle navigation of probly.utils</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="probly.utils.errors.html">probly.utils.errors</a></li>
<li class="toctree-l3"><a class="reference internal" href="probly.utils.probabilities.html">probly.utils.probabilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="probly.utils.sets.html">probly.utils.sets</a></li>
<li class="toctree-l3"><a class="reference internal" href="probly.utils.torch.html">probly.utils.torch</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Development</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing to probly 🏔️</a></li>
</ul>

</div>
</div><div style="text-align: center; margin-top: 1rem; margin-bottom: 1rem;">
  <a href="https://github.com/pwhofman/probly" target="_blank" rel="noopener noreferrer" title="GitHub Repository">
    <img src="../_static/github-mark.svg" alt="GitHub Logo" width="28" height="28" style="display: inline-block;">
  </a>
</div>
      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          

<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="module-probly.train.losses">
<span id="probly-train-losses"></span><h1>probly.train.losses<a class="headerlink" href="#module-probly.train.losses" title="Link to this heading">¶</a></h1>
<p>Collection of loss implementations.</p>
<p class="rubric">Classes</p>
<div class="table-wrapper autosummary longtable docutils container">
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#probly.train.losses.ELBOLoss" title="probly.train.losses.ELBOLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ELBOLoss</span></code></a>([kl_penalty])</p></td>
<td><p>Evidence lower bound loss based on <span id="id1">[<a class="reference internal" href="../references.html#id2" title="Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra. Weight uncertainty in neural network. In Francis R. Bach and David M. Blei, editors, Proceedings of the 32nd International Conference on Machine Learning, ICML 2015, Lille, France, 6-11 July 2015, volume 37 of JMLR Workshop and Conference Proceedings, 1613–1622. JMLR.org, 2015. URL: http://proceedings.mlr.press/v37/blundell15.html.">BCKW15</a>]</span>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#probly.train.losses.EvidentialCELoss" title="probly.train.losses.EvidentialCELoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EvidentialCELoss</span></code></a>()</p></td>
<td><p>Evidential Cross Entropy Loss based on <span id="id2">[<a class="reference internal" href="../references.html#id5" title="Murat Sensoy, Lance M. Kaplan, and Melih Kandemir. Evidential deep learning to quantify classification uncertainty. In Samy Bengio, Hanna M. Wallach, Hugo Larochelle, Kristen Grauman, Nicolò Cesa-Bianchi, and Roman Garnett, editors, Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montréal, Canada, 3183–3193. 2018. URL: https://proceedings.neurips.cc/paper/2018/hash/a981f2b708044d6fb4a71a1463242520-Abstract.html.">SKK18</a>]</span>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#probly.train.losses.EvidentialKLDivergence" title="probly.train.losses.EvidentialKLDivergence"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EvidentialKLDivergence</span></code></a>()</p></td>
<td><p>Evidential KL Divergence Loss based on <span id="id3">[<a class="reference internal" href="../references.html#id5" title="Murat Sensoy, Lance M. Kaplan, and Melih Kandemir. Evidential deep learning to quantify classification uncertainty. In Samy Bengio, Hanna M. Wallach, Hugo Larochelle, Kristen Grauman, Nicolò Cesa-Bianchi, and Roman Garnett, editors, Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montréal, Canada, 3183–3193. 2018. URL: https://proceedings.neurips.cc/paper/2018/hash/a981f2b708044d6fb4a71a1463242520-Abstract.html.">SKK18</a>]</span>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#probly.train.losses.EvidentialLogLoss" title="probly.train.losses.EvidentialLogLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EvidentialLogLoss</span></code></a>()</p></td>
<td><p>Evidential Log Loss based on <span id="id4">[<a class="reference internal" href="../references.html#id5" title="Murat Sensoy, Lance M. Kaplan, and Melih Kandemir. Evidential deep learning to quantify classification uncertainty. In Samy Bengio, Hanna M. Wallach, Hugo Larochelle, Kristen Grauman, Nicolò Cesa-Bianchi, and Roman Garnett, editors, Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montréal, Canada, 3183–3193. 2018. URL: https://proceedings.neurips.cc/paper/2018/hash/a981f2b708044d6fb4a71a1463242520-Abstract.html.">SKK18</a>]</span>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#probly.train.losses.EvidentialMSELoss" title="probly.train.losses.EvidentialMSELoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EvidentialMSELoss</span></code></a>()</p></td>
<td><p>Evidential Mean Square Error Loss based on <span id="id5">[<a class="reference internal" href="../references.html#id5" title="Murat Sensoy, Lance M. Kaplan, and Melih Kandemir. Evidential deep learning to quantify classification uncertainty. In Samy Bengio, Hanna M. Wallach, Hugo Larochelle, Kristen Grauman, Nicolò Cesa-Bianchi, and Roman Garnett, editors, Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montréal, Canada, 3183–3193. 2018. URL: https://proceedings.neurips.cc/paper/2018/hash/a981f2b708044d6fb4a71a1463242520-Abstract.html.">SKK18</a>]</span>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#probly.train.losses.EvidentialNIGNLLLoss" title="probly.train.losses.EvidentialNIGNLLLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EvidentialNIGNLLLoss</span></code></a>()</p></td>
<td><p>Evidential normal inverse gamma negative log likelihood loss.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#probly.train.losses.EvidentialRegressionRegularization" title="probly.train.losses.EvidentialRegressionRegularization"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EvidentialRegressionRegularization</span></code></a>()</p></td>
<td><p>Implementation of the evidential regression regularization <span id="id6">[<a class="reference internal" href="../references.html#id6" title="Alexander Amini, Wilko Schwarting, Ava Soleimany, and Daniela Rus. Deep evidential regression. In Hugo Larochelle, Marc'Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin, editors, Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual. 2020. URL: https://proceedings.neurips.cc/paper/2020/hash/aab085461de182608ee9f607f3f7d18f-Abstract.html.">ASSR20</a>]</span>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#probly.train.losses.ExpectedCalibrationError" title="probly.train.losses.ExpectedCalibrationError"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ExpectedCalibrationError</span></code></a>([num_bins])</p></td>
<td><p>Expected Calibration Error (ECE) <span id="id7">[<a class="reference internal" href="../references.html#id14" title="Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q. Weinberger. On calibration of modern neural networks. In Doina Precup and Yee Whye Teh, editors, Proceedings of the 34th International Conference on Machine Learning, ICML 2017, Sydney, NSW, Australia, 6-11 August 2017, volume 70 of Proceedings of Machine Learning Research, 1321–1330. PMLR, 2017. URL: http://proceedings.mlr.press/v70/guo17a.html.">GPSW17</a>]</span>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#probly.train.losses.FocalLoss" title="probly.train.losses.FocalLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FocalLoss</span></code></a>([alpha, gamma])</p></td>
<td><p>Focal Loss based on <span id="id8">[<a class="reference internal" href="../references.html#id13" title="Tsung-Yi Lin, Priya Goyal, Ross B. Girshick, Kaiming He, and Piotr Dollár. Focal loss for dense object detection. In IEEE International Conference on Computer Vision, ICCV 2017, Venice, Italy, October 22-29, 2017, 2999–3007. IEEE Computer Society, 2017. URL: https://doi.org/10.1109/ICCV.2017.324, doi:10.1109/ICCV.2017.324.">LGG+17</a>]</span>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#probly.train.losses.LabelRelaxationLoss" title="probly.train.losses.LabelRelaxationLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LabelRelaxationLoss</span></code></a>([alpha])</p></td>
<td><p>Label Relaxation Loss from <span id="id9">[<a class="reference internal" href="../references.html#id10" title="Julian Lienen and Eyke Hüllermeier. From label smoothing to label relaxation. In Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event, February 2-9, 2021, 8583–8591. AAAI Press, 2021. URL: https://doi.org/10.1609/aaai.v35i10.17041, doi:10.1609/AAAI.V35I10.17041.">LHullermeier21</a>]</span>.</p></td>
</tr>
</tbody>
</table>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="probly.train.losses.ELBOLoss">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">probly.train.losses.</span></span><span class="sig-name descname"><span class="pre">ELBOLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kl_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/probly/train/losses.html#ELBOLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#probly.train.losses.ELBOLoss" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a></p>
<p>Evidence lower bound loss based on <span id="id10">[<a class="reference internal" href="../references.html#id2" title="Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra. Weight uncertainty in neural network. In Francis R. Bach and David M. Blei, editors, Proceedings of the 32nd International Conference on Machine Learning, ICML 2015, Lille, France, 6-11 July 2015, volume 37 of JMLR Workshop and Conference Proceedings, 1613–1622. JMLR.org, 2015. URL: http://proceedings.mlr.press/v37/blundell15.html.">BCKW15</a>]</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>kl_penalty</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a>)</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="probly.train.losses.ELBOLoss.kl_penalty">
<span class="sig-name descname"><span class="pre">kl_penalty</span></span><a class="headerlink" href="#probly.train.losses.ELBOLoss.kl_penalty" title="Link to this definition">¶</a></dt>
<dd><p>float, weight for KL divergence term</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="probly.train.losses.ELBOLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kl</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/probly/train/losses.html#ELBOLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#probly.train.losses.ELBOLoss.forward" title="Link to this definition">¶</a></dt>
<dd><p>Forward pass of the ELBO loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>inputs</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.9)"><em>Tensor</em></a>) – torch.Tensor of size (n_instances, n_classes)</p></li>
<li><p><strong>targets</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.9)"><em>Tensor</em></a>) – torch.Tensor of size (n_instances,)</p></li>
<li><p><strong>kl</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.9)"><em>Tensor</em></a>) – torch.Tensor, KL divergence of the model</p></li>
</ul>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor, mean loss value</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>loss</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="probly.train.losses.EvidentialCELoss">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">probly.train.losses.</span></span><span class="sig-name descname"><span class="pre">EvidentialCELoss</span></span><a class="reference internal" href="../_modules/probly/train/losses.html#EvidentialCELoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#probly.train.losses.EvidentialCELoss" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a></p>
<p>Evidential Cross Entropy Loss based on <span id="id11">[<a class="reference internal" href="../references.html#id5" title="Murat Sensoy, Lance M. Kaplan, and Melih Kandemir. Evidential deep learning to quantify classification uncertainty. In Samy Bengio, Hanna M. Wallach, Hugo Larochelle, Kristen Grauman, Nicolò Cesa-Bianchi, and Roman Garnett, editors, Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montréal, Canada, 3183–3193. 2018. URL: https://proceedings.neurips.cc/paper/2018/hash/a981f2b708044d6fb4a71a1463242520-Abstract.html.">SKK18</a>]</span>.</p>
<dl class="field-list simple">
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="probly.train.losses.EvidentialCELoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/probly/train/losses.html#EvidentialCELoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#probly.train.losses.EvidentialCELoss.forward" title="Link to this definition">¶</a></dt>
<dd><p>Forward pass of the evidential cross entropy loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>inputs</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.9)"><em>Tensor</em></a>) – torch.Tensor of size (n_instances, n_classes)</p></li>
<li><p><strong>targets</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.9)"><em>Tensor</em></a>) – torch.Tensor of size (n_instances,)</p></li>
</ul>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor, mean loss value</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>loss</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="probly.train.losses.EvidentialKLDivergence">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">probly.train.losses.</span></span><span class="sig-name descname"><span class="pre">EvidentialKLDivergence</span></span><a class="reference internal" href="../_modules/probly/train/losses.html#EvidentialKLDivergence"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#probly.train.losses.EvidentialKLDivergence" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a></p>
<p>Evidential KL Divergence Loss based on <span id="id12">[<a class="reference internal" href="../references.html#id5" title="Murat Sensoy, Lance M. Kaplan, and Melih Kandemir. Evidential deep learning to quantify classification uncertainty. In Samy Bengio, Hanna M. Wallach, Hugo Larochelle, Kristen Grauman, Nicolò Cesa-Bianchi, and Roman Garnett, editors, Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montréal, Canada, 3183–3193. 2018. URL: https://proceedings.neurips.cc/paper/2018/hash/a981f2b708044d6fb4a71a1463242520-Abstract.html.">SKK18</a>]</span>.</p>
<dl class="field-list simple">
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="probly.train.losses.EvidentialKLDivergence.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/probly/train/losses.html#EvidentialKLDivergence.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#probly.train.losses.EvidentialKLDivergence.forward" title="Link to this definition">¶</a></dt>
<dd><p>Forward pass of the evidential KL divergence loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>inputs</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.9)"><em>Tensor</em></a>) – torch.Tensor of size (n_instances, n_classes)</p></li>
<li><p><strong>targets</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.9)"><em>Tensor</em></a>) – torch.Tensor of size (n_instances,)</p></li>
</ul>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor, mean loss value</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>loss</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="probly.train.losses.EvidentialLogLoss">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">probly.train.losses.</span></span><span class="sig-name descname"><span class="pre">EvidentialLogLoss</span></span><a class="reference internal" href="../_modules/probly/train/losses.html#EvidentialLogLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#probly.train.losses.EvidentialLogLoss" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a></p>
<p>Evidential Log Loss based on <span id="id13">[<a class="reference internal" href="../references.html#id5" title="Murat Sensoy, Lance M. Kaplan, and Melih Kandemir. Evidential deep learning to quantify classification uncertainty. In Samy Bengio, Hanna M. Wallach, Hugo Larochelle, Kristen Grauman, Nicolò Cesa-Bianchi, and Roman Garnett, editors, Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montréal, Canada, 3183–3193. 2018. URL: https://proceedings.neurips.cc/paper/2018/hash/a981f2b708044d6fb4a71a1463242520-Abstract.html.">SKK18</a>]</span>.</p>
<dl class="field-list simple">
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="probly.train.losses.EvidentialLogLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/probly/train/losses.html#EvidentialLogLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#probly.train.losses.EvidentialLogLoss.forward" title="Link to this definition">¶</a></dt>
<dd><p>Forward pass of the evidential log loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>inputs</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.9)"><em>Tensor</em></a>) – torch.Tensor of size (n_instances, n_classes)</p></li>
<li><p><strong>targets</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.9)"><em>Tensor</em></a>) – torch.Tensor of size (n_instances,)</p></li>
</ul>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor, mean loss value</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>loss</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="probly.train.losses.EvidentialMSELoss">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">probly.train.losses.</span></span><span class="sig-name descname"><span class="pre">EvidentialMSELoss</span></span><a class="reference internal" href="../_modules/probly/train/losses.html#EvidentialMSELoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#probly.train.losses.EvidentialMSELoss" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a></p>
<p>Evidential Mean Square Error Loss based on <span id="id14">[<a class="reference internal" href="../references.html#id5" title="Murat Sensoy, Lance M. Kaplan, and Melih Kandemir. Evidential deep learning to quantify classification uncertainty. In Samy Bengio, Hanna M. Wallach, Hugo Larochelle, Kristen Grauman, Nicolò Cesa-Bianchi, and Roman Garnett, editors, Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montréal, Canada, 3183–3193. 2018. URL: https://proceedings.neurips.cc/paper/2018/hash/a981f2b708044d6fb4a71a1463242520-Abstract.html.">SKK18</a>]</span>.</p>
<dl class="field-list simple">
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="probly.train.losses.EvidentialMSELoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/probly/train/losses.html#EvidentialMSELoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#probly.train.losses.EvidentialMSELoss.forward" title="Link to this definition">¶</a></dt>
<dd><p>Forward pass of the evidential mean squared error loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>inputs</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.9)"><em>Tensor</em></a>) – torch.Tensor of size (n_instances, n_classes)</p></li>
<li><p><strong>targets</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.9)"><em>Tensor</em></a>) – torch.Tensor of size (n_instances,)</p></li>
</ul>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor, mean loss value</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>loss</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="probly.train.losses.EvidentialNIGNLLLoss">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">probly.train.losses.</span></span><span class="sig-name descname"><span class="pre">EvidentialNIGNLLLoss</span></span><a class="reference internal" href="../_modules/probly/train/losses.html#EvidentialNIGNLLLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#probly.train.losses.EvidentialNIGNLLLoss" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a></p>
<p>Evidential normal inverse gamma negative log likelihood loss.</p>
<p>Implementation is based on <span id="id15">[<a class="reference internal" href="../references.html#id6" title="Alexander Amini, Wilko Schwarting, Ava Soleimany, and Daniela Rus. Deep evidential regression. In Hugo Larochelle, Marc'Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin, editors, Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual. 2020. URL: https://proceedings.neurips.cc/paper/2020/hash/aab085461de182608ee9f607f3f7d18f-Abstract.html.">ASSR20</a>]</span>.</p>
<dl class="field-list simple">
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="probly.train.losses.EvidentialNIGNLLLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/probly/train/losses.html#EvidentialNIGNLLLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#probly.train.losses.EvidentialNIGNLLLoss.forward" title="Link to this definition">¶</a></dt>
<dd><p>Forward pass of the evidential normal inverse gamma negative log likelihood loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>inputs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.14)"><em>dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.9)"><em>Tensor</em></a><em>]</em>) – dict[str, torch.Tensor] with keys ‘gamma’, ‘nu’, ‘alpha’, ‘beta’</p></li>
<li><p><strong>targets</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.9)"><em>Tensor</em></a>) – torch.Tensor of size (n_instances,)</p></li>
</ul>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor, mean loss value</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>loss</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="probly.train.losses.EvidentialRegressionRegularization">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">probly.train.losses.</span></span><span class="sig-name descname"><span class="pre">EvidentialRegressionRegularization</span></span><a class="reference internal" href="../_modules/probly/train/losses.html#EvidentialRegressionRegularization"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#probly.train.losses.EvidentialRegressionRegularization" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a></p>
<p>Implementation of the evidential regression regularization <span id="id16">[<a class="reference internal" href="../references.html#id6" title="Alexander Amini, Wilko Schwarting, Ava Soleimany, and Daniela Rus. Deep evidential regression. In Hugo Larochelle, Marc'Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin, editors, Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual. 2020. URL: https://proceedings.neurips.cc/paper/2020/hash/aab085461de182608ee9f607f3f7d18f-Abstract.html.">ASSR20</a>]</span>.</p>
<dl class="field-list simple">
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="probly.train.losses.EvidentialRegressionRegularization.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/probly/train/losses.html#EvidentialRegressionRegularization.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#probly.train.losses.EvidentialRegressionRegularization.forward" title="Link to this definition">¶</a></dt>
<dd><p>Forward pass of the evidential regression regularization.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>inputs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.14)"><em>dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.9)"><em>Tensor</em></a><em>]</em>) – dict[str, torch.Tensor] with keys ‘gamma’, ‘nu’, ‘alpha’, ‘beta’</p></li>
<li><p><strong>targets</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.9)"><em>Tensor</em></a>) – torch.Tensor of size (n_instances,)</p></li>
</ul>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor, mean loss value</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>loss</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="probly.train.losses.ExpectedCalibrationError">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">probly.train.losses.</span></span><span class="sig-name descname"><span class="pre">ExpectedCalibrationError</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_bins</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/probly/train/losses.html#ExpectedCalibrationError"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#probly.train.losses.ExpectedCalibrationError" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a></p>
<p>Expected Calibration Error (ECE) <span id="id17">[<a class="reference internal" href="../references.html#id14" title="Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q. Weinberger. On calibration of modern neural networks. In Doina Precup and Yee Whye Teh, editors, Proceedings of the 34th International Conference on Machine Learning, ICML 2017, Sydney, NSW, Australia, 6-11 August 2017, volume 70 of Proceedings of Machine Learning Research, 1321–1330. PMLR, 2017. URL: http://proceedings.mlr.press/v70/guo17a.html.">GPSW17</a>]</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>num_bins</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>)</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="probly.train.losses.ExpectedCalibrationError.num_bins">
<span class="sig-name descname"><span class="pre">num_bins</span></span><a class="headerlink" href="#probly.train.losses.ExpectedCalibrationError.num_bins" title="Link to this definition">¶</a></dt>
<dd><p>int, number of bins to use for calibration</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="probly.train.losses.ExpectedCalibrationError.self.bins">
<span class="sig-prename descclassname"><span class="pre">self.</span></span><span class="sig-name descname"><span class="pre">bins</span></span><a class="headerlink" href="#probly.train.losses.ExpectedCalibrationError.self.bins" title="Link to this definition">¶</a></dt>
<dd><p>torch.Tensor, the actual bins for calibration</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="probly.train.losses.ExpectedCalibrationError.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/probly/train/losses.html#ExpectedCalibrationError.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#probly.train.losses.ExpectedCalibrationError.forward" title="Link to this definition">¶</a></dt>
<dd><p>Forward pass of the expected calibration error.</p>
<p>Assumes that inputs are probability distributions over classes.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>inputs</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.9)"><em>Tensor</em></a>) – torch.Tensor of size (n_instances, n_classes).</p></li>
<li><p><strong>targets</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.9)"><em>Tensor</em></a>) – torch.Tensor of size (n_instances,)</p></li>
</ul>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor, mean loss value</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>loss</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="probly.train.losses.FocalLoss">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">probly.train.losses.</span></span><span class="sig-name descname"><span class="pre">FocalLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/probly/train/losses.html#FocalLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#probly.train.losses.FocalLoss" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a></p>
<p>Focal Loss based on <span id="id18">[<a class="reference internal" href="../references.html#id13" title="Tsung-Yi Lin, Priya Goyal, Ross B. Girshick, Kaiming He, and Piotr Dollár. Focal loss for dense object detection. In IEEE International Conference on Computer Vision, ICCV 2017, Venice, Italy, October 22-29, 2017, 2999–3007. IEEE Computer Society, 2017. URL: https://doi.org/10.1109/ICCV.2017.324, doi:10.1109/ICCV.2017.324.">LGG+17</a>]</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a>)</p></li>
<li><p><strong>gamma</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a>)</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="probly.train.losses.FocalLoss.alpha">
<span class="sig-name descname"><span class="pre">alpha</span></span><a class="headerlink" href="#probly.train.losses.FocalLoss.alpha" title="Link to this definition">¶</a></dt>
<dd><p>float, control importance of minority class</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="probly.train.losses.FocalLoss.gamma">
<span class="sig-name descname"><span class="pre">gamma</span></span><a class="headerlink" href="#probly.train.losses.FocalLoss.gamma" title="Link to this definition">¶</a></dt>
<dd><p>float, control loss for hard instances</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="probly.train.losses.FocalLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/probly/train/losses.html#FocalLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#probly.train.losses.FocalLoss.forward" title="Link to this definition">¶</a></dt>
<dd><p>Forward pass of the focal loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>inputs</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.9)"><em>Tensor</em></a>) – torch.Tensor of size (n_instances, n_classes)</p></li>
<li><p><strong>targets</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.9)"><em>Tensor</em></a>) – torch.Tensor of size (n_instances,)</p></li>
</ul>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor, mean loss value</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>loss</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="probly.train.losses.LabelRelaxationLoss">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">probly.train.losses.</span></span><span class="sig-name descname"><span class="pre">LabelRelaxationLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/probly/train/losses.html#LabelRelaxationLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#probly.train.losses.LabelRelaxationLoss" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a></p>
<p>Label Relaxation Loss from <span id="id19">[<a class="reference internal" href="../references.html#id10" title="Julian Lienen and Eyke Hüllermeier. From label smoothing to label relaxation. In Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event, February 2-9, 2021, 8583–8591. AAAI Press, 2021. URL: https://doi.org/10.1609/aaai.v35i10.17041, doi:10.1609/AAAI.V35I10.17041.">LHullermeier21</a>]</span>.</p>
<p>This loss is used to improve the calibration of a neural network. It works by minimizing
the Kullback-Leibler divergence between the predicted probabilities and the target distribution in the credal set
defined by the alpha parameter. The target distribution is the distribution in the credal set that minimizes the
Kullback-Leibler divergence from the predicted probabilities. If the predicted probability distribution
is in the credal set, the loss is zero.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a>)</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="probly.train.losses.LabelRelaxationLoss.alpha">
<span class="sig-name descname"><span class="pre">alpha</span></span><a class="headerlink" href="#probly.train.losses.LabelRelaxationLoss.alpha" title="Link to this definition">¶</a></dt>
<dd><p>float, the parameter that controls the amount of label relaxation. Increasing alpha, increases the size
of the credal set and thus the amount of label relaxation.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="probly.train.losses.LabelRelaxationLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/probly/train/losses.html#LabelRelaxationLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#probly.train.losses.LabelRelaxationLoss.forward" title="Link to this definition">¶</a></dt>
<dd><p>Forward pass of the label relaxation loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>inputs</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.9)"><em>Tensor</em></a>) – torch.Tensor of size (n_instances, n_classes)</p></li>
<li><p><strong>targets</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.9)"><em>Tensor</em></a>) – torch.Tensor of size (n_instances,)</p></li>
</ul>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor, mean loss value</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>loss</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="probly.transformation.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">probly.transformation</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="probly.train.bayesian.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">probly.train.bayesian</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2025, probly team
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">probly.train.losses</a><ul>
<li><a class="reference internal" href="#probly.train.losses.ELBOLoss"><code class="docutils literal notranslate"><span class="pre">ELBOLoss</span></code></a><ul>
<li><a class="reference internal" href="#probly.train.losses.ELBOLoss.kl_penalty"><code class="docutils literal notranslate"><span class="pre">ELBOLoss.kl_penalty</span></code></a></li>
<li><a class="reference internal" href="#probly.train.losses.ELBOLoss.forward"><code class="docutils literal notranslate"><span class="pre">ELBOLoss.forward()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#probly.train.losses.EvidentialCELoss"><code class="docutils literal notranslate"><span class="pre">EvidentialCELoss</span></code></a><ul>
<li><a class="reference internal" href="#probly.train.losses.EvidentialCELoss.forward"><code class="docutils literal notranslate"><span class="pre">EvidentialCELoss.forward()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#probly.train.losses.EvidentialKLDivergence"><code class="docutils literal notranslate"><span class="pre">EvidentialKLDivergence</span></code></a><ul>
<li><a class="reference internal" href="#probly.train.losses.EvidentialKLDivergence.forward"><code class="docutils literal notranslate"><span class="pre">EvidentialKLDivergence.forward()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#probly.train.losses.EvidentialLogLoss"><code class="docutils literal notranslate"><span class="pre">EvidentialLogLoss</span></code></a><ul>
<li><a class="reference internal" href="#probly.train.losses.EvidentialLogLoss.forward"><code class="docutils literal notranslate"><span class="pre">EvidentialLogLoss.forward()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#probly.train.losses.EvidentialMSELoss"><code class="docutils literal notranslate"><span class="pre">EvidentialMSELoss</span></code></a><ul>
<li><a class="reference internal" href="#probly.train.losses.EvidentialMSELoss.forward"><code class="docutils literal notranslate"><span class="pre">EvidentialMSELoss.forward()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#probly.train.losses.EvidentialNIGNLLLoss"><code class="docutils literal notranslate"><span class="pre">EvidentialNIGNLLLoss</span></code></a><ul>
<li><a class="reference internal" href="#probly.train.losses.EvidentialNIGNLLLoss.forward"><code class="docutils literal notranslate"><span class="pre">EvidentialNIGNLLLoss.forward()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#probly.train.losses.EvidentialRegressionRegularization"><code class="docutils literal notranslate"><span class="pre">EvidentialRegressionRegularization</span></code></a><ul>
<li><a class="reference internal" href="#probly.train.losses.EvidentialRegressionRegularization.forward"><code class="docutils literal notranslate"><span class="pre">EvidentialRegressionRegularization.forward()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#probly.train.losses.ExpectedCalibrationError"><code class="docutils literal notranslate"><span class="pre">ExpectedCalibrationError</span></code></a><ul>
<li><a class="reference internal" href="#probly.train.losses.ExpectedCalibrationError.num_bins"><code class="docutils literal notranslate"><span class="pre">ExpectedCalibrationError.num_bins</span></code></a></li>
<li><a class="reference internal" href="#probly.train.losses.ExpectedCalibrationError.self.bins"><code class="docutils literal notranslate"><span class="pre">ExpectedCalibrationError.self.bins</span></code></a></li>
<li><a class="reference internal" href="#probly.train.losses.ExpectedCalibrationError.forward"><code class="docutils literal notranslate"><span class="pre">ExpectedCalibrationError.forward()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#probly.train.losses.FocalLoss"><code class="docutils literal notranslate"><span class="pre">FocalLoss</span></code></a><ul>
<li><a class="reference internal" href="#probly.train.losses.FocalLoss.alpha"><code class="docutils literal notranslate"><span class="pre">FocalLoss.alpha</span></code></a></li>
<li><a class="reference internal" href="#probly.train.losses.FocalLoss.gamma"><code class="docutils literal notranslate"><span class="pre">FocalLoss.gamma</span></code></a></li>
<li><a class="reference internal" href="#probly.train.losses.FocalLoss.forward"><code class="docutils literal notranslate"><span class="pre">FocalLoss.forward()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#probly.train.losses.LabelRelaxationLoss"><code class="docutils literal notranslate"><span class="pre">LabelRelaxationLoss</span></code></a><ul>
<li><a class="reference internal" href="#probly.train.losses.LabelRelaxationLoss.alpha"><code class="docutils literal notranslate"><span class="pre">LabelRelaxationLoss.alpha</span></code></a></li>
<li><a class="reference internal" href="#probly.train.losses.LabelRelaxationLoss.forward"><code class="docutils literal notranslate"><span class="pre">LabelRelaxationLoss.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=4621528c"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=5fa4622c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=ccdb6887"></script>
    </body>
</html>